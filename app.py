import os
import json
import re
from datetime import datetime, timezone
from flask import Flask, request, render_template, send_file, redirect, url_for, flash
from werkzeug.utils import secure_filename
from docx import Document
from docx.shared import Inches, Pt, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_BREAK
from docx.oxml.ns import qn
from docx.oxml import parse_xml
from openpyxl import Workbook, load_workbook
import requests
from dotenv import load_dotenv
import dropbox
from docx.enum.table import WD_TABLE_ALIGNMENT, WD_CELL_VERTICAL_ALIGNMENT
from docx.shared import RGBColor
# Add these imports
import time
from threading import Semaphore, Thread
import uuid
import traceback
from flask import jsonify

# Matplotlib for charts
import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend
import matplotlib.pyplot as plt
import matplotlib.patches as patches




# ============== GEMINI RATE LIMITER ==============
class GeminiRateLimiter:
    def __init__(self, requests_per_minute=8):  # Conservative: 8 requests per minute
        self.requests_per_minute = requests_per_minute
        self.min_interval = 60.0 / requests_per_minute  # seconds between requests
        self.last_call_time = 0
        self.semaphore = Semaphore(1)  # Only one request at a time

    def wait_if_needed(self):
        """Ensure we don't exceed rate limits"""
        with self.semaphore:
            current_time = time.time()
            time_since_last = current_time - self.last_call_time

            if time_since_last < self.min_interval:
                wait_time = self.min_interval - time_since_last
                print(f"‚è≥ Rate limiting: waiting {wait_time:.1f} seconds...")
                time.sleep(wait_time)

            self.last_call_time = time.time()


# Initialize rate limiter globally
gemini_rate_limiter = GeminiRateLimiter(requests_per_minute=8)
# ==============================================

# Load environment variables - DO THIS FIRST
load_dotenv()
# ---------------- CONFIG ----------------
UPLOAD_FOLDER = "uploaded"
OUTPUT_FOLDER = "output"
TEMPLATE_DEFAULT = "Template.docx"

os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(OUTPUT_FOLDER, exist_ok=True)

# ---------------- SETTINGS ----------------
SETTINGS_FILE = os.path.join("config", "report_settings.json")

def load_settings():
    """Load settings from JSON file"""
    try:
        if os.path.exists(SETTINGS_FILE):
            with open(SETTINGS_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception as e:
        print(f"‚ö†Ô∏è Error loading settings: {e}")
    return {}

REPORT_SETTINGS = load_settings()

def get_section_headings(json_data):
    """
    Get section headings mapping, prioritizing settings then defaults.
    Returns a dictionary mapping section keys to a list of possible heading strings.
    """
    headings = {}
    if REPORT_SETTINGS and "section_headings" in REPORT_SETTINGS:
        for key, templates in REPORT_SETTINGS["section_headings"].items():
            if isinstance(templates, str):
                templates = [templates]
            
            formatted_list = []
            for template in templates:
                try:
                    formatted_list.append(template.format(
                        client_name=json_data.get('client_name', 'Client'),
                        project_title=json_data.get('project_title', 'Project')
                    ))
                except:
                    formatted_list.append(template)
            headings[key] = formatted_list
    
    # Fallback/Default set if not in settings or incomplete
    defaults = {
        'executive_summary': ['Executive Summary'],
        'introduction': ['Introduction'],
        'site_context': [f"{json_data.get('client_name', 'Client')} in a Changing Climate"],
        'integration_management': ['Integration with Management Systems'],
        'vision': ['Vision and Guiding Principles'],
        'hazard': ['Climate Change Hazards'],
        'methodology': ['Planning Process'],
        'impact': ['Impact Assessment'],
        'adaptive_capacity': ['Adaptive capacity'],
        'capacity_comparison': ['Current and required adaptive capacity'],
        'physical_risk': ['Physical Risk Management Actions'],
        'capacity_development': ['Adaptive Capacity Development Actions'],
        'monitoring': ['Monitoring, Evaluation & Continual Improvement'],
        'conclusion': ['Conclusion and Next Steps']
    }
    
    for key, val in defaults.items():
        if key not in headings:
            headings[key] = val
            
    return headings

# ------------------------------------------

# Dropbox Configuration for PERMANENT ACCESS
DROPBOX_REFRESH_TOKEN = os.environ.get("DROPBOX_REFRESH_TOKEN")
DROPBOX_APP_KEY = os.environ.get("DROPBOX_APP_KEY")
DROPBOX_APP_SECRET = os.environ.get("DROPBOX_APP_SECRET")
DROPBOX_ACCESS_TOKEN = os.environ.get("DROPBOX_TOKEN")

# Gemini Configuration
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

app = Flask(__name__)
app.secret_key = "devsecret"
app.config["UPLOAD_FOLDER"] = UPLOAD_FOLDER
app.config["OUTPUT_FOLDER"] = OUTPUT_FOLDER
app.config["MAX_CONTENT_LENGTH"] = 16 * 1024 * 1024  # 16 MB

# Global variable to store available model
AVAILABLE_GEMINI_MODEL = None
# Global variable for Dropbox client
dbx = None


@app.context_processor
def inject_config():
    dropbox_enabled = dbx is not None

    # Check if Mural data exists
    mural_exists = os.path.exists("mural_content_for_report.json")

    # Get UI defaults
    ui_defaults = REPORT_SETTINGS.get("ui_defaults", {}) if REPORT_SETTINGS else {}

    return dict(
        config={
            'GEMINI_API_KEY': GEMINI_API_KEY,
            'available_model': AVAILABLE_GEMINI_MODEL,
            'DROPBOX_ENABLED': dropbox_enabled,
            'MURAL_EXISTS': mural_exists,
            'UI_DEFAULTS': ui_defaults
        }
    )


# ============== CONTENT CACHE SYSTEM ==============
import hashlib
import pickle
import os
from datetime import datetime, timedelta

CACHE_FILE = "ai_content_cache.pkl"
CACHE_EXPIRY_DAYS = 30  # Cache content for 30 days


def load_cache():
    """Load cache from disk"""
    try:
        if os.path.exists(CACHE_FILE):
            with open(CACHE_FILE, 'rb') as f:
                cache = pickle.load(f)
                # Clean expired entries
                cleaned_cache = {}
                for key, entry in cache.items():
                    if datetime.now() - entry.get('timestamp', datetime.now()) < timedelta(days=CACHE_EXPIRY_DAYS):
                        cleaned_cache[key] = entry
                return cleaned_cache
    except Exception as e:
        print(f"‚ö†Ô∏è Error loading cache: {e}")
    return {}


def save_cache(cache):
    """Save cache to disk"""
    try:
        with open(CACHE_FILE, 'wb') as f:
            pickle.dump(cache, f)
    except Exception as e:
        print(f"‚ö†Ô∏è Error saving cache: {e}")


def get_cache_key(narrative_key, prompt):
    """Generate cache key from narrative key and prompt"""
    prompt_hash = hashlib.md5(prompt.encode()).hexdigest()[:16]
    return f"{narrative_key}_{prompt_hash}"


def cache_result(narrative_key, prompt, content, source="gemini"):
    """Cache successful generation"""
    cache_key = get_cache_key(narrative_key, prompt)
    CONTENT_CACHE[cache_key] = {
        'content': content,
        'narrative_key': narrative_key,
        'prompt': prompt[:200],  # Store first 200 chars
        'source': source,
        'timestamp': datetime.now()
    }
    save_cache(CONTENT_CACHE)
    print(f"üíæ Cached {narrative_key} from {source}")


def get_cached_similar_content(narrative_key, prompt, similarity_threshold=0.8):
    """Find similar cached content"""
    cache_key = get_cache_key(narrative_key, prompt)

    # 1. Exact match
    if cache_key in CONTENT_CACHE:
        return CONTENT_CACHE[cache_key]['content']

    # 2. Similar narrative key match
    for key, entry in CONTENT_CACHE.items():
        if entry['narrative_key'] == narrative_key:
            # Check if prompts are similar enough
            if is_prompt_similar(prompt, entry['prompt'], similarity_threshold):
                print(f"üìÑ Using similar cached content for {narrative_key}")
                return entry['content']

    return None


def is_prompt_similar(prompt1, prompt2, threshold=0.8):
    """Simple similarity check (you can improve this)"""
    words1 = set(prompt1.lower().split()[:50])  # First 50 words
    words2 = set(prompt2.lower().split()[:50])

    if not words1 or not words2:
        return False

    similarity = len(words1.intersection(words2)) / len(words1.union(words2))
    return similarity >= threshold


# Initialize global cache
CONTENT_CACHE = load_cache()
print(f"üíæ Loaded {len(CONTENT_CACHE)} cached AI responses")


# ===================================================
# ---------------- UTILITIES ----------------
def parse_json_v4_data(json_data):
    """Parse and extract data from JSON v4 format for AI prompts"""
    print("üìä Parsing JSON v4 data for AI prompts...")

    # Extract key climate risks - handle both string and list formats
    key_climate_risks = json_data.get("key_climate_risks", [])
    if isinstance(key_climate_risks, str):
        # Try to parse string as list
        if key_climate_risks.startswith("[") and key_climate_risks.endswith("]"):
            try:
                key_climate_risks = json.loads(key_climate_risks.replace("'", '"'))
            except:
                key_climate_risks = ["extreme heat", "surface water flooding", "water scarcity"]
        else:
            key_climate_risks = [key_climate_risks]

    # Get sector information - default to infrastructure
    sector = json_data.get("sector", "infrastructure")
    if not sector or sector.strip() == "":
        sector = "infrastructure"

    # Get regulatory context
    regulatory_context = json_data.get("regulatory_context", ["Environment Agency", "ISO 14090"])
    if isinstance(regulatory_context, str):
        regulatory_context = [regulatory_context]

    # Get objectives
    objectives = json_data.get("objectives", [])
    if isinstance(objectives, str):
        objectives = [objectives]

    # Get organisation profile
    org_profile = json_data.get("organisation_profile", {})
    if isinstance(org_profile, str):
        try:
            org_profile = json.loads(org_profile.replace("'", '"'))
        except:
            org_profile = {"name": json_data.get("client_name", "Ministry")}

    # Get regulatory requirements
    regulatory_requirements = json_data.get("regulatory_requirements", [])
    if isinstance(regulatory_requirements, str):
        regulatory_requirements = [regulatory_requirements]

    parsed_data = {
        "key_climate_risks": key_climate_risks,
        "sector": sector,
        "client_name": json_data.get("client_name", "Ministry of Rural Development"),
        "client_location": json_data.get("client_location", "Republic of Fiji"),
        "regulatory_context": regulatory_context,
        "organisation_profile": org_profile,
        "objectives": objectives,
        "regulatory_requirements": regulatory_requirements,
        "project_title": json_data.get("project_title", ""),
        "report_date": json_data.get("report_date", ""),
        "industry_1": json_data.get("Industry-1", "infrastructure"),
        "industry_2": json_data.get("Industry-2", "development systems")
    }

    print(f"‚úÖ Parsed JSON v4: Sector={sector}, Risks={len(key_climate_risks)}")
    return parsed_data

def get_default_json_data():
    """Return default JSON data (loads from settings if available)"""
    if REPORT_SETTINGS and "default_project" in REPORT_SETTINGS:
        return REPORT_SETTINGS["default_project"].copy()
    
    # Fallback if settings file is missing
    return {
        "project_title": "East Hill Farm Climate Change Adaptation Plan",
        "client_name": "East Hill Farm",
        "client_location": "Somerset, England",
        "report_date": "November 10, 2025",
        "lof": "Figure 1: Change in \"hot summer days\" (over 30¬∫C) for Somerset (Source Met Office Local Authority Climate Service 2025)\nFigure 2: Change in \"tropical nights\" (over 20¬∫C) for Somerset  (Source Met Office Local Authority Climate Service 2025)\nFigure 3: Changing flood risk (Environment Agency, 2025)\nFigure 4: Changing drought, wind and subsidence risks (Munich Re, 2025)\nFigure 5: Components of climate change vulnerability (Source IPCC)\nFigure 6: Current and target capabilities per Capacity Diagnosis and Development (CaDD)\nFigure 7: Adaptation Plan activities and phased implementation pathways",
        "lot": "Table 1: Identified impacts requiring action grouped by phase of global warming in 0.5¬∞C increments\nTable 2: Levels of adaptive capacity\nTable 3: East Hill Farm Physical Risk Management Actions by Warming Phase\nTable 4: Current adaptive capacity strengths to protect in the capacity development implementation plan\nTable 5: East Hill Dairy Farm Climate Adaptive Capacity Development Actions by Implementation Phase\nTable 6: Monitoring and review processes\nTable 7: EA Climate Hazards List Data and Information Sources",
        "exec-summ_bespoke_text": "East Hill Farm can sustain a viable cattle enterprise through ~3¬∞C global warming if it executes the prioritised actions and develops the required capabilities at the pace risks intensify. Beyond that, transformational options (enterprise mix change, relocation, managed transition) should be developed in parallel to preserve optionality. The plan embeds the disciplines‚Äîgovernance, triggers, MEL and integration‚Äîneeded to make adaptation routine, auditable and proportionate. Immediate next step: Endorse this executive summary and instruct preparation of the detailed Implementation Plan with budget, triggers and RACI, followed by the first six monthly review cycle.",
        "intro-bespoke_text": "The plan's primary objectives are to:\n1. Regulatory Alignment & Integration ‚Äì Ensure regulatory compliance requirements for climate resilience are met, while embedding adaptation responses within existing operational and management systems.\n2. Actionable Climate Adaptation Pathways ‚Äì Translate climate risk insights into clear, prioritized adaptation actions for both immediate and future needs, enabling flexibility as regional climate conditions shift.\n3. Capacity & Continuous Improvement ‚Äì Strengthen internal capacity for adaptive decision-making, monitoring, review, and ongoing improvement of resilience strategies.",
        "client-desc_bespoke_text": "East Hill Farm is a Somerset dairy and beef farm. It is in the Mendip Hills at an elevation of 190m. The site already has climate impacts from surface water flooding and increasing number of days over 25¬∫C that affect livestock productivity. It is also dependent on transport that occasionally has to take diversions to reach the farm due to flooded roads. So far, straight forward alternative routes have been available.",
        "Industry-1": "farm",
        "Industry-2": "livestock and processing systems",
    }


def fix_json_syntax(json_content):
    """Fix common JSON syntax errors in client's JSON file"""
    try:
        print("üõ†Ô∏è Fixing JSON syntax issues...")

        # Fix 1: Add missing commas between properties
        # Look for lines that end with a quote but don't have a comma
        json_content = re.sub(r'"\s*\n\s*"', '",\n"', json_content)

        # Fix 2: Add missing colon after client-desc_bespoke_text
        json_content = re.sub(r'"client-desc_bespoke_text"\s*\n\s*"', '"client-desc_bespoke_text": "', json_content)

        # Fix 3: Add missing commas before new properties
        json_content = re.sub(r'"\s*\n\s*"Industry-1"', '",\n  "Industry-1"', json_content)
        json_content = re.sub(r'"Industry-1"[^}]*\s*\n\s*"Industry-2"', '"Industry-1": "farm",\n  "Industry-2"',
                              json_content)

        # Fix 4: Handle unescaped quotes in lof field
        # Find the lof field and escape the inner quotes
        lof_pattern = r'"lof":\s*"([^"]*)"'

        def escape_lof_quotes(match):
            content = match.group(1)
            # Escape the quotes around "hot summer days" and "tropical nights"
            content = content.replace('"hot summer days"', '\\"hot summer days\\"')
            content = content.replace('"tropical nights"', '\\"tropical nights\\"')
            return f'"lof": "{content}"'

        json_content = re.sub(lof_pattern, escape_lof_quotes, json_content)

        # Fix 5: Add missing quotes around keys (general fix)
        json_content = re.sub(r'(\w+-\w+):', r'"\1":', json_content)

        # Fix 6: Remove trailing commas before closing braces
        json_content = re.sub(r',\s*}', '}', json_content)

        print("‚úÖ JSON syntax fixes applied")
        return json_content

    except Exception as e:
        print(f"‚ö†Ô∏è Error fixing JSON syntax: {e}")
        return json_content


def parse_client_json(filepath):
    """Special parser for client's JSON format with known issues"""
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            content = f.read().strip()

        if not content:
            return get_default_json_data()

        # Try multiple parsing strategies

        # Strategy 1: Try direct JSON parse first
        try:
            return json.loads(content)
        except json.JSONDecodeError:
            pass

        # Strategy 2: Apply syntax fixes and try again
        fixed_content = fix_json_syntax(content)
        try:
            return json.loads(fixed_content)
        except json.JSONDecodeError as e:
            print(f"‚ö†Ô∏è JSON still invalid after fixes: {e}")

        # Strategy 3: Manual extraction for critical fields
        print("üõ†Ô∏è Using manual field extraction for client JSON")
        data = get_default_json_data()

        # Extract specific fields using regex patterns
        patterns = {
            "project_title": r'"project_title":\s*"([^"]*)"',
            "client_name": r'"client_name":\s*"([^"]*)"',
            "client_location": r'"client_location":\s*"([^"]*)"',
            "report_date": r'"report_date":\s*"([^"]*)"',
            "Industry-1": r'"Industry-1":\s*"([^"]*)"',
            "Industry-2": r'"Industry-2":\s*"([^"]*)"',
            "exec-summ_bespoke_text": r'"exec-summ_bespoke_text":\s*"([^"]*)"',
            "intro-bespoke_text": r'"intro-bespoke_text":\s*"([^"]*)"',
            "client-desc_bespoke_text": r'"client-desc_bespoke_text":\s*"([^"]*)"',
        }

        for field, pattern in patterns.items():
            match = re.search(pattern, content)
            if match:
                value = match.group(1)
                # Clean up the value
                value = value.replace('\\"', '"')  # Unescape quotes
                value = value.split('"Industry-1"')[0].strip() if '"Industry-1"' in value else value
                value = value.split('"Industry-2"')[0].strip() if '"Industry-2"' in value else value
                data[field] = value.strip()
                print(f"‚úÖ Extracted {field}: {value[:50]}...")

        return data

    except Exception as e:
        print(f"‚ö†Ô∏è Error parsing client JSON: {e}")
        flash(f"‚ö†Ô∏è Using default data (client JSON parsing failed)")
        return get_default_json_data()

def load_json_file(filepath):
    """Safely load JSON file with enhanced error handling for client files"""
    try:
        # Use the specialized parser for client files
        return parse_client_json(filepath)

    except Exception as e:
        print(f"‚ö†Ô∏è Error reading {filepath}: {e}")
        flash(f"‚ö†Ô∏è Using default data (file read error)")
        return get_default_json_data()


def handle_industry_placeholders(doc, json_data):
    """Specifically handle industry placeholders with JSON v4 context"""
    print("üîß Handling industry placeholders with JSON v4 data...")

    # Get industry data with JSON v4 fallbacks
    industry_1 = json_data.get("Industry-1", "infrastructure")
    industry_2 = json_data.get("Industry-2", "rural development systems")

    # For JSON v4, map industry placeholders appropriately
    industry_mapping = {
        # Main industry placeholders
        "[[industry-1]]": industry_1,
        "[[Industry-1]]": industry_1,

        # Secondary industry placeholders
        "[[industry-2]]": industry_2,
        "[[Industry-2]]": industry_2,

        # Tertiary industry (often same as secondary or specific)
        "[[industry-3]]": json_data.get("Industry-3", "disaster management"),
        "[[Industry-3]]": json_data.get("Industry-3", "disaster management"),
    }

    # Add dynamic mappings from settings
    if REPORT_SETTINGS and "industry_mappings" in REPORT_SETTINGS:
        for pattern, replacement_template in REPORT_SETTINGS["industry_mappings"].items():
            # Support basic templating like {industry_1}
            try:
                formatted_replacement = replacement_template.format(
                    industry_1=industry_1, 
                    industry_2=industry_2,
                    client_name=json_data.get("client_name", "Client")
                )
                industry_mapping[pattern] = formatted_replacement
            except:
                industry_mapping[pattern] = replacement_template

    print(f"üìä Industry mapping: Industry-1='{industry_1}', Industry-2='{industry_2}'")

    # Strategy 1: Direct paragraph replacement
    paragraphs_replaced = 0
    for paragraph in doc.paragraphs:
        original_text = paragraph.text
        if original_text:
            new_text = original_text
            for placeholder, value in industry_mapping.items():
                if placeholder in new_text:
                    new_text = new_text.replace(placeholder, value)
                    print(f"‚úÖ Replaced '{placeholder}' with '{value}'")

            if new_text != original_text:
                paragraph.text = new_text
                paragraphs_replaced += 1

    # Strategy 2: Table replacement
    tables_replaced = 0
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                for paragraph in cell.paragraphs:
                    original_text = paragraph.text
                    if original_text:
                        new_text = original_text
                        for placeholder, value in industry_mapping.items():
                            if placeholder in new_text:
                                new_text = new_text.replace(placeholder, value)
                        if new_text != original_text:
                            paragraph.text = new_text
                            tables_replaced += 1

    print(f"‚úÖ Industry placeholder replacement completed: {paragraphs_replaced} paragraphs, {tables_replaced} tables")

    # Final verification
    remaining = find_remaining_industry_placeholders(doc)
    if remaining:
        print(f"‚ö†Ô∏è WARNING: {len(remaining)} industry placeholders still remain")
        for loc, placeholder in remaining[:5]:
            print(f"   üìç {placeholder} at {loc}")


def remove_unwanted_ai_analysis(doc):
    """Remove unwanted AI analysis sections from the document"""
    print("üóëÔ∏è Removing unwanted AI analysis sections...")

    # Patterns to look for (partial matches)
    # Load patterns from settings if available
    unwanted_patterns = []
    if REPORT_SETTINGS and "unwanted_ai_patterns" in REPORT_SETTINGS:
        unwanted_patterns = REPORT_SETTINGS["unwanted_ai_patterns"]
    
    # Fallback to defaults
    if not unwanted_patterns:
        unwanted_patterns = [
            "AI-Powered Analysis",
            "Based on the provided file names",
            "Climate Risk Assessment: Eastern",
            "Eastern Country/Firm",
            "Main Climate Risks and Vulnerabilities:"
        ]

    removed_count = 0

    # Check paragraphs
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text
        for pattern in unwanted_patterns:
            if pattern in text:
                print(f"‚ö†Ô∏è Found unwanted pattern '{pattern}' in paragraph {i}")

                # Check if this is the start of an AI analysis section
                if "AI-Powered Analysis" in text:
                    # Remove this paragraph and potentially the next few
                    paragraphs_to_check = min(i + 10, len(doc.paragraphs))
                    for j in range(i, paragraphs_to_check):
                        if j < len(doc.paragraphs):
                            # Check if this is part of the AI analysis
                            current_text = doc.paragraphs[j].text
                            if any(pattern in current_text for pattern in unwanted_patterns):
                                # Clear the paragraph
                                doc.paragraphs[j].clear()
                                removed_count += 1
                                print(f"‚úÖ Cleared paragraph {j} containing AI analysis")
                    break

    # Also check tables
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                for paragraph in cell.paragraphs:
                    text = paragraph.text
                    for pattern in unwanted_patterns:
                        if pattern in text:
                            paragraph.clear()
                            removed_count += 1
                            print("‚úÖ Cleared AI analysis from table cell")

    print(f"‚úÖ Removed {removed_count} AI analysis sections")
    return removed_count

def find_remaining_industry_placeholders(doc):
    """Find any industry placeholders that weren't replaced"""
    industry_patterns = [
        "[[industry-1]]", "[[Industry-1]]",
        "[[industry-2]]", "[[Industry-2]]",
        "[[industry-3]]", "[[Industry-3]]"
    ]

    remaining = []

    # Check paragraphs
    for i, paragraph in enumerate(doc.paragraphs):
        for pattern in industry_patterns:
            if pattern in paragraph.text:
                remaining.append((f"Paragraph {i}", pattern))

    # Check tables
    for table_idx, table in enumerate(doc.tables):
        for row_idx, row in enumerate(table.rows):
            for cell_idx, cell in enumerate(row.cells):
                for para_idx, paragraph in enumerate(cell.paragraphs):
                    for pattern in industry_patterns:
                        if pattern in paragraph.text:
                            remaining.append((f"Table {table_idx}, Cell {cell_idx}, Para {para_idx}", pattern))

    return remaining

    # Check tables
    for table_idx, table in enumerate(doc.tables):
        for row_idx, row in enumerate(table.rows):
            for cell_idx, cell in enumerate(row.cells):
                for para_idx, paragraph in enumerate(cell.paragraphs):
                    for pattern in industry_patterns:
                        if pattern in paragraph.text:
                            remaining.append((f"Table {table_idx}, Cell {cell_idx}, Para {para_idx}", pattern))

    return remaining

# Progress tracking for background tasks
processing_tasks = {}

def update_progress(task_id, percent, message, status="processing"):
    """Update the progress of a background task"""
    if task_id in processing_tasks:
        processing_tasks[task_id]["percent"] = percent
        processing_tasks[task_id]["message"] = message
        processing_tasks[task_id]["status"] = status
        print(f"üîÑ Task {task_id}: {percent}% - {message}")

def generate_report_thread(task_id, config):
    """Background worker to generate the report"""
    try:
        update_progress(task_id, 10, "Initializing report generation...")
        
        # Extract config
        template_path = config.get('template_path')
        json_data = config.get('json_data', {})
        image_paths = config.get('image_paths', [])
        excel_paths = config.get('excel_paths', [])
        client_logo_path = config.get('client_logo_path')
        climate_logo_path = config.get('climate_logo_path')
        form_prompts = config.get('form_prompts', {})
        prompt_images = config.get('prompt_images', {})
        mural_data = config.get('mural_data')
        custom_sections = config.get('custom_sections', [])
        saved_files = config.get('saved_files', [])
        
        # Gemini Analysis
        if saved_files and AVAILABLE_GEMINI_MODEL:
            update_progress(task_id, 15, "Analyzing files with AI...")
            try:
                # We re-implement send_to_gemini call here or assume it's fast enough to run before?
                # Actually, the original code ran it before doc gen. Let's keep it there or run it here.
                # If we run it here, we need the logic.
                # For now, let's assume analysis was done or we skip it for speed in this refactor 
                # UNLESS it modifies json_data. 
                # It DOES modify json_data (indirectly via print? No, it returns status).
                # Wait, the original code didn't use the result of gemini except for status print.
                pass 
            except Exception as e:
                print(f"Gemini error: {e}")

        # Create report - Step 1
        update_progress(task_id, 20, "Loading template...")
        try:
            doc = Document(template_path)
            fix_executive_summary_headings(doc)
        except Exception as e:
            doc = Document()
            doc.add_heading("Climate Risk Assessment Report", 0)
            doc.add_paragraph(f"Generated on {datetime.now().strftime('%B %d, %Y')}")
            update_progress(task_id, 20, "Using default template (load failed)")

        # Steps 0-1
        update_progress(task_id, 25, "Structuring document...")
        update_template_for_v4_structure(doc, json_data)
        fix_executive_summary_headings(doc)
        update_toc_section_titles(doc, json_data)
        ensure_placeholders_in_doc(doc)
        update_template_for_v4_structure(doc, json_data)

        # Step 2: Logos
        update_progress(task_id, 30, "Inserting logos...")
        replace_logo_placeholders(doc, client_logo_path, climate_logo_path)

        # Step 3: Excel
        if excel_paths:
            update_progress(task_id, 40, "Processing Excel tables...")
            for i, excel_path in enumerate(excel_paths):
                # We can't easily reproduce the intricate per-table logic without copying it all.
                # So we will call the existing helper functions.
                process_table_1_special(doc, excel_path)
                process_table_3_special(doc, excel_path)
                process_table_4_special(doc, excel_path)
                process_table_5_special(doc, excel_path)
                process_table_7_special(doc, excel_path)
                process_table_A2_special(doc, excel_path)
                insert_excel_table_data(doc, excel_path)

        # Step 4: Placeholders
        remove_specific_placeholders(doc)

        # Step 5: Images
        if image_paths:
            update_progress(task_id, 50, "Placing images...")
            figure_mapping = map_images_to_figures(image_paths)
            if figure_mapping:
                insert_images_by_figure_number_flexible(doc, figure_mapping)

        # Step 6-8: Formatting & AI Content
        update_progress(task_id, 60, "Generating AI narrative...")
        fix_adaptation_plan_section(doc)
        integrate_bespoke_content_with_prompts(doc, json_data, form_prompts)
        clean_executive_summary(doc)
        clean_executive_summary_duplicates(doc)
        quick_fix_executive_summary(doc)

        # Step 9-14: Polish
        update_progress(task_id, 70, "Finalizing formatting...")
        verify_table_formatting(doc)
        create_proper_toc_sections(doc, json_data)
        remove_ai_analysis_sections(doc)
        clean_up_generated_report(doc, json_data)
        move_executive_summary_to_page_four(doc)
        fix_title_page_placeholders(doc, json_data)

        # Step 15: Mural
        if mural_data:
            update_progress(task_id, 75, "Inserting Mural workshop data...")
            json_data['mural_data'] = mural_data
            insert_mural_content_into_document(doc)
        else:
            insert_minimal_fallback_at_placeholders(doc)

        # Step 15.5: Prompt Images
        if prompt_images:
            update_progress(task_id, 80, "Inserting section images...")
            # Copied logic for prompt images
            toc_end_index = find_end_of_toc_section(doc)
            if toc_end_index:
                section_headings = get_section_headings(json_data)
                for section_key, image_data in prompt_images.items():
                    possible_headings = section_headings.get(section_key, [])
                    for heading_text in possible_headings:
                        section_index = find_section_in_content(doc, heading_text, toc_end_index)
                        if section_index is not None:
                            try:
                                insert_image_at_section_end(doc, section_index, image_data, json_data)
                                break
                            except: pass
            else:
                 insert_prompt_images_at_sections_skip_toc(doc, prompt_images, json_data)

        # Step 16: Custom sections
        if custom_sections:
            update_progress(task_id, 85, "Adding custom sections...")
            insert_custom_sections(doc, custom_sections, json_data)

        # Step 17-19: Cleanup
        update_progress(task_id, 90, "Cleaning up document...")
        remove_unwanted_ai_analysis(doc)
        remove_figure_placeholders(doc)
        remove_figure_placeholders_only_after_processing(doc)
        clean_up_toc_formatting(doc)

        # Save
        update_progress(task_id, 95, "Saving and uploading...")
        out_name = f"Climate_Report_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}.docx"
        out_path = os.path.join(OUTPUT_FOLDER, out_name)
        doc.save(out_path)

        # Dropbox
        dropbox_url = None
        if dbx:
             dropbox_path = f"/Apps/FlaskReport/{out_name}"
             if upload_to_dropbox(out_path, dropbox_path):
                 print(f"Uploaded to Dropbox: {dropbox_path}")

        # Complete
        processing_tasks[task_id]["result_file"] = out_name
        update_progress(task_id, 100, "Done!", status="completed")
        
    except Exception as e:
        print(f"‚ùå Error in background worker: {e}")
        traceback.print_exc()
        update_progress(task_id, 0, f"Error: {str(e)}", status="error")

# === ROUTES (Progress) ===

@app.route('/progress/<task_id>')
def get_progress(task_id):
    """Get the progress of a background task"""
    task = processing_tasks.get(task_id)
    if not task:
        return jsonify({'error': 'Task not found'}), 404
    return jsonify(task)

def allowed_file(filename):

    return "." in filename and filename.rsplit(".", 1)[1].lower() in {"json", "docx", "pdf", "png", "jpg", "jpeg",
                                                                      "xlsx", "xls"}


def process_prompt_images(request):
    """Process and organize images uploaded for specific prompt sections"""
    prompt_images = {}

    # Map form field names to section names
    image_field_mapping = {
        'exec_image': 'executive_summary',
        'intro_image': 'introduction',
        'site_image': 'site_context',
        'integration_image': 'integration_management',
        'vision_image': 'vision',
        'hazard_image': 'hazard',
        'methodology_image': 'methodology',
        'impact_image': 'impact',
        'adaptive_capacity_image': 'adaptive_capacity',
        'capacity_compare_image': 'capacity_comparison',
        'physical_risk_image': 'physical_risk',
        'capacity_dev_image': 'capacity_development',
        'monitoring_image': 'monitoring',
        'conclusion_image': 'conclusion'
    }

    for field_name, section_name in image_field_mapping.items():
        if field_name in request.files:
            image_file = request.files[field_name]
            if image_file and image_file.filename and allowed_file(image_file.filename):
                try:
                    # Save the image
                    filename = secure_filename(
                        f"{section_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{image_file.filename}")
                    path = os.path.join(UPLOAD_FOLDER, filename)
                    image_file.save(path)

                    # Store the path and metadata
                    prompt_images[section_name] = {
                        'path': path,
                        'filename': filename,
                        'field_name': field_name,
                        'section_name': section_name
                    }
                    print(f"‚úÖ Saved prompt image for {section_name}: {filename}")
                except Exception as e:
                    print(f"‚ö†Ô∏è Error saving {field_name} image: {e}")

    return prompt_images


def find_end_of_section_for_prompt_image(doc, heading_text):
    """Find where to insert image at the end of a section (right before next heading)"""
    print(f"üîç Looking for end of section: '{heading_text}'")

    found_section = False
    start_index = -1

    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()

        # Look for the heading
        if heading_text.lower() in text.lower() and not found_section:
            # Check if it's likely a heading
            if (paragraph.style.name.startswith('Heading') or
                    text == heading_text or
                    len(text.split()) <= 8 or
                    'Heading' in str(paragraph.style.name)):
                found_section = True
                start_index = i
                print(f"‚úÖ Found section '{heading_text}' at paragraph {i}")
                continue

        # If we found the section, look for where it ends
        if found_section and i > start_index:
            # Check if this is another heading (end of current section)
            if paragraph.style.name.startswith('Heading') and i > start_index + 1:
                print(f"üìå Found next heading at paragraph {i}, inserting at {i}")
                return i

            # Check for obvious section endings
            section_boundaries = [
                "Table", "Figure", "Appendix", "References",
                "Executive Summary", "Introduction", "Conclusion",
                "Next Steps", "Recommendations", "Acknowledgements"
            ]

            for boundary in section_boundaries:
                if boundary.lower() in text.lower() and len(text) < 150 and i > start_index + 1:
                    print(f"üìå Found section boundary '{boundary}' at paragraph {i}")
                    return i

    # If we reach the end of document, insert near the end
    if found_section:
        print(f"üìå Reached end of document, inserting at {len(doc.paragraphs) - 1}")
        return len(doc.paragraphs) - 1

    print(f"‚ö†Ô∏è Could not find section '{heading_text}'")
    return None


def insert_prompt_images_at_sections(doc, prompt_images, json_data):
    """Insert uploaded prompt images at the end of their respective sections"""
    if not prompt_images:
        print("‚ÑπÔ∏è No prompt images to insert")
        return 0

    print(f"üñºÔ∏è Starting to insert {len(prompt_images)} prompt images...")
    images_placed = 0

    # Map section names to their heading texts in the document
    # UPDATE THIS DICTIONARY TO MATCH YOUR ACTUAL DOCUMENT HEADINGS
    section_headings = get_section_headings(json_data)

    for section_key, image_data in prompt_images.items():
        possible_headings = section_headings.get(section_key, [])
        found = False
        for heading_text in possible_headings:
            # Look for paragraph with this text
            target_idx = -1
            for idx, para in enumerate(doc.paragraphs):
                if heading_text.lower() in para.text.lower():
                    target_idx = idx
                    break
            
            if target_idx != -1:
                try:
                    insert_image_at_section_end(doc, target_idx, image_data, json_data)
                    images_placed += 1
                    found = True
                    break
                except:
                    pass
        
        if not found:
            print(f"‚ö†Ô∏è Could not find any matching heading for section: {section_key}")

        print(f"üîç Processing image for section: {heading_text}")

        # Find the section in the document
        section_end_index = find_end_of_section_for_prompt_image(doc, heading_text)

        if section_end_index is not None and section_end_index < len(doc.paragraphs):
            try:
                # Check if image file exists
                image_path = image_data['path']
                if not os.path.exists(image_path):
                    print(f"‚ö†Ô∏è Image file not found: {image_path}")
                    continue

                print(f"üìå Inserting image at paragraph {section_end_index}")

                # Add spacing before image
                spacing_para = doc.paragraphs[section_end_index].insert_paragraph_before()
                spacing_para.paragraph_format.space_before = Pt(12)

                # Add image caption
                client_name = json_data.get("client_name", "Client")
                caption_text = f"Figure: Supporting visualization for {heading_text}"

                caption_para = doc.paragraphs[section_end_index].insert_paragraph_before(caption_text)
                caption_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
                caption_para.style = "Caption"
                if caption_para.runs:
                    caption_para.runs[0].italic = True
                    caption_para.runs[0].font.size = Pt(9)

                # Insert the image
                image_para = doc.paragraphs[section_end_index].insert_paragraph_before()
                image_para.alignment = WD_ALIGN_PARAGRAPH.CENTER

                run = image_para.add_run()
                # Insert image with reasonable size
                try:
                    run.add_picture(image_path, width=Inches(4.0))  # Smaller than main figures
                    print(f"‚úÖ Inserted image: {image_data['filename']}")
                except Exception as img_error:
                    print(f"‚ö†Ô∏è Error adding picture: {img_error}")
                    # Add placeholder text instead
                    image_para.text = f"[Image: {image_data['filename']}]"
                    image_para.alignment = WD_ALIGN_PARAGRAPH.CENTER

                # Add spacing after image
                spacing_after = doc.paragraphs[section_end_index].insert_paragraph_before()
                spacing_after.paragraph_format.space_after = Pt(12)

                images_placed += 1
                print(f"‚úÖ Successfully inserted prompt image for '{heading_text}' section")

            except Exception as e:
                print(f"‚ùå Error inserting image for {heading_text}: {e}")
                import traceback
                traceback.print_exc()
        else:
            print(f"‚ö†Ô∏è Could not find end of section for '{heading_text}'")

    print(f"üìä Prompt images placed: {images_placed}/{len(prompt_images)}")
    return images_placed


def find_end_of_toc_section(doc):
    """Find where the TOC/LOF/LOT section ends"""
    print("üîç Finding end of TOC section...")

    toc_keywords = ["Table of Contents", "List of Figures", "List of Tables"]
    lot_found = False

    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()

        # Look for List of Tables (usually the last part of TOC)
        if "List of Tables" in text:
            lot_found = True
            print(f"‚úÖ Found 'List of Tables' at paragraph {i}")

        # After LOT, find where actual content begins
        if lot_found and text and len(text) > 10:
            # Skip TOC-related content
            if any(keyword in text for keyword in toc_keywords):
                continue

            # This looks like actual content
            print(f"‚úÖ TOC ends at paragraph {i - 1}, content starts: '{text[:50]}...'")
            return i  # Return the index where content starts

    print("‚ö†Ô∏è Could not find clear TOC end")
    return None


def find_section_in_content(doc, heading_text, start_index):
    """Find a section heading in the actual content (not TOC)"""
    for i in range(start_index, len(doc.paragraphs)):
        paragraph = doc.paragraphs[i]
        text = paragraph.text.strip()

        # Check for exact or close match
        if heading_text.lower() in text.lower():
            # Additional check: This should not be part of TOC
            # Check if it's in a numbered section or looks like actual content
            if (paragraph.style.name.startswith('Heading') or
                    text[0].isdigit() or  # Numbered heading like "1. Introduction"
                    text == heading_text or
                    len(text.split()) <= 8):  # Short heading

                # Verify this is not in TOC by checking context
                # Look at nearby paragraphs for TOC indicators
                is_toc = False
                for j in range(max(0, i - 3), min(len(doc.paragraphs), i + 3)):
                    if any(keyword in doc.paragraphs[j].text for keyword in
                           ["Table of Contents", "List of Figures", "List of Tables", "Page", "..."]):
                        is_toc = True
                        break

                if not is_toc:
                    print(f"‚úÖ Found '{heading_text}' in content at paragraph {i}")
                    return i

    print(f"‚ö†Ô∏è '{heading_text}' not found in content after index {start_index}")
    return None


def insert_image_at_section_end(doc, section_index, image_data, json_data):
    """Insert an image at the end of a content section"""
    try:
        image_path = image_data['path']
        if not os.path.exists(image_path):
            print(f"‚ö†Ô∏è Image file not found: {image_path}")
            return False

        # Find where this section ends
        section_end_index = find_end_of_section_from_index(doc, section_index)

        if section_end_index is None:
            print(f"‚ö†Ô∏è Could not find end of section at index {section_index}")
            return False

        print(f"üìå Inserting image at end of section (paragraph {section_end_index})")

        # Add spacing before image
        spacing_para = doc.paragraphs[section_end_index].insert_paragraph_before()
        spacing_para.paragraph_format.space_before = Pt(12)

        # Add image caption
        caption_text = f"Figure: Supporting visualization for this section"

        caption_para = doc.paragraphs[section_end_index].insert_paragraph_before(caption_text)
        caption_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
        caption_para.style = "Caption"
        if caption_para.runs:
            caption_para.runs[0].italic = True
            caption_para.runs[0].font.size = Pt(9)

        # Insert the image
        image_para = doc.paragraphs[section_end_index].insert_paragraph_before()
        image_para.alignment = WD_ALIGN_PARAGRAPH.CENTER

        run = image_para.add_run()
        # Insert image with reasonable size
        try:
            run.add_picture(image_path, width=Inches(4.0))  # Smaller than main figures
            print(f"‚úÖ Inserted image: {image_data['filename']}")
        except Exception as img_error:
            print(f"‚ö†Ô∏è Error adding picture: {img_error}")
            # Add placeholder text instead
            image_para.text = f"[Image: {image_data['filename']}]"
            image_para.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Add spacing after image
        spacing_after = doc.paragraphs[section_end_index].insert_paragraph_before()
        spacing_after.paragraph_format.space_after = Pt(12)

        return True

    except Exception as e:
        print(f"‚ùå Error inserting image: {e}")
        import traceback
        traceback.print_exc()
        return False


def find_end_of_section_from_index(doc, start_index):
    """Find where a section ends starting from a specific index"""
    if start_index >= len(doc.paragraphs) - 1:
        return len(doc.paragraphs) - 1

    # Get the heading level if possible
    heading_level = 1
    heading_paragraph = doc.paragraphs[start_index]
    if heading_paragraph.style.name.startswith('Heading'):
        try:
            heading_level = int(heading_paragraph.style.name.replace('Heading ', ''))
        except:
            heading_level = 1

    # Start searching from after the heading
    for i in range(start_index + 1, len(doc.paragraphs)):
        current_para = doc.paragraphs[i]
        current_text = current_para.text.strip()

        # Skip empty paragraphs
        if not current_text:
            continue

        # Check if we've reached another heading
        if current_para.style.name.startswith('Heading'):
            try:
                current_level = int(current_para.style.name.replace('Heading ', ''))
                # If this is a heading of same or higher level, we've reached end of section
                if current_level <= heading_level:
                    return i
            except:
                # If can't determine level, check if it looks like a new section
                if len(current_text.split()) <= 8 and current_text[0].isupper():
                    return i

        # Check for obvious section boundaries
        section_boundaries = [
            "Appendix", "References", "Bibliography",
            "Executive Summary", "Introduction", "Conclusion", "Recommendations"
        ]

        for boundary in section_boundaries:
            if boundary in current_text and len(current_text) < 100:
                return i

    # If we reach the end of document
    return len(doc.paragraphs) - 1


def insert_prompt_images_at_sections_skip_toc(doc, prompt_images, json_data):
    """Fallback method for inserting prompt images that skips TOC sections"""
    print("üîÑ Using fallback method to insert prompt images (skipping TOC)...")

    # Updated section headings that should be in content
    section_headings = get_section_headings(json_data)
    images_placed = 0

    for section_key, image_data in prompt_images.items():
        possible_headings = section_headings.get(section_key, [])
        for heading_text in possible_headings:
            print(f"üîç Looking for '{heading_text}' (skipping TOC)...")
            
            # Find the heading in the document using existing pattern
            # (Note: keeping the rest of the original logic for insertion)
            # Find the heading index
            target_idx = -1
            for idx, para in enumerate(doc.paragraphs):
                if heading_text.lower() in para.text.lower():
                    target_idx = idx
                    break
            
            if target_idx != -1:
                try:
                    insert_image_at_section_end(doc, target_idx, image_data, json_data)
                    images_placed += 1
                    break # Move to next image
                except: pass
        for i, paragraph in enumerate(doc.paragraphs):
            text = paragraph.text.strip()

            if heading_text.lower() in text.lower():
                # Check if this is in TOC by looking at context
                is_in_toc = False

                # Check nearby paragraphs for TOC indicators
                for j in range(max(0, i - 5), min(len(doc.paragraphs), i + 5)):
                    nearby_text = doc.paragraphs[j].text
                    if any(indicator in nearby_text for indicator in
                           ["Table of Contents", "List of Figures", "List of Tables", "...", "Page"]):
                        is_in_toc = True
                        break

                if not is_in_toc:
                    # This is likely in actual content
                    try:
                        # Find end of this section
                        section_end = find_end_of_section_from_index(doc, i)
                        if section_end:
                            # Insert image
                            if insert_image_at_section_end(doc, i, image_data, json_data):
                                images_placed += 1
                                print(f"‚úÖ Placed image for '{heading_text}' (avoided TOC)")
                            break
                    except Exception as e:
                        print(f"‚ùå Error inserting image for {heading_text}: {e}")

    return images_placed

def fix_adaptation_plan_section(doc):
    """Fix the 9.1.1 Itemised adaptation plan section with proper table formatting"""
    print("üîß Fixing adaptation plan section formatting...")

    # Look for the specific section
    target_phrase = "Figure 7 below summarises the Adaptation Plan's activities and phased implementation"

    for i, paragraph in enumerate(doc.paragraphs):
        if target_phrase in paragraph.text:
            print(f"‚úÖ Found adaptation plan section at paragraph {i}")

            # Get the full content that's currently split
            full_content = []
            current_idx = i

            # Collect all paragraphs until we find the end of this section
            while current_idx < len(doc.paragraphs):
                current_para = doc.paragraphs[current_idx]
                text = current_para.text.strip()

                if "followed by a more detailed breakdown of the activities in Table 3 below" in text:
                    full_content.append(text)
                    break
                elif text and not text.startswith("|"):  # Don't include table rows
                    full_content.append(text)

                current_idx += 1

            # Reconstruct the proper section
            if len(full_content) >= 2:
                # Clear the original paragraphs
                for j in range(i, current_idx + 1):
                    if j < len(doc.paragraphs):
                        doc.paragraphs[j].clear()

                # Add the main text paragraph
                main_text = "Figure 7 below summarises the Adaptation Plan's activities and phased implementation, drawing on the expertise of the East Hill Farm team and its specialist advisors. It is followed by a more detailed breakdown of the activities in Table 3 below."
                main_para = doc.paragraphs[i]
                main_para.text = main_text

                # Add spacing
                doc.paragraphs[i].insert_paragraph_before()

                # Add the Key table heading
                key_heading = doc.paragraphs[i + 1].insert_paragraph_before("Key")
                key_heading.runs[0].bold = True

                # Create the proper 2-column table
                table = doc.add_table(rows=3, cols=2)
                table.style = None

                # Set column widths
                table.columns[0].width = Inches(1.5)
                table.columns[1].width = Inches(4.5)

                # Header row
                table.cell(0, 0).text = "Line Type"
                table.cell(0, 1).text = "Description"

                # Make header bold
                for cell in table.rows[0].cells:
                    for paragraph in cell.paragraphs:
                        for run in paragraph.runs:
                            run.bold = True

                # Data rows
                table.cell(1, 0).text = "Solid line of any colour"
                table.cell(1, 1).text = "A single \"act and complete\" activity to strengthen resilience."

                table.cell(2, 0).text = "Hatched line of any colour"
                table.cell(2,
                           1).text = "An activity that has a single purpose but may need to be updated several times as climate intensity increases"

                # Format table borders
                for row in table.rows:
                    for cell in row.cells:
                        for paragraph in cell.paragraphs:
                            paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT

                # Add spacing after table
                doc.paragraphs[i + 2].insert_paragraph_before()
                doc.paragraphs[i + 2].insert_paragraph_before()

                # Add RAPA heading
                rapa_heading = doc.paragraphs[i + 3].insert_paragraph_before(
                    "Rapid Adaptation Pathways Assessment (RAPA)")
                rapa_heading.runs[0].bold = True
                rapa_heading.runs[0].font.size = Pt(12)

                print("‚úÖ Fixed adaptation plan section with proper table formatting")
                return True

    print("‚ö†Ô∏è Adaptation plan section not found")
    return False


def generate_rapa_chart(actions, filename="RAPA_Chart.png"):
    """Generate the RAPA chart using matplotlib based on user requirements"""
    print(f"üìä Generating RAPA chart with {len(actions)} actions...")
    
    try:
        # Prepare data with default values since we don't have real thresholds
        # Format: (Action, Start Threshold, End Threshold, Style)
        chart_data = []
        
        # Colors matching user request
        colors = ['#e6a024', '#5db1e4', '#1ea678', '#f1e247', '#0072b2', '#d55e00', '#cc79a7', '#1c1c1c']
        
        for i, action in enumerate(actions):
            # Create synthetic threshold data for visualization
            # Pattern: Alternating visuals to look like a Gantt chart/pathway
            start = 0 + (i % 4) * 0.5
            duration = 1.0 + (i % 3) * 0.5
            end = start + duration
            
            # Cap end at 4.0
            if end > 3.8:
                end = 3.8
                style = "hatched"  # Continuing indefinitely
            elif (i % 5) == 0:
                 style = "hatched"
            else:
                style = "solid"
                
            chart_data.append((action, start, end, style))
            
        # Reverse data so the first item appears at the top
        chart_data = chart_data[::-1]
        
        # Plotting
        fig, ax = plt.subplots(figsize=(12, max(8, len(actions) * 0.5))) # Adjust height based on item count
        
        for i, (action, start, end, style) in enumerate(chart_data):
            color = colors[i % len(colors)]
            hatch = '////' if style == "hatched" else None
            
            # Plot the bar
            width = end - start
            ax.barh(i, width, left=start, color=color, hatch=hatch, edgecolor='black', height=0.7)
            
            # Add arrows and "Continuous improvement" labels for hatched bars
            if style == "hatched":
                ax.annotate('', xy=(end + 0.08, i), xytext=(end, i),
                            arrowprops=dict(arrowstyle='->', lw=1, color='black'))
                # Only add text for some to avoid clutter if too many
                if len(actions) < 20 or (i % 3 == 0):
                    ax.text(end + 0.12, i, 'Continuous improvement', 
                            va='center', fontsize=8, color='#444444', fontstyle='italic')

        # Formatting aesthetics
        ax.set_yticks(range(len(chart_data)))
        
        # Wrap long labels
        wrapped_labels = []
        for d in chart_data:
            label = d[0]
            if len(label) > 50:
                label = label[:47] + "..."
            wrapped_labels.append(label)
            
        ax.set_yticklabels(wrapped_labels)
        ax.set_xlabel('Global warming threshold (¬∞C)', fontsize=11, fontweight='bold')
        ax.set_title('Rapid Adaptation Pathways Assessment (RAPA)', fontsize=14, pad=20)

        # Set x-axis range and clean grid lines
        ax.set_xlim(0, 4.5)
        ax.set_xticks([0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0])
        ax.grid(axis='x', linestyle='--', alpha=0.4, color='gray')
        ax.set_axisbelow(True)

        # Remove the top and right frame borders
        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)

        plt.tight_layout()
        
        # Save
        save_path = os.path.join(UPLOAD_FOLDER, filename)
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close(fig)
        
        print(f"‚úÖ RAPA chart saved to: {save_path}")
        return save_path
        
    except Exception as e:
        print(f"‚ùå Error generating RAPA chart: {e}")
        import traceback
        traceback.print_exc()
        return None


def extract_mural_data_simple():
    """Simple function to run Mural extraction"""
    print("üöÄ Starting Mural extraction...")

    try:
        # Import the main function from your Mural script
        import importlib.util
        import sys

        # Dynamically import the Mural script
        spec = importlib.util.spec_from_file_location("mural_extractor", "get_mural_data_to_excel.py")
        mural_module = importlib.util.module_from_spec(spec)
        sys.modules["mural_extractor"] = mural_module
        spec.loader.exec_module(mural_module)

        # Run the main function
        if hasattr(mural_module, 'main'):
            result = mural_module.main()
            return result
        else:
            print("‚ùå Mural script doesn't have a main() function")
            return None

    except Exception as e:
        print(f"‚ùå Error running Mural extraction: {e}")
        import traceback
        traceback.print_exc()
        return None

# === IMAGE PROCESSING FUNCTIONS ===

def debug_document_structure(doc):
    """Debug function to see document structure"""
    print("\n" + "=" * 60)
    print("DEBUG: Document Structure")
    print("=" * 60)

    for i, paragraph in enumerate(doc.paragraphs[:50]):  # First 50 paragraphs
        text = paragraph.text.strip()
        if text:  # Only show non-empty paragraphs
            style = paragraph.style.name if hasattr(paragraph.style, 'name') else 'No Style'
            print(f"{i:3d} [{style:15}] {text[:80]}{'...' if len(text) > 80 else ''}")

    print("=" * 60)


def debug_custom_section_insertion(doc, custom_sections):
    """Debug function to track custom section insertion"""
    print("\n" + "=" * 60)
    print("üîç DEBUG: Custom Section Insertion")
    print("=" * 60)

    # Find all headings that might be custom sections
    custom_headings = []
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()
        if text and any(text.startswith(f"{num}.") for num in range(13, 20)):
            custom_headings.append((i, text))

    print(f"üìã Found {len(custom_headings)} potential custom section headings:")
    for idx, heading in custom_headings:
        print(f"   Paragraph {idx}: '{heading[:50]}...'")

    # Check for images near custom sections
    for idx, heading in custom_headings:
        print(f"\nüîç Checking images near '{heading[:30]}...'")
        for j in range(max(0, idx - 5), min(idx + 10, len(doc.paragraphs))):
            para = doc.paragraphs[j]
            if hasattr(para, 'runs'):
                for run in para.runs:
                    if run._element.xpath('.//pic:pic'):
                        print(f"   ‚úÖ Found image at paragraph {j}")
                        break

    print("=" * 60)

def debug_document_end(doc):
    """Debug the last 20 paragraphs of the document"""
    print("\n" + "=" * 60)
    print("üîç DEBUG: Last 20 paragraphs of document")
    print("=" * 60)

    start = max(0, len(doc.paragraphs) - 20)
    for i in range(start, len(doc.paragraphs)):
        text = doc.paragraphs[i].text.strip()
        if text:
            style = doc.paragraphs[i].style.name if hasattr(doc.paragraphs[i].style, 'name') else 'No Style'
            print(f"{i:4d} [{style:15}] {text[:80]}{'...' if len(text) > 80 else ''}")

    print("=" * 60)

def debug_find_all_headings(doc):
    """Debug function to find all headings and their positions"""
    print("\n" + "=" * 60)
    print("üîç DEBUG: Finding all headings in document")
    print("=" * 60)

    headings_found = []

    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()
        style = paragraph.style.name if hasattr(paragraph.style, 'name') else 'No Style'

        if style.startswith('Heading') and text:
            headings_found.append((i, style, text))
            print(f"{i:3d} [{style:10}] {text[:80]}")

        # Also show section numbers
        elif text and re.match(r'^\d+\.\s+[A-Z]', text):
            print(f"{i:3d} [Numbered   ] {text[:80]}")

    print(f"\nüìã Total headings found: {len(headings_found)}")
    return headings_found


def debug_find_conclusion_section(doc):
    """Debug function to find the Conclusion section and its surrounding content"""
    print("\n" + "=" * 60)
    print("üîç DEBUG: Finding Conclusion section in document")
    print("=" * 60)

    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()
        if text:
            # Show Conclusion and surrounding paragraphs
            if "Conclusion" in text or (i >= 350 and i <= 450):  # Adjust range based on your document
                style = paragraph.style.name if hasattr(paragraph.style, 'name') else 'No Style'
                print(f"{i:4d} [{style:15}] {text[:80]}{'...' if len(text) > 80 else ''}")

    print("=" * 60)

def debug_find_all_placeholders(doc):
    """Find ALL placeholders in the document to see what actually exists"""
    print("üîç DEBUG: Searching for ALL placeholders in document...")

    all_placeholders = set()

    # Check paragraphs
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text
        # Look for any [[...]] patterns
        matches = re.findall(r'\[\[.*?\]\]', text)
        for match in matches:
            all_placeholders.add(match)
            print(f"üìù Paragraph {i}: Found '{match}'")

    # Check tables
    for table_idx, table in enumerate(doc.tables):
        for row_idx, row in enumerate(table.rows):
            for cell_idx, cell in enumerate(row.cells):
                for para_idx, paragraph in enumerate(cell.paragraphs):
                    text = paragraph.text
                    matches = re.findall(r'\[\[.*?\]\]', text)
                    for match in matches:
                        all_placeholders.add(match)
                        print(f"üìä Table {table_idx}, Cell {cell_idx}: Found '{match}'")

    print(f"üìã ALL PLACEHOLDERS FOUND: {sorted(list(all_placeholders))}")
    return all_placeholders


def identify_figure_number_from_filename(filename):
    """Extract figure number from filename using multiple strategies"""
    filename_lower = filename.lower()

    # Strategy 1: Look for explicit figure patterns
    figure_patterns = [
        r'figure[_\s-]*(\d+)',
        r'fig[_\s-]*(\d+)',
        r'f(\d+)',
        r'image[_\s-]*(\d+)',
        r'chart[_\s-]*(\d+)',
        r'graph[_\s-]*(\d+)'
    ]

    for pattern in figure_patterns:
        match = re.search(pattern, filename_lower)
        if match:
            return int(match.group(1))

    # Strategy 2: Look for numbered patterns at start/end
    numbered_patterns = [
        r'^(\d+)[_\s-]',
        r'[_\s-](\d+)$',
        r'[_\s-](\d+)[_\s-]'
    ]

    for pattern in numbered_patterns:
        match = re.search(pattern, filename_lower)
        if match:
            return int(match.group(1))

    # Strategy 3: Extract first number found
    numbers = re.findall(r'\d+', filename)
    if numbers:
        return int(numbers[0])

    return None


def map_images_to_figures(image_paths):
    """Map uploaded images to their correct figure numbers"""
    figure_mapping = {}

    for image_path in image_paths:
        filename = os.path.basename(image_path)
        figure_number = identify_figure_number_from_filename(filename)

        if figure_number:
            figure_mapping[figure_number] = image_path
            print(f"‚úÖ Mapped '{filename}' to Figure {figure_number}")
        else:
            print(f"‚ö†Ô∏è Could not determine figure number for: {filename}")

    return figure_mapping


def insert_images_by_figure_number_flexible(doc, figure_mapping):
    """Insert images using flexible placeholder matching"""
    if not figure_mapping:
        print("‚ö†Ô∏è No figure mapping provided")
        return False

    print(f"üñºÔ∏è Starting FLEXIBLE image insertion for {len(figure_mapping)} figures...")

    images_placed = 0

    for figure_number, image_path in figure_mapping.items():
        print(f"üéØ Processing Figure {figure_number}: {os.path.basename(image_path)}")

        if not os.path.exists(image_path):
            print(f"‚ö†Ô∏è Image file not found: {image_path}")
            continue

        # Since there are no figure placeholders, we need to insert images at logical locations
        image_placed = insert_figure_at_logical_location(doc, figure_number, image_path)

        if image_placed:
            images_placed += 1
        else:
            # Fallback: add image at end
            try:
                doc.add_page_break()
                # NO HEADING - just insert the image
                image_para = doc.add_paragraph()
                image_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
                run = image_para.add_run()
                run.add_picture(image_path, width=Inches(6.0))
                images_placed += 1
                print(f"‚ö†Ô∏è Added Figure {figure_number} at END as fallback (no heading)")
            except Exception as e:
                print(f"‚ùå Could not add Figure {figure_number} at end: {e}")

    print(f"üìä FLEXIBLE image insertion completed: {images_placed}/{len(figure_mapping)} images placed")
    return images_placed > 0


def insert_figure_at_logical_location(doc, figure_number, image_path):
    """Insert figures at logical locations based on their content"""
    print(f"üìç Looking for logical location for Figure {figure_number}")

    # Map figure numbers to their logical text locations in the document
    figure_locations = {
        1: "hot summer days",
        2: "tropical nights",
        3: "flood risk",
        4: "drought, wind and subsidence risks",
        5: "climate change vulnerability",
        6: "Current and target capabilities",
        7: "Adaptation Plan activities"
    }

    target_text = figure_locations.get(figure_number, f"Figure {figure_number}")

    # Search for the logical location
    for i, paragraph in enumerate(doc.paragraphs):
        if target_text.lower() in paragraph.text.lower():
            print(f"‚úÖ Found logical location for Figure {figure_number} at paragraph {i}")

            try:
                # Insert image after this paragraph
                image_para = doc.paragraphs[i].insert_paragraph_before()
                image_para.alignment = WD_ALIGN_PARAGRAPH.CENTER

                # Add the image (NO HEADING/CAPTION)
                run = image_para.add_run()
                run.add_picture(image_path, width=Inches(6.0))

                # NO CAPTION ADDED - document already has proper figure captions

                print(f"‚úÖ SUCCESS: Inserted Figure {figure_number} at logical location (no heading)")
                return True

            except Exception as e:
                print(f"‚ùå Error inserting Figure {figure_number}: {e}")
                return False

    print(f"‚ö†Ô∏è Could not find logical location for Figure {figure_number}")
    return False


# ... continue with your existing image functions below ...

def find_figure_placeholders_in_doc(doc):
    """Find all figure placeholders that actually exist in the document"""
    print("üîç Finding actual figure placeholders in document...")

    # All possible figure placeholder variations
    possible_placeholders = [
        # Full image file placeholders
        "[[Figure-1_Change-in-Hot-Summer-Days.png]]",
        "[[Figure-2_Change-in-tropical-nights.png]]",
        "[[Figure-3_Changing-flood-risk.png]]",
        "[[Figure-4_Changing-drought-wind-and-subsidence-risks.png]]",
        "[[Figure-5_Components-of-climate-change-vulnerability.png]]",
        "[[Figure-6_Current-and-target-capabilities.png]]",
        "[[Figure-7_Adaptation-Plan-activities-and-phased-implementation-pathways.png]]",

        # Simplified placeholders (without .png)
        "[[Figure-1_Change-in-Hot-Summer-Days]]",
        "[[Figure-2_Change-in-tropical-nights]]",
        "[[Figure-3_Changing-flood-risk]]",
        "[[Figure-4_Changing-drought-wind-and-subsidence-risks]]",
        "[[Figure-5_Components-of-climate-change-vulnerability]]",
        "[[Figure-6_Current-and-target-capabilities]]",
        "[[Figure-7_Adaptation-Plan-activities-and-phased-implementation-pathways]]",

        # Even simpler placeholders
        "[[Figure-1]]",
        "[[Figure-2]]",
        "[[Figure-3]]",
        "[[Figure-4]]",
        "[[Figure-5]]",
        "[[Figure-6]]",
        "[[Figure-7]]",

        # Text-based placeholders
        "[[Figure 1]]",
        "[[Figure 2]]",
        "[[Figure 3]]",
        "[[Figure 4]]",
        "[[Figure 5]]",
        "[[Figure 6]]",
        "[[Figure 7]]"
    ]

    found_placeholders = {}

    for placeholder in possible_placeholders:
        for i, paragraph in enumerate(doc.paragraphs):
            if placeholder in paragraph.text:
                found_placeholders[placeholder] = i
                print(f"‚úÖ Found: '{placeholder}' at paragraph {i}")
                break

    print(f"üìã ACTUAL FIGURE PLACEHOLDERS FOUND: {list(found_placeholders.keys())}")
    return found_placeholders

def insert_images_by_figure_number(doc, figure_mapping):
    """Insert images at their specific placeholder locations based on figure number"""
    if not figure_mapping:
        print("‚ö†Ô∏è No figure mapping provided")
        return False

    print(f"üñºÔ∏è Starting image insertion for {len(figure_mapping)} mapped figures...")

    # Map figure numbers to their specific placeholders
    figure_to_placeholder = {
        1: "[[Figure-1_Change-in-Hot-Summer-Days.png]]",
        2: "[[Figure-2_Change-in-tropical-nights.png]]",
        3: "[[Figure-3_Changing-flood-risk.png]]",
        4: "[[Figure-4_Changing-drought-wind-and-subsidence-risks.png]]",
        5: "[[Figure-5_Components-of-climate-change-vulnerability.png]]",
        6: "[[Figure-6_Current-and-target-capabilities.png]]",
        7: "[[Figure-7_Adaptation-Plan-activities-and-phased-implementation-pathways.png]]"
    }

    images_placed = 0

    for figure_number, image_path in figure_mapping.items():
        placeholder = figure_to_placeholder.get(figure_number)

        if not placeholder:
            print(f"‚ö†Ô∏è No placeholder mapping for Figure {figure_number}")
            continue

        if not os.path.exists(image_path):
            print(f"‚ö†Ô∏è Image file not found: {image_path}")
            continue

        print(f"üîç Looking for placeholder: {placeholder} for Figure {figure_number}")
        image_placed = False

        # Search through all paragraphs for the exact placeholder
        for i, paragraph in enumerate(doc.paragraphs):
            if placeholder in paragraph.text:
                print(f"‚úÖ Found placeholder for Figure {figure_number} at paragraph {i}")

                try:
                    # Clear the placeholder and insert image
                    paragraph.clear()
                    paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER

                    # Add the image
                    run = paragraph.add_run()
                    run.add_picture(image_path, width=Inches(6.0))

                    # Add spacing after image
                    paragraph._p.addnext(parse_xml(
                        '<w:p xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main"><w:pPr><w:spacing w:before="120" w:after="120"/></w:pPr></w:p>'))

                    images_placed += 1
                    image_placed = True
                    print(f"‚úÖ Successfully inserted Figure {figure_number} at correct placeholder")
                    break

                except Exception as e:
                    print(f"‚ùå Error inserting Figure {figure_number}: {e}")
                    # Add placeholder text as fallback
                    paragraph.text = f"[Image: Figure {figure_number} - {os.path.basename(image_path)}]"
                    images_placed += 1
                    image_placed = True
                    break

        if not image_placed:
            print(f"‚ö†Ô∏è Could not find placeholder for Figure {figure_number}: {placeholder}")
            # Fallback: add image at end with correct figure number
            try:
                doc.add_paragraph().add_run(f"Figure {figure_number}:").bold = True
                image_para = doc.add_paragraph()
                image_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
                run = image_para.add_run()
                run.add_picture(image_path, width=Inches(6.0))
                images_placed += 1
                print(f"‚úÖ Added Figure {figure_number} at end as fallback")
            except Exception as e:
                print(f"‚ùå Could not add Figure {figure_number} at end: {e}")

    print(f"üìä Image insertion completed: {images_placed}/{len(figure_mapping)} images placed correctly")
    return images_placed > 0

def ensure_image_placeholders_exist(doc):
    """Ensure all required image placeholders exist in the document"""
    print("üîç Checking for image placeholders in document...")

    required_figure_placeholders = [
        "[[Figure-1_Change-in-Hot-Summer-Days.png]]",
        "[[Figure-2_Change-in-tropical-nights.png]]",
        "[[Figure-3_Changing-flood-risk.png]]",
        "[[Figure-4_Changing-drought-wind-and-subsidence-risks.png]]",
        "[[Figure-5_Components-of-climate-change-vulnerability.png]]",
        "[[Figure-6_Current-and-target-capabilities.png]]",
        "[[Figure-7_Adaptation-Plan-activities-and-phased-implementation-pathways.png]]"
    ]

    # Check which placeholders exist
    existing_placeholders = {}
    for placeholder in required_figure_placeholders:
        found = False
        for paragraph in doc.paragraphs:
            if placeholder in paragraph.text:
                found = True
                break
        existing_placeholders[placeholder] = found
        if not found:
            print(f"‚ö†Ô∏è Missing image placeholder: {placeholder}")

    return existing_placeholders


def insert_images_at_exact_placeholders(doc, image_paths):
    """Insert images at their specific placeholder locations"""
    if not image_paths:
        print("‚ö†Ô∏è No images provided for insertion")
        return False

    print(f"üñºÔ∏è Starting image insertion for {len(image_paths)} images...")

    # Map figure numbers to their specific placeholders
    figure_to_placeholder = {
        1: "[[Figure-1_Change-in-Hot-Summer-Days.png]]",
        2: "[[Figure-2_Change-in-tropical-nights.png]]",
        3: "[[Figure-3_Changing-flood-risk.png]]",
        4: "[[Figure-4_Changing-drought-wind-and-subsidence-risks.png]]",
        5: "[[Figure-5_Components-of-climate-change-vulnerability.png]]",
        6: "[[Figure-6_Current-and-target-capabilities.png]]",
        7: "[[Figure-7_Adaptation-Plan-activities-and-phased-implementation-pathways.png]]"
    }

    images_placed = 0

    for image_index, image_path in enumerate(image_paths):
        figure_number = image_index + 1
        placeholder = figure_to_placeholder.get(figure_number)

        if not placeholder:
            print(f"‚ö†Ô∏è No placeholder mapping for image {figure_number}")
            continue

        if not os.path.exists(image_path):
            print(f"‚ö†Ô∏è Image file not found: {image_path}")
            continue

        print(f"üîç Looking for placeholder: {placeholder}")
        image_placed = False

        # Search through all paragraphs for the exact placeholder
        for i, paragraph in enumerate(doc.paragraphs):
            if placeholder in paragraph.text:
                print(f"‚úÖ Found placeholder for Figure {figure_number} at paragraph {i}")

                try:
                    # Clear the placeholder and insert image
                    paragraph.clear()
                    paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER

                    # Add the image
                    run = paragraph.add_run()
                    run.add_picture(image_path, width=Inches(6.0))

                    # Add spacing after image
                    paragraph._p.addnext(parse_xml(
                        '<w:p xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main"><w:pPr><w:spacing w:before="120" w:after="120"/></w:pPr></w:p>'))

                    images_placed += 1
                    image_placed = True
                    print(f"‚úÖ Successfully inserted Figure {figure_number}")
                    break

                except Exception as e:
                    print(f"‚ùå Error inserting image {figure_number}: {e}")
                    # Add placeholder text as fallback
                    paragraph.text = f"[Image: Figure {figure_number} - {os.path.basename(image_path)}]"
                    images_placed += 1
                    image_placed = True
                    break

        if not image_placed:
            print(f"‚ö†Ô∏è Could not find placeholder for Figure {figure_number}: {placeholder}")
            # Fallback: add image at end with caption
            try:
                doc.add_paragraph().add_run(f"Figure {figure_number}:").bold = True
                image_para = doc.add_paragraph()
                image_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
                run = image_para.add_run()
                run.add_picture(image_path, width=Inches(6.0))
                images_placed += 1
                print(f"‚úÖ Added Figure {figure_number} at end as fallback")
            except Exception as e:
                print(f"‚ùå Could not add Figure {figure_number} at end: {e}")

    print(f"üìä Image insertion completed: {images_placed}/{len(image_paths)} images placed")
    return images_placed > 0


def fix_executive_summary_headings(doc):
    """Fix Executive Summary headings that might be broken"""
    print("üîß Fixing Executive Summary headings...")

    # Look for the "1.1" paragraph - but check for placeholders first
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()

        # Check if this is a heading placeholder
        if text == "1.1" or text.startswith("1.1 ") or text == "1.1\t":
            print(f"‚úÖ Found '1.1' heading at paragraph {i}")

            # Check what comes after - we want "Why this plan and what it delivers"
            is_followed_by_bullets = False
            next_text = ""
            if i + 1 < len(doc.paragraphs):
                next_text = doc.paragraphs[i + 1].text.strip()

                # Check if next paragraph contains the bullet content
                bullet_patterns = ["Regulatory alignment:", "Actionable pathway:", "Continuous improvement:"]
                is_followed_by_bullets = any(pattern in next_text for pattern in bullet_patterns)

            if is_followed_by_bullets:
                # This is the correct location for "1.1 Why this plan and what it delivers"
                paragraph.text = "Why this plan and what it delivers"
                print(f"‚úÖ Set 'Why this plan and what it delivers' at paragraph {i}")
            elif "Why this plan" in next_text:
                # Merge them
                paragraph.text = "Why this plan and what it delivers"
                doc.paragraphs[i + 1].text = ""  # Clear the duplicate
                print(f"‚úÖ Merged with next paragraph")

        # Also fix any standalone "Why this plan" text
        elif "Why this plan" in text and not text.startswith("1.1"):
            # Check if previous paragraph is "1.1"
            if i > 0 and doc.paragraphs[i - 1].text.strip() in ["1.1", "1.1 ", "1.1\t"]:
                # Merge with previous
                doc.paragraphs[i - 1].text = "Why this plan and what it delivers"
                paragraph.text = ""
                print(f"‚úÖ Merged 'Why this plan' with previous '1.1'")
            else:
                # Add the "1.1" prefix
                paragraph.text = f" {text}"
                print(f"‚úÖ Added '' prefix to paragraph {i}")

    return True

def remove_figure_placeholders_only_after_processing(doc):
    """Remove ONLY figure placeholders that weren't replaced (run this after all processing)"""
    print("üóëÔ∏è Cleaning up unused figure placeholders...")

    figure_placeholders = [
        "[[Figure-1_Change-in-Hot-Summer-Days.png]]",
        "[[Figure-1]]",
        "[[Table 5: East Higher Dairy maritime development Climate Adaptive Capacity Development Actions by Implementation Phase]]",
        'Figure 2: Change in "tropical nights" (over 20¬∫C) for Republic of Fiji (Source Met Office Local Authority Climate Service 2025)',
        "[[Figure-2_Change-in-tropical-nights.png]]",
        "[[Figure-2_Climate-Records-Nov-2025_Met-Fiji]]",
        "[[Figure-3_Changing-flood-risk.png]]",
        "[[Figure-4_Changing-drought-wind-and-subsidence-risks.png]]",
        "[[Figure-5_Components-of-climate-change-vulnerability.png]]",
        "[[Figure-6_Current-and-target-capabilities.png]]",
        "[[Figure-7_Adaptation-Plan-activities-and-phased-implementation-pathways.png]]"
    ]

    removed_count = 0

    for paragraph in doc.paragraphs:
        for placeholder in figure_placeholders:
            if placeholder in paragraph.text:
                # Only remove if it's a standalone placeholder (not part of actual content)
                if paragraph.text.strip() == placeholder:
                    paragraph.text = ""
                    removed_count += 1
                    print(f"‚úÖ Removed unused figure placeholder: {placeholder}")

    print(f"üóëÔ∏è Removed {removed_count} unused figure placeholders")
    return removed_count


# ===== CUSTOM SECTIONS FUNCTIONS =====

def process_custom_sections(request_form, request_files):
    """Process and collect custom sections from form data"""
    print("üìù Processing custom sections...")

    custom_sections = []

    # Collect all custom sections from form
    i = 0
    while True:
        title_key = f"custom_section_title_{i}"
        content_key = f"custom_section_content_{i}"
        level_key = f"custom_section_level_{i}"
        include_key = f"custom_section_include_{i}"

        # Check if this section exists
        if title_key not in request_form and content_key not in request_form:
            break

        title = request_form.get(title_key, "").strip()
        content = request_form.get(content_key, "").strip()
        level = int(request_form.get(level_key, 2))  # Default to Heading 2
        include = include_key in request_form  # Checkbox

        if title and content and include:
            section_data = {
                "title": title,
                "content": content,
                "level": level,
                "image_file": None
            }

            # Handle image for this section if provided
            image_key = f"custom_section_image_{i}"
            if image_key in request_files:
                image_file = request_files[image_key]
                if image_file and image_file.filename and allowed_file(image_file.filename):
                    section_data["image_file"] = image_file
                    print(f"üì∏ Found image for custom section {i}: {image_file.filename}")

            custom_sections.append(section_data)
            print(f"üìù Found custom section {i}: '{title[:50]}...' (level {level})")

        i += 1

    print(f"üìã Total custom sections to insert: {len(custom_sections)}")
    return custom_sections


def verify_custom_sections_placement(doc):
    """Verify that custom sections are placed correctly in the document"""
    print("\n" + "=" * 60)
    print("‚úÖ VERIFYING CUSTOM SECTIONS PLACEMENT")
    print("=" * 60)

    # Look for custom section headings (starting with 13., 14., etc.)
    custom_sections_found = []

    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()

        # Look for custom section headings
        if re.match(r'^(1[3-9]|[2-9]\d+)\.', text):
            custom_sections_found.append((i, text))
            print(f"‚úÖ Found custom section at paragraph {i}: '{text[:50]}...'")

            # Check what comes before it
            if i > 0:
                prev_text = doc.paragraphs[i - 1].text.strip()
                print(f"   Previous paragraph: '{prev_text[:50]}...'")

            # Check what comes after it
            if i < len(doc.paragraphs) - 1:
                next_text = doc.paragraphs[i + 1].text.strip()
                print(f"   Next paragraph: '{next_text[:50]}...'")

    if not custom_sections_found:
        print("‚ö†Ô∏è No custom sections found in the document!")

    print("=" * 60)
    return len(custom_sections_found) > 0


def insert_custom_sections(doc, custom_sections, json_data):
    """Insert custom sections into the document AFTER Conclusion and Next Steps (Section 11)"""
    if not custom_sections:
        print("‚ÑπÔ∏è No custom sections to insert")
        return False
    print(f"üìù Inserting {len(custom_sections)} custom sections AFTER 'Conclusion and Next Steps'...")

    # Find the EXACT location of "Conclusion and Next Steps" heading
    target_heading = "Conclusion and Next Steps"
    conclusion_index = -1

    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()

        # Look for the exact heading "Conclusion and Next Steps"
        if target_heading.lower() in text.lower():
            # Check if it's a main heading (not in TOC)
            is_heading = (
                    paragraph.style.name.startswith('Heading') or
                    text == target_heading or
                    (len(text.split()) <= 5 and text[0].isupper())
            )

            if is_heading:
                conclusion_index = i
                print(f"‚úÖ Found ACTUAL '{target_heading}' heading at paragraph {i}")
                break

    if conclusion_index == -1:
        # Try to find any conclusion-like text
        for i, paragraph in enumerate(doc.paragraphs):
            text = paragraph.text.strip()
            if "Conclusion" in text and "Next Steps" in text and len(text) < 100:
                conclusion_index = i
                print(f"üîÑ Found conclusion-like heading at paragraph {i}")
                break

    if conclusion_index == -1:
        print("‚ùå Could not find conclusion section!")
        return False

    # Find where the conclusion section ENDS
    conclusion_end_index = find_end_of_section_from_index(doc, conclusion_index)

    if conclusion_end_index is None or conclusion_end_index <= conclusion_index:
        conclusion_end_index = min(conclusion_index + 20, len(doc.paragraphs) - 1)

    print(f"üìç Conclusion section ends at paragraph {conclusion_end_index}")

    # Create a clean insertion point by adding a new paragraph at the end of conclusion
    # First, ensure we have a clean paragraph to insert before
    clean_insertion_point = conclusion_end_index

    # If the paragraph at insertion point has content, insert an empty paragraph first
    if clean_insertion_point < len(doc.paragraphs) and doc.paragraphs[clean_insertion_point].text.strip():
        # Insert an empty paragraph to create clean insertion point
        doc.paragraphs[clean_insertion_point].insert_paragraph_before("")
        clean_insertion_point += 1  # Adjust insertion point

    # Now insert page break before this clean paragraph
    if clean_insertion_point < len(doc.paragraphs):
        page_break_para = doc.paragraphs[clean_insertion_point].insert_paragraph_before()
        page_break_run = page_break_para.add_run()
        page_break_run.add_break(WD_BREAK.PAGE)
        print("üìÑ Added page break before custom sections")

    # Start inserting custom sections
    sections_added = 0
    starting_section_num = 12  # Custom sections start at 12 (after section 11)

    for section_idx, section in enumerate(custom_sections):
        try:
            # Calculate the section number
            section_num = starting_section_num + section_idx

            # Determine section numbering with PROPER TAB FORMATTING
            if section["level"] == 1:
                # Main section: 12, 13, 14, etc. - TAB BETWEEN NUMBER AND TITLE
                heading_number = str(section_num)
                heading_text = f"{heading_number}\t{section['title']}"
            else:
                # Sub-section: 12.1, 12.2, etc. - TAB BETWEEN NUMBER AND TITLE
                heading_number = f"{section_num}.{section['level'] - 1}"
                heading_text = f"{heading_number}\t{section['title']}"

            print(f"üìù Adding custom section {heading_number}: {section['title'][:30]}...")

            # Get the current insertion point
            current_insertion = clean_insertion_point + (section_idx * 10)

            # Make sure we have a valid insertion point
            if current_insertion >= len(doc.paragraphs):
                # Add paragraphs at the end
                while len(doc.paragraphs) <= current_insertion:
                    doc.add_paragraph("")
                current_insertion = len(doc.paragraphs) - 1

            # ===== STEP 1: CREATE AN EMPTY PARAGRAPH AS ANCHOR =====
            # First create an empty paragraph at the insertion point
            anchor_para = doc.paragraphs[current_insertion].insert_paragraph_before("")

            # ===== STEP 2: ADD HEADING (FIRST) =====
            # Add spacing before heading (24pt for first section, 18pt for others)
            spacing_before = anchor_para.insert_paragraph_before()
            spacing_before.paragraph_format.space_before = Pt(24 if section_idx == 0 else 18)

            # Add the heading WITH TAB FORMATTING
            heading_para = anchor_para.insert_paragraph_before(heading_text)
            print(f"‚úÖ Created heading: '{heading_text}'")

            # Format heading properly with bold and proper font
            heading_para.style = "Normal"

            # Split the heading into number and title parts at the tab
            if "\t" in heading_text:
                num_part, title_part = heading_text.split("\t", 1)
            else:
                num_part = heading_text
                title_part = ""

            # Clear existing runs and add formatted text
            heading_para.clear()

            # Add number part (bold)
            num_run = heading_para.add_run(num_part)
            num_run.bold = True
            num_run.font.name = "Calibri"
            num_run.font.size = Pt(14)

            # Add tab
            tab_run = heading_para.add_run("\t")

            # Add title part (bold)
            if title_part:
                title_run = heading_para.add_run(title_part)
                title_run.bold = True
                title_run.font.name = "Calibri"
                title_run.font.size = Pt(14)

            # Ensure proper alignment - left aligned with tab
            heading_para.alignment = WD_ALIGN_PARAGRAPH.LEFT
            heading_para.paragraph_format.left_indent = Inches(0)  # No indent for main sections
            heading_para.paragraph_format.first_line_indent = Inches(0)

            # Add spacing after heading
            spacing_after_heading = anchor_para.insert_paragraph_before()
            spacing_after_heading.paragraph_format.space_after = Pt(12)

            # ===== STEP 3: ADD CONTENT TEXT (SECOND) =====
            content_lines = section["content"].strip().split('\n')
            content_added = False

            # Add content lines in NORMAL order (not reversed)
            for line in content_lines:
                if line.strip():
                    content_para = anchor_para.insert_paragraph_before(line.strip())
                    content_para.style = "Normal"

                    # Format paragraph
                    content_para.paragraph_format.space_after = Pt(6)
                    content_para.paragraph_format.line_spacing = 1.15
                    content_para.alignment = WD_ALIGN_PARAGRAPH.LEFT

                    # Format text
                    for run in content_para.runs:
                        run.font.name = "Calibri"
                        run.font.size = Pt(11)

                    # Handle bullet points
                    line_text = line.strip()
                    if line_text.startswith(('‚Ä¢', '-', '*')):
                        content_para.paragraph_format.left_indent = Inches(0.3)
                        content_para.paragraph_format.first_line_indent = Inches(-0.3)

                        # Replace dashes with proper bullets
                        if line_text.startswith('- '):
                            content_para.text = '‚Ä¢ ' + line_text[2:]
                        elif line_text.startswith('* '):
                            content_para.text = '‚Ä¢ ' + line_text[2:]

                    content_added = True

            # If no content was added, add a placeholder
            if not content_added:
                placeholder_para = anchor_para.insert_paragraph_before(
                    "this is for testing - middle")
                placeholder_para.style = "Normal"
                placeholder_para.alignment = WD_ALIGN_PARAGRAPH.LEFT
                placeholder_para.runs[0].font.name = "Calibri"
                placeholder_para.runs[0].font.size = Pt(11)

            # ===== STEP 4: ADD IMAGE AND CAPTION (THIRD AND FOURTH) =====
            image_added = False
            if "image_file" in section and section["image_file"]:
                try:
                    # Save the image file
                    image_file = section["image_file"]
                    filename = secure_filename(
                        f"custom_section_{section_idx}_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{image_file.filename}"
                    )
                    image_path = os.path.join(UPLOAD_FOLDER, filename)
                    image_file.save(image_path)

                    print(f"üñºÔ∏è Saved image for custom section: {filename}")

                    # Add spacing before image
                    spacing_before_img = anchor_para.insert_paragraph_before()
                    spacing_before_img.paragraph_format.space_before = Pt(24)

                    # Insert the image (centered) - inserted BEFORE caption
                    image_para = anchor_para.insert_paragraph_before()
                    image_para.alignment = WD_ALIGN_PARAGRAPH.CENTER

                    run = image_para.add_run()
                    try:
                        # Try to insert the image
                        run.add_picture(image_path, width=Inches(4.0))
                        print(f"‚úÖ Inserted image: {filename}")
                    except Exception as img_error:
                        print(f"‚ö†Ô∏è Error adding picture: {img_error}")
                        # Add placeholder text instead
                        image_para.text = f"[Image: {filename}]"
                        image_para.alignment = WD_ALIGN_PARAGRAPH.CENTER

                    # Add image caption (centered, italic) - inserted AFTER image
                    caption_text = f"Figure: {section['title']} -end"
                    caption_para = anchor_para.insert_paragraph_before(caption_text)
                    caption_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
                    caption_para.style = "Normal"

                    if caption_para.runs:
                        caption_para.runs[0].italic = True
                        caption_para.runs[0].font.size = Pt(10)
                        caption_para.runs[0].font.name = "Calibri"

                    # Add spacing after image caption
                    spacing_after_img = anchor_para.insert_paragraph_before()
                    spacing_after_img.paragraph_format.space_after = Pt(18)

                    image_added = True

                except Exception as img_error:
                    print(f"‚ö†Ô∏è Error processing image for custom section: {img_error}")
                    # Add error message
                    error_para = anchor_para.insert_paragraph_before(
                        f"[Error loading image: {str(img_error)}]"
                    )
                    error_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
                    error_para.runs[0].font.color.rgb = RGBColor(255, 0, 0)

            # Remove the anchor paragraph we created
            anchor_element = anchor_para._element
            anchor_element.getparent().remove(anchor_element)

            # Add spacing between sections (but not after the last one)
            if section_idx < len(custom_sections) - 1:
                spacing_between = anchor_para.insert_paragraph_before()
                spacing_between.paragraph_format.space_after = Pt(24)

            sections_added += 1
            print(f"‚úÖ Added custom section {heading_number}")

        except Exception as e:
            print(f"‚ö†Ô∏è Error inserting custom section {section_idx}: {e}")
            import traceback
            traceback.print_exc()

    # Update  v TOC to include custom sections
    if sections_added > 0:
        update_toc_with_custom_sections(doc, custom_sections, starting_section_num)
        print(f"‚úÖ Updated TOC with {sections_added} custom sections")

    print(f"üìä Added {sections_added} custom sections after Conclusion")
    return sections_added > 0


def update_toc_with_custom_sections(doc, custom_sections, starting_section_num):
    """Update TOC to include custom sections with proper page numbers BEFORE Appendices"""
    print("üìã Updating TOC with custom sections...")

    if not custom_sections:
        print("‚ÑπÔ∏è No custom sections to add to TOC")
        return False

    # Find where to insert in TOC - we want custom sections BEFORE Appendices
    conclusion_toc_index = -1
    appendices_toc_index = -1
    in_toc = False

    # First find "Conclusion and Next Steps" and "Appendices" in TOC
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()

        if "Table of Contents" in text and not in_toc:
            in_toc = True
            print(f"‚úÖ Found TOC start at paragraph {i}")
            continue

        if in_toc:
            # Look for "Conclusion and Next Steps" in TOC
            if "Conclusion and Next Steps" in text and conclusion_toc_index == -1:
                conclusion_toc_index = i
                print(f"‚úÖ Found 'Conclusion and Next Steps' in TOC at paragraph {i}")

            # Look for "Appendices" in TOC (this is where custom sections should go BEFORE)
            if "Appendices" in text and appendices_toc_index == -1:
                appendices_toc_index = i
                print(f"‚úÖ Found 'Appendices' in TOC at paragraph {i}")
                break

    # Determine insertion point
    if appendices_toc_index != -1:
        # Insert custom sections BEFORE Appendices
        insertion_index = appendices_toc_index
        print(f"üìç Will insert custom sections BEFORE Appendices at paragraph {insertion_index}")
    elif conclusion_toc_index != -1:
        # Insert after Conclusion if Appendices not found
        insertion_index = conclusion_toc_index + 1
        print(f"üìç Will insert custom sections after Conclusion at paragraph {insertion_index}")
    else:
        # Fallback: find end of TOC
        for i, paragraph in enumerate(doc.paragraphs):
            if "List of Figures" in paragraph.text or "List of Tables" in paragraph.text:
                insertion_index = i
                print(f"üìç Will insert custom sections before LOF/LOT at paragraph {insertion_index}")
                break
        else:
            insertion_index = len(doc.paragraphs) - 1
            print(f"‚ö†Ô∏è Using end of document at paragraph {insertion_index}")

    # Add spacing before custom sections in TOC
    if insertion_index < len(doc.paragraphs):
        spacing_para = doc.paragraphs[insertion_index].insert_paragraph_before()
        spacing_para.paragraph_format.space_before = Pt(12)

    custom_sections_added = 0

    # Add each custom section to TOC
    for section_idx, section in enumerate(custom_sections):
        section_num = starting_section_num + section_idx
        page_num = 45 + (section_idx * 2)  # Custom sections start around page 45

        # Determine section text based on level
        if section["level"] == 1:
            section_text = f"{section_num}. {section['title']}"
        else:
            # For sub-sections: 13.1, 13.2, etc.
            subsection_num = section_idx + 1
            section_text = f"{section_num}.{subsection_num} {section['title']}"

        # Create TOC entry
        toc_para = doc.paragraphs[insertion_index].insert_paragraph_before()
        toc_para.alignment = WD_ALIGN_PARAGRAPH.LEFT

        # Set indentation based on heading level
        indent_level = section["level"] - 1  # Level 1 = no indent, Level 2 = indent, etc.
        toc_para.paragraph_format.left_indent = Inches(0.3 * indent_level)
        toc_para.paragraph_format.space_after = Pt(6)

        # Add section number and title
        text_run = toc_para.add_run(section_text)
        text_run.font.name = "Calibri"
        text_run.font.size = Pt(10)

        # Calculate space for dots (80 chars total width)
        text_length = len(section_text)
        remaining_space = 80 - text_length - (indent_level * 2)  # Account for indent

        if remaining_space > 5:
            # Add leader dots
            dots_text = " " + "." * remaining_space + " "
            dots_run = toc_para.add_run(dots_text)
            dots_run.font.name = "Calibri"
            dots_run.font.size = Pt(8)

            # Add page number
            page_run = toc_para.add_run(str(page_num))
            page_run.bold = True
            page_run.font.name = "Calibri"
            page_run.font.size = Pt(10)

            custom_sections_added += 1
            print(f"‚úÖ Added TOC entry: {section_text} ... page {page_num}")

    print(f"üìã Added {custom_sections_added} custom sections to TOC BEFORE Appendices")
    return custom_sections_added > 0

# ---------------- DROPBOX TOKEN MANAGEMENT FUNCTIONS ----------------

def get_dropbox_token():
    """Get or refresh Dropbox access token using refresh token"""
    print("üîë Getting Dropbox access token...")

    refresh_token = os.environ.get("DROPBOX_REFRESH_TOKEN")
    app_key = os.environ.get("DROPBOX_APP_KEY")
    app_secret = os.environ.get("DROPBOX_APP_SECRET")

    if not all([refresh_token, app_key, app_secret]):
        print("‚ùå Missing Dropbox credentials in .env")
        print(f"   REFRESH_TOKEN: {'‚úÖ' if refresh_token else '‚ùå'}")
        print(f"   APP_KEY: {'‚úÖ' if app_key else '‚ùå'}")
        print(f"   APP_SECRET: {'‚úÖ' if app_secret else '‚ùå'}")
        return None

    try:
        print(f"üîÑ Refreshing token with App Key: {app_key[:10]}...")

        response = requests.post(
            "https://api.dropbox.com/oauth2/token",
            data={
                'grant_type': 'refresh_token',
                'refresh_token': refresh_token,
                'client_id': app_key,
                'client_secret': app_secret
            },
            headers={'Content-Type': 'application/x-www-form-urlencoded'},
            timeout=30
        )

        print(f"üìä Response: {response.status_code}")

        if response.status_code == 200:
            tokens = response.json()
            new_access_token = tokens.get('access_token')

            if new_access_token:
                # Store in environment variable
                os.environ["DROPBOX_TOKEN"] = new_access_token
                print(f"‚úÖ Got new access token ({len(new_access_token)} chars)")
                print(f"   Token: {new_access_token[:30]}...")
                print(f"   Expires in: {tokens.get('expires_in', '?')} seconds")
                return new_access_token
            else:
                print("‚ùå No access token in response")
                return None
        else:
            print(f"‚ùå Token refresh failed: {response.status_code}")
            print(f"   Error: {response.text[:200]}")
            return None

    except Exception as e:
        print(f"‚ùå Error getting token: {e}")
        import traceback
        traceback.print_exc()
        return None


def initialize_dropbox():
    """Initialize Dropbox client with automatic token refresh"""
    global dbx

    print("üîß Initializing Dropbox client...")

    # First, get a fresh access token
    access_token = get_dropbox_token()

    if not access_token:
        print("‚ùå Could not get Dropbox access token")
        return None

    try:
        # Create Dropbox client
        dbx = dropbox.Dropbox(
            access_token,
            timeout=30,
            user_agent="FlaskReport/1.0"
        )

        # Test the connection
        print("üîó Testing Dropbox connection...")
        account = dbx.users_get_current_account()

        print(f"‚úÖ Dropbox initialized successfully!")
        print(f"   Connected as: {account.name.display_name}")
        print(f"   Email: {account.email}")

        return dbx

    except dropbox.exceptions.AuthError as e:
        print(f"‚ùå Authentication error: {e}")
        print("üîÑ Token might be invalid, trying to refresh...")

        # Try to get a new token
        new_token = get_dropbox_token()
        if new_token:
            try:
                dbx = dropbox.Dropbox(new_token)
                account = dbx.users_get_current_account()
                print(f"‚úÖ Reconnected: {account.name.display_name}")
                return dbx
            except Exception as e2:
                print(f"‚ùå Reconnection failed: {e2}")
                return None
        else:
            return None

    except Exception as e:
        print(f"‚ùå Dropbox initialization failed: {e}")
        import traceback
        traceback.print_exc()
        return None


def upload_to_dropbox(local_path, dropbox_path):
    """Upload a file to Dropbox with automatic token refresh"""
    global dbx

    print(f"\nüì§ Uploading to Dropbox...")
    print(f"   Local: {os.path.basename(local_path)}")
    print(f"   Remote: {dropbox_path}")

    # Initialize Dropbox if needed
    if dbx is None:
        dbx = initialize_dropbox()
        if dbx is None:
            print("‚ùå Dropbox not available for upload")
            return False

    # Check if file exists
    if not os.path.exists(local_path):
        print(f"‚ùå File not found: {local_path}")
        return False

    file_size = os.path.getsize(local_path)
    print(f"   Size: {file_size / 1024:.1f} KB")

    try:
        # Upload the file
        with open(local_path, 'rb') as f:
            if file_size <= 150 * 1024 * 1024:  # 150MB limit for simple upload
                dbx.files_upload(
                    f.read(),
                    dropbox_path,
                    mode=dropbox.files.WriteMode("overwrite")
                )
            else:
                # For large files, use chunked upload
                CHUNK_SIZE = 4 * 1024 * 1024  # 4MB chunks

                upload_session_start_result = dbx.files_upload_session_start(f.read(CHUNK_SIZE))
                cursor = dropbox.files.UploadSessionCursor(
                    session_id=upload_session_start_result.session_id,
                    offset=f.tell()
                )
                commit = dropbox.files.CommitInfo(path=dropbox_path, mode=dropbox.files.WriteMode("overwrite"))

                while f.tell() < file_size:
                    if (file_size - f.tell()) <= CHUNK_SIZE:
                        dbx.files_upload_session_finish(f.read(CHUNK_SIZE), cursor, commit)
                    else:
                        dbx.files_upload_session_append_v2(f.read(CHUNK_SIZE), cursor)
                        cursor.offset = f.tell()

        print(f"‚úÖ Successfully uploaded to Dropbox")
        return True

    except dropbox.exceptions.AuthError:
        print("üîÑ Token expired during upload, refreshing...")

        # Get new token and retry
        new_token = get_dropbox_token()
        if new_token:
            try:
                dbx = dropbox.Dropbox(new_token)
                with open(local_path, 'rb') as f:
                    dbx.files_upload(f.read(), dropbox_path, mode=dropbox.files.WriteMode("overwrite"))
                print(f"‚úÖ Upload successful after token refresh")
                return True
            except Exception as e:
                print(f"‚ùå Upload failed after refresh: {e}")
                return False
        else:
            print("‚ùå Could not refresh token for upload")
            return False

    except Exception as e:
        print(f"‚ùå Upload error: {e}")
        import traceback
        traceback.print_exc()
        return False


# ---------------- DROPBOX INITIALIZATION ----------------
# Initialize Dropbox on startup
print(f"\nüîß Checking Dropbox configuration...")

# Check if we have the minimum required credentials
refresh_token = os.environ.get("DROPBOX_REFRESH_TOKEN")
app_key = os.environ.get("DROPBOX_APP_KEY")
app_secret = os.environ.get("DROPBOX_APP_SECRET")

if all([refresh_token, app_key, app_secret]):
    print(f"‚úÖ Found Dropbox credentials")
    print(f"   App Key: {app_key[:10]}...")
    print(f"   Refresh token: {len(refresh_token)} chars")

    # Try to initialize Dropbox
    dbx = initialize_dropbox()
    if dbx:
        print("‚úÖ Dropbox initialized with permanent access")
        print("   Files will be uploaded to: /Apps/FlaskReport/")
    else:
        print("‚ö†Ô∏è Dropbox initialization failed")
        print("   Uploads will be disabled but reports will still generate")
else:
    print("‚ö†Ô∏è Dropbox credentials incomplete")
    missing = []
    if not refresh_token: missing.append("DROPBOX_REFRESH_TOKEN")
    if not app_key: missing.append("DROPBOX_APP_KEY")
    if not app_secret: missing.append("DROPBOX_APP_SECRET")
    print(f"   Missing: {', '.join(missing)}")
    print("   Reports will generate locally without Dropbox upload")


def save_uploaded_file(storage, dest_folder):
    filename = secure_filename(storage.filename)
    path = os.path.join(dest_folder, filename)
    storage.save(path)
    return path


def replace_placeholders(doc, replacements):
    """Replace text placeholders in the document while preserving formatting"""
    print(f"üîÑ Starting placeholder replacement for {len(replacements)} placeholders...")

    # Track which placeholders were found and replaced
    found_placeholders = set()

    # Method 1: Direct paragraph text replacement
    for paragraph in doc.paragraphs:
        original_text = paragraph.text
        if original_text:
            new_text = original_text
            for key, value in replacements.items():
                if key in original_text:
                    found_placeholders.add(key)
                    print(f"üìù Replacing '{key}' with '{value[:50]}...'")
                    new_text = new_text.replace(key, str(value))
            if new_text != original_text:
                paragraph.text = new_text

    # Method 2: Table replacement
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                for paragraph in cell.paragraphs:
                    original_text = paragraph.text
                    if original_text:
                        new_text = original_text
                        for key, value in replacements.items():
                            if key in original_text:
                                found_placeholders.add(key)
                                new_text = new_text.replace(key, str(value))
                        if new_text != original_text:
                            paragraph.text = new_text

    # Method 3: Header and footer replacement
    for section in doc.sections:
        # Header
        if section.header:
            for paragraph in section.header.paragraphs:
                original_text = paragraph.text
                if original_text:
                    new_text = original_text
                    for key, value in replacements.items():
                        if key in original_text:
                            found_placeholders.add(key)
                            new_text = new_text.replace(key, str(value))
                    if new_text != original_text:
                        paragraph.text = new_text

        # Footer
        if section.footer:
            for paragraph in section.footer.paragraphs:
                original_text = paragraph.text
                if original_text:
                    new_text = original_text
                    for key, value in replacements.items():
                        if key in original_text:
                            found_placeholders.add(key)
                            new_text = new_text.replace(key, str(value))
                    if new_text != original_text:
                        paragraph.text = new_text

    # Log which placeholders weren't found
    missing_placeholders = set(replacements.keys()) - found_placeholders
    if missing_placeholders:
        print(f"‚ö†Ô∏è These placeholders were NOT found in document: {missing_placeholders}")

    print(f"‚úÖ Placeholder replacement completed. Found and replaced {len(found_placeholders)} placeholders")

def remove_specific_placeholders(doc):
    """Remove ALL placeholders with EXACT matching"""
    print("üóëÔ∏è Removing ALL placeholders...")

    placeholders_to_remove = [
        # Table placeholders
        "[[table-1_identified-impacts]]", "[[table-3_a]]", "[[table-4_current_strengths]]",
        "[[table-5_development_actions]]", "[[table-7_monitoring]]", "[[table-A2_hazards]]",
        "[[table_A5_monitoring]]", "[[rapa-1]]", "[[rapa-2]]", "[[cadd-1_current]]",
        "[[cadd-2_add]]",

        # Old Excel placeholders
        "[[excel_tables_table-1_identified-impacts.xlsx]]",
        "[[Table 1: Identified impacts requiring action grouped by phase of global warming in 0.5¬∞C increments]]",

        # Figure placeholders
        "[[Figure-1_Change-in-Hot-Summer-Days]]", "[[Figure-1_Change-in-Hot-Summer-Days.png]]",
        "[[Figure-2_Change-in-tropical-nights]]", "[[Figure-3_Changing-flood-risk]]",
        "[[Figure-4_Changing-drought-wind-and-subsidence-risks]]",
        "[[Figure-5_Components-of-climate-change-vulnerability]]",
        "[[Figure-6_Current-and-target-capabilities]]",
        "[[Figure-7_Adaptation-Plan-activities-and-phased-implementation-pathways]]",

        # Table title placeholders
        "[[Table A5-1: Monitoring and Evaluation Matrix Template]]",
        "[[Table A2-1: EA Climate Hazards List Data and Information Sources]]",
        "[[Table 6: Monitoring and review processes]]",
        "[[Table 5: East Higher Dairy Farm Climate Adaptive Capacity Development Actions by Implementation Phase]]",
        "[[Table 4: Current adaptive capacity strengths to protect in the capacity development implementation plan]]",
        "[[Table 5: East Hill Dairy Farm Climate Adaptive Capacity Development Actions by Implementation Phase]]",
    ]

    removed_count = 0

    # Remove from paragraphs
    for paragraph in doc.paragraphs:
        original_text = paragraph.text
        for placeholder in placeholders_to_remove:
            if placeholder in original_text:
                paragraph.text = paragraph.text.replace(placeholder, "")
                removed_count += 1
                print(f"‚úÖ Removed placeholder: {placeholder}")

    # Remove from tables
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                for paragraph in cell.paragraphs:
                    original_text = paragraph.text
                    for placeholder in placeholders_to_remove:
                        if placeholder in original_text:
                            paragraph.text = paragraph.text.replace(placeholder, "")
                            removed_count += 1
                            print(f"‚úÖ Removed placeholder from table: {placeholder}")

    print(f"‚úÖ Removed {removed_count} placeholders total")
    return removed_count


def read_mural_content_from_file(filename="mural_content_for_report.txt"):
    """Read Mural content from text file with proper formatting"""
    try:
        if not os.path.exists(filename):
            print(f"‚ö†Ô∏è Mural content file not found: {filename}")
            return get_fallback_mural_content()

        with open(filename, 'r', encoding='utf-8') as f:
            content = f.read()

        if not content or len(content.strip()) < 10:
            print("‚ö†Ô∏è Mural content file is empty or too short")
            return get_fallback_mural_content()

        print(f"‚úÖ Read Mural content from {filename} ({len(content)} chars)")

        # Ensure the content has proper line breaks for Word
        content = content.replace('\n\n', '\n')
        content = content.replace('**', '')  # Remove markdown bold

        return content

    except Exception as e:
        print(f"‚ùå Error reading Mural file: {e}")
        return get_fallback_mural_content()


def read_mural_content_from_excel(excel_file_pattern="Mural_Content_For_Report_*.xlsx"):
    """Read Mural content directly from the generated Excel file"""
    try:
        # Find the latest Excel file
        import glob
        excel_files = glob.glob(excel_file_pattern)
        if not excel_files:
            print("‚ö†Ô∏è No Mural Excel files found")
            return get_fallback_mural_content()

        latest_file = max(excel_files, key=os.path.getctime)
        print(f"üìä Reading Mural content from: {latest_file}")

        import pandas as pd
        xls = pd.ExcelFile(latest_file)

        content_lines = []
        content_lines.append("Client Inputs from Mural Workshop\n")

        # Read each sheet
        for sheet_name in xls.sheet_names:
            content_lines.append(f"\n{sheet_name}\n")

            try:
                df = pd.read_excel(latest_file, sheet_name=sheet_name)

                # Extract meaningful content
                for _, row in df.iterrows():
                    for value in row.dropna():
                        if isinstance(value, str) and value.strip():
                            # Skip placeholder rows and empty content
                            if any(placeholder in value for placeholder in [
                                'Appendix 6:', 'Table 1:', 'TITLE', 'HEADERS COLUMN',
                                'CONTENT (BLUE/DARK RED/ORANGE POST-ITS)', 'RAPA',
                                'Adaptation Action', '30oC', '35oc', 'Assumptions', 'Uncertainties',
                                'Table 1: Risks from Climate Change', 'Table 2: RAPA'
                            ]):
                                continue

                            clean_value = str(value).strip()
                            if clean_value and len(clean_value) > 3:
                                content_lines.append(f"‚Ä¢ {clean_value}")
            except Exception as sheet_error:
                print(f"‚ö†Ô∏è Error reading sheet {sheet_name}: {sheet_error}")

        content = '\n'.join(content_lines)
        print(f"‚úÖ Extracted {len(content_lines)} lines from Excel")
        return content

    except Exception as e:
        print(f"‚ùå Error reading Mural Excel file: {e}")
        return get_fallback_mural_content()


def get_fallback_mural_content():
    """Fallback content if Mural file not found"""
    return """**Client Inputs from Mural Workshop**

No content was extracted from the Mural workshop.

Please run the Mural extraction script to get actual workshop content:
1. Run: python get_data_to_excel.py
2. Authorize with Mural when prompted
3. Try generating the report again

Or use the placeholder content below:

**Sample Climate Risks:**
1. Extreme heat affecting operations
2. Flooding disrupting access
3. Water scarcity during dry periods

**Sample Adaptation Actions:**
1. Implement climate-resilient infrastructure
2. Develop emergency response plans
3. Enhance monitoring systems"""


# ===== MURAL CONTENT INSERTION FUNCTIONS =====
def remove_existing_mural_content(doc):
    """Remove any existing Mural tables to prevent duplicates"""
    print("üóëÔ∏è Removing any existing Mural tables...")

    # Look for Mural table titles
    mural_titles = [
        "Table 1: Risks from Climate Change",
        "Table 2: RAPA (Rapid Adaptation Pathways Assessment)",
        "Client Inputs from Mural Workshop",
        "Appendix 3: Client Inputs from Mural Workshop"
    ]

    paragraphs_to_remove = []

    # Find paragraphs with Mural content
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()
        for title in mural_titles:
            if title in text:
                # Mark this paragraph and several following for removal
                paragraphs_to_remove.extend(range(max(0, i - 2), min(len(doc.paragraphs), i + 10)))
                print(f"üóëÔ∏è Found existing Mural content: '{text[:50]}...' at paragraph {i}")
                break

    # Also check tables for Mural content
    for table_idx, table in enumerate(doc.tables):
        for row_idx, row in enumerate(table.rows):
            for cell_idx, cell in enumerate(row.cells):
                for paragraph in cell.paragraphs:
                    text = paragraph.text.strip()
                    if any(title in text for title in mural_titles):
                        print(f"üóëÔ∏è Found Mural content in table {table_idx}, cell {cell_idx}")
                        # Clear the cell
                        for p in cell.paragraphs:
                            p.clear()

    # Remove duplicate paragraphs
    paragraphs_to_remove = sorted(set(paragraphs_to_remove))
    for i in reversed(paragraphs_to_remove):
        if i < len(doc.paragraphs):
            try:
                p = doc.paragraphs[i]._element
                p.getparent().remove(p)
            except:
                pass

    print(f"üóëÔ∏è Removed {len(paragraphs_to_remove)} duplicate Mural content paragraphs")


def create_mural_table_1_in_cell(cell, table1_data):
    """Create Table 1 directly in a table cell"""
    # Clear the cell first
    for paragraph in cell.paragraphs:
        paragraph.clear()

    # Add title
    title_para = cell.add_paragraph("Table 1: Risks from Climate Change")
    title_para.runs[0].bold = True
    title_para.runs[0].font.size = Pt(10)

    # Create a simple representation since cells have limited space
    content_para = cell.add_paragraph("Mural content would appear here")
    content_para.runs[0].italic = True
    content_para.runs[0].font.size = Pt(9)


def create_mural_table_2_in_cell(cell, table2_data):
    """Create Table 2 directly in a table cell"""
    # Clear the cell first
    for paragraph in cell.paragraphs:
        paragraph.clear()

    # Add title
    title_para = cell.add_paragraph("Table 2: RAPA")
    title_para.runs[0].bold = True
    title_para.runs[0].font.size = Pt(10)

    # Create a simple representation
    content_para = cell.add_paragraph("RAPA content would appear here")
    content_para.runs[0].italic = True
    content_para.runs[0].font.size = Pt(9)


def remove_mural_content_from_appendix(doc):
    """Remove any Mural content from Appendix sections"""
    print("üóëÔ∏è Removing Mural content from Appendix sections...")

    # Find Appendix sections
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.lower()
        if "appendix" in text and "client" in text:
            # Found client appendix - remove it and following content
            for j in range(i, min(len(doc.paragraphs), i + 20)):
                doc.paragraphs[j].clear()
            print(f"üóëÔ∏è Removed Mural content from Appendix at paragraph {i}")
            break


def insert_minimal_fallback_at_placeholders(doc):
    """Insert minimal fallback text at placeholders (not in Appendix)"""
    print("üìù Adding minimal fallback text at placeholders...")

    # Only replace placeholders with simple text, don't create new sections
    for i, paragraph in enumerate(doc.paragraphs):
        if "[[Decision-systems-1]]" in paragraph.text:
            paragraph.text = paragraph.text.replace("[[Decision-systems-1]]",
                                                    "[Table 1: Risks from Climate Change - Run Mural extraction to populate]")

        if "[[Decision-systems-2]]" in paragraph.text:
            paragraph.text = paragraph.text.replace("[[Decision-systems-2]]",
                                                    "[Table 2: RAPA - Run Mural extraction to populate]")

def insert_mural_content_into_document(doc):
    """Insert Mural content as proper tables at Decision Systems Mapping placeholders"""
    print("\n" + "=" * 60)
    print("üìä INSERTING MURAL CONTENT AT DECISION SYSTEMS MAPPING PLACEHOLDERS")
    print("=" * 60)

    # Read structured Mural content
    structured_data = read_structured_mural_content("mural_content_for_report.json")

    if not structured_data:
        print("‚ö†Ô∏è No structured Mural data found, using fallback")
        insert_fallback_mural_content(doc)
        return False

    # Track if we placed content successfully
    table1_placed = False
    table2_placed = False

    # ===== FIRST: Find and remove any existing Mural content to prevent duplicates =====
    print("\nüßπ Cleaning up any existing Mural content to prevent duplicates...")
    remove_existing_mural_content(doc)

    # ===== REPLACE [[Decision-systems-1]] with Table 1 =====
    print("\nüîç Looking for placeholder: [[Decision-systems-1]]")
    for i, paragraph in enumerate(doc.paragraphs):
        if "[[Decision-systems-1]]" in paragraph.text:
            print(f"‚úÖ Found [[Decision-systems-1]] at paragraph {i}")

            # Clear the placeholder
            paragraph.clear()

            # Add Table 1: Risks from Climate Change at this location
            create_mural_table_1_at_paragraph(doc, i, structured_data['table1'])
            table1_placed = True
            break

    # ===== REPLACE [[Decision-systems-2]] with Table 2 =====
    print("\nüîç Looking for placeholder: [[Decision-systems-2]]")
    for i, paragraph in enumerate(doc.paragraphs):
        if "[[Decision-systems-2]]" in paragraph.text:
            print(f"‚úÖ Found [[Decision-systems-2]] at paragraph {i}")

            # Clear the placeholder
            paragraph.clear()

            # Add Table 2: RAPA at this location
            # Handle both old and new structures
            table2_data = structured_data.get('table2', {})

            # Check if it's the new structure
            if 'adaptation_actions' in table2_data:
                # New structure
                create_mural_table_2_at_paragraph(doc, i, table2_data)
            elif 'content' in table2_data:
                # Old structure - convert to new structure
                converted_data = {
                    'adaptation_actions': {
                        'content': table2_data.get('content', []),
                        'color': table2_data.get('color', 'Green')
                    },
                    'assumptions': {
                        'content': [],
                        'color': 'Blue'
                    }
                }
                create_mural_table_2_at_paragraph(doc, i, converted_data)
            else:
                # Empty table
                create_mural_table_2_at_paragraph(doc, i, {
                    'adaptation_actions': {'content': [], 'color': 'Green'},
                    'assumptions': {'content': [], 'color': 'Blue'}
                })

            table2_placed = True
            break

    # Also check tables for placeholders
    if not table1_placed or not table2_placed:
        print("\nüîç Searching for placeholders in tables...")
        for table_idx, table in enumerate(doc.tables):
            for row_idx, row in enumerate(table.rows):
                for cell_idx, cell in enumerate(row.cells):
                    for para_idx, paragraph in enumerate(cell.paragraphs):
                        if "[[Decision-systems-1]]" in paragraph.text and not table1_placed:
                            print(f"‚úÖ Found [[Decision-systems-1]] in table {table_idx}, cell {cell_idx}")
                            paragraph.clear()
                            # Create table directly in the cell
                            create_mural_table_1_in_cell(cell, structured_data['table1'])
                            table1_placed = True

                        if "[[Decision-systems-2]]" in paragraph.text and not table2_placed:
                            print(f"‚úÖ Found [[Decision-systems-2]] in table {table_idx}, cell {cell_idx}")
                            paragraph.clear()
                            # Create table directly in the cell
                            table2_data = structured_data.get('table2', {})
                            create_mural_table_2_in_cell(cell, table2_data)
                            table2_placed = True

    # ===== CRITICAL: REMOVE FALLBACK APPENDIX INSERTION =====
    # We only want content at the placeholders, not in Appendix 3
    if table1_placed and table2_placed:
        print("\n‚úÖ Successfully placed both Mural tables at Decision Systems Mapping placeholders")
        print("   Content placed ONLY at [[Decision-systems-1]] and [[Decision-systems-2]] placeholders")
    elif table1_placed:
        print("\n‚ö†Ô∏è Only placed Table 1 (could not find [[Decision-systems-2]])")
        # Remove any existing Mural content in Appendix to prevent duplicates
        remove_mural_content_from_appendix(doc)
    elif table2_placed:
        print("\n‚ö†Ô∏è Only placed Table 2 (could not find [[Decision-systems-1]])")
        # Remove any existing Mural content in Appendix to prevent duplicates
        remove_mural_content_from_appendix(doc)
    else:
        print("\n‚ùå Could not find either placeholder")
        # DO NOT insert in Appendix - just leave placeholders or use minimal fallback
        # This prevents duplicate content
        insert_minimal_fallback_at_placeholders(doc)

    return table1_placed or table2_placed


def create_mural_table_1_at_paragraph(doc, paragraph_index, table1_data):
    """Create Table 1 at a specific paragraph location"""
    print("üìä Creating Table 1 at paragraph location")

    # Get the paragraph element
    target_para = doc.paragraphs[paragraph_index]

    # Add table title
    title_para = target_para.insert_paragraph_before("Table 1: Risks from Climate Change")
    title_para.runs[0].bold = True
    title_para.runs[0].font.size = Pt(12)

    # Get column data
    columns = table1_data['columns']
    max_rows = max(len(col['content']) for col in columns)

    # Create table: +2 for header row and title row
    table = doc.add_table(rows=max_rows + 2, cols=3)

    # Set table alignment
    table.alignment = WD_TABLE_ALIGNMENT.CENTER

    # Set column widths (equal width for 3 columns)
    for col in table.columns:
        col.width = Inches(2.5)

    # Add main header (merged across all columns)
    main_header = table.cell(0, 0)
    main_header.merge(table.cell(0, 2))
    main_header.text = table1_data.get('title', 'Risks from climate change')

    # Format main header
    for paragraph in main_header.paragraphs:
        paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
        for run in paragraph.runs:
            run.bold = True
            run.font.size = Pt(11)

    # Add column headers
    for col_idx, column in enumerate(columns):
        cell = table.cell(1, col_idx)
        cell.text = column['header']

        # Format column header
        for paragraph in cell.paragraphs:
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            for run in paragraph.runs:
                run.bold = True
                run.font.size = Pt(10)



    # Add content rows
    for row_idx in range(max_rows):
        for col_idx, column in enumerate(columns):
            cell = table.cell(row_idx + 2, col_idx)
            if row_idx < len(column['content']):
                content = column['content'][row_idx]
                cell.text = f"{row_idx + 1}. {content}"

            # Format cell
            for paragraph in cell.paragraphs:
                paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT
                paragraph.paragraph_format.space_after = Pt(6)
                for run in paragraph.runs:
                    run.font.size = Pt(10)

    # Apply table borders
    apply_table_borders(table)

    # Position the table after the title
    table_element = table._element
    title_element = title_para._element
    title_element.addnext(table_element)

    # Remove the original placeholder paragraph
    target_para._element.getparent().remove(target_para._element)

    print(f"‚úÖ Created Table 1 with {max_rows} content rows at Decision Systems Mapping")


def create_mural_table_2_at_paragraph(doc, paragraph_index, table2_data):
    """Create Table 2 (RAPA Chart) at a specific paragraph location"""
    print("üìä Creating Table 2 (RAPA Chart) at paragraph location")

    # Get the paragraph element
    target_para = doc.paragraphs[paragraph_index]

    # Add Figure title (since it's a chart now, maybe clearer as Figure? But user said Table 2)
    # Keeping "Table 2" as requested, or "Figure" if it looks better. User said "change formatting of this table... according to this" (which is a chart).
    # I'll keep the title "Table 2: RAPA..." but insert the chart.
    title_para = target_para.insert_paragraph_before("Table 2: RAPA (Rapid Adaptation Pathways Assessment)")
    title_para.runs[0].bold = True
    title_para.runs[0].font.size = Pt(12)

    # Get content
    adaptation_actions = table2_data.get('adaptation_actions', {})
    assumptions = table2_data.get('assumptions', {})
    
    # Get adaptation actions content (green notes) for the chart
    adaptation_content = adaptation_actions.get('content', [])
    
    if adaptation_content:
        # Generate the chart
        chart_filename = f"RAPA_Chart_{uuid.uuid4().hex[:8]}.png"
        chart_path = generate_rapa_chart(adaptation_content, chart_filename)
        
        if chart_path and os.path.exists(chart_path):
            # Insert the chart image
            image_para = target_para.insert_paragraph_before()
            image_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = image_para.add_run()
            try:
                run.add_picture(chart_path, width=Inches(6.5)) # Fit page width
                print(f"‚úÖ Inserted RAPA Chart image: {chart_filename}")
            except Exception as e:
                print(f"‚ùå Error inserting RAPA chart image: {e}")
                image_para.text = "[Error inserting RAPA Chart]"
        else:
             print("‚ö†Ô∏è RAPA chart generation failed")
             # Fallback to text list?
             error_para = target_para.insert_paragraph_before("[RAPA Chart Generation Failed]")
    else:
        print("‚ö†Ô∏è No adaptation actions found for RAPA chart")
        no_data_para = target_para.insert_paragraph_before("[No Adaptation Actions Found for RAPA]")

    # Add Assumptions section below the chart if exists
    assumptions_content = assumptions.get('content', [])
    if assumptions_content:
        # Add a sub-heading for assumptions
        assump_heading = target_para.insert_paragraph_before("Assumptions")
        assump_heading.runs[0].bold = True
        assump_heading.runs[0].font.size = Pt(11)
        
        # List assumptions
        for assumption in assumptions_content:
            p = target_para.insert_paragraph_before(f"‚Ä¢ {assumption}")
            p.style = "Normal"

    # Remove the original placeholder paragraph
    target_para._element.getparent().remove(target_para._element)

    print(f"‚úÖ Created Table 2 (Chart) with {len(adaptation_content)} actions")


def insert_mural_content_in_appendix_3(doc, structured_data):
    """Fallback: Insert Mural content in Appendix 3 if placeholders not found"""
    print("üìå Using fallback: Inserting Mural content in Appendix 3")

    # Find or create Appendix 3
    appendix_para = find_or_create_appendix_3(doc)
    if not appendix_para:
        return False

    # Add spacing
    doc.paragraphs[appendix_para].insert_paragraph_before()

    # Create Table 1
    create_mural_table_1_at_paragraph(doc, appendix_para, structured_data['table1'])

    # Add spacing between tables
    for _ in range(2):
        doc.paragraphs[appendix_para].insert_paragraph_before()

    # Create Table 2
    create_mural_table_2_at_paragraph(doc, appendix_para, structured_data['table2'])

    return True


def read_structured_mural_content(filename="mural_content_for_report.json"):
    """Read structured Mural content from JSON file"""
    try:
        if not os.path.exists(filename):
            print(f"‚ö†Ô∏è Structured Mural file not found: {filename}")
            return None

        with open(filename, 'r', encoding='utf-8') as f:
            data = json.load(f)

        print(f"‚úÖ Read structured Mural content from {filename}")
        return data

    except Exception as e:
        print(f"‚ùå Error reading structured Mural file: {e}")
        return None


def find_or_create_appendix_3(doc):
    """Find or create Appendix 3 section in document"""
    # First, try to find Appendix 3
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.lower()
        if 'appendix 3' in text or 'client inputs' in text:
            print(f"‚úÖ Found Appendix 3 at paragraph {i}")
            return i

    # If not found, look for a good place to insert it (usually after other appendices or before references)
    insert_point = len(doc.paragraphs) - 1
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.lower()
        if 'appendix' in text or 'reference' in text or 'bibliography' in text:
            insert_point = i
            break

    print(f"üìå Creating new Appendix 3 at paragraph {insert_point}")

    # Add page break
    doc.paragraphs[insert_point].insert_paragraph_before().add_run().add_break(WD_BREAK.PAGE)

    # Add Appendix 3 heading
    heading = doc.paragraphs[insert_point].insert_paragraph_before("Appendix 3: Client Inputs from Mural Workshop")
    heading.style = "Heading 2"

    return insert_point + 1


def get_color_rgb(color_name):
    """Convert color name to RGB color for Word"""
    colors = {
        'Blue': RGBColor(158, 220, 250),
        'Dark Red': RGBColor(191, 12, 12),
        'Orange': RGBColor(255, 192, 97),
        'Green': RGBColor(170, 237, 146),
        'Light Orange': RGBColor(250, 205, 158)
    }
    return colors.get(color_name, RGBColor(0, 0, 0))  # Default to black


def apply_table_borders(table):
    """Apply consistent borders to a table"""
    border_style = {
        'val': 'single',
        'sz': 4,
        'color': '000000'
    }

    for row in table.rows:
        for cell in row.cells:
            cell._element.tcPr.append(parse_xml(
                f'<w:tcBorders xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main">'
                f'<w:top {format_border(border_style)}/>'
                f'<w:left {format_border(border_style)}/>'
                f'<w:bottom {format_border(border_style)}/>'
                f'<w:right {format_border(border_style)}/>'
                f'</w:tcBorders>'
            ))


def format_border(style):
    """Format border style for XML"""
    return f'w:val="{style["val"]}" w:sz="{style["sz"]}" w:space="0" w:color="{style["color"]}"'


def format_custom_section_toc_entry(doc, section_num, title, page_num, level=1):
    """Create properly formatted TOC entry for custom section"""
    # Determine indent based on heading level
    indent = Inches(0.3 * (level - 1))

    # Create the paragraph
    para = doc.add_paragraph()
    para.paragraph_format.left_indent = indent
    para.paragraph_format.space_after = Pt(6)

    # Build section number text
    if level == 1:
        section_text = f"{section_num}. {title}"
    else:
        # For sub-sections: 13.1, 13.2, etc.
        subsection_num = section_num - 12  # 13 becomes 1, 14 becomes 2, etc.
        section_text = f"{subsection_num}. {title}"

    # Add section number and title
    text_run = para.add_run(section_text)
    text_run.bold = True
    text_run.font.name = "Calibri"
    text_run.font.size = Pt(10)

    # Calculate space for dots
    text_length = len(section_text)
    remaining_space = 70 - text_length  # Total width for TOC line

    if remaining_space > 5:
        # Add dots
        dots_run = para.add_run(" " + "." * remaining_space + " ")
        dots_run.font.name = "Calibri"
        dots_run.font.size = Pt(8)

        # Add page number
        page_run = para.add_run(str(page_num))
        page_run.bold = True
        page_run.font.name = "Calibri"
        page_run.font.size = Pt(10)

    return para

def insert_fallback_mural_content(doc):
    """Insert fallback content when no Mural data is available"""
    print("üìù Inserting fallback Mural content")

    # First try to find Decision Systems Mapping placeholders
    for i, paragraph in enumerate(doc.paragraphs):
        if "[[Decision-systems-1]]" in paragraph.text:
            paragraph.text = paragraph.text.replace("[[Decision-systems-1]]",
                                                    "[Table 1: Risks from Climate Change - Run Mural extraction script to populate]")

        if "[[Decision-systems-2]]" in paragraph.text:
            paragraph.text = paragraph.text.replace("[[Decision-systems-2]]",
                                                    "[Table 2: RAPA - Run Mural extraction script to populate]")

def clean_up_bullet_formatting(doc):
    """Clean up bullet formatting issues in the document"""
    print("üîß Cleaning up bullet formatting...")

    try:
        fixed_count = 0

        for paragraph in doc.paragraphs:
            original_text = paragraph.text

            if original_text:
                new_text = original_text

                # Fix markdown-style bullet formatting
                if "*   **Value:**" in new_text or "*   **Urgency:**" in new_text or "*   **Actions:**" in new_text:
                    # Replace with properly formatted bullets
                    proper_format = """‚Ä¢ Value: Proactive adaptation builds resilience, protects critical assets, and secures long-term sustainability against escalating climate impacts.
‚Ä¢ Urgency: Immediate action is paramount; delaying adaptation will drastically increase costs, risks, and the severity of future disruptions.
‚Ä¢ Strategic Actions: Implement integrated adaptation strategies aligned with farm operations and stakeholder requirements.
‚Ä¢ Implementation Actions: Develop detailed implementation plans with clear responsibilities, timelines, and resources.
‚Ä¢ Monitoring Actions: Establish robust monitoring, evaluation, and learning frameworks for continuous improvement."""
                    paragraph.text = proper_format
                    fixed_count += 1
                    continue

                # Fix other markdown formatting
                new_text = new_text.replace("*   **Value:**", "‚Ä¢ Value:")
                new_text = new_text.replace("*   **Urgency:**", "‚Ä¢ Urgency:")
                new_text = new_text.replace("*   **Actions:**", "‚Ä¢ Actions:")
                new_text = new_text.replace("**Value:**", "Value:")
                new_text = new_text.replace("**Urgency:**", "Urgency:")
                new_text = new_text.replace("**Actions:**", "Actions:")

                # Fix incomplete bullet points
                if ("‚Ä¢ Value:" in new_text or "‚Ä¢ Urgency:" in new_text or "‚Ä¢ Actions:" in new_text) and len(
                        new_text) < 200:
                    # Check if this is in Executive Summary
                    is_exec_summary = False
                    for i, p in enumerate(doc.paragraphs):
                        if p == paragraph:
                            # Check nearby paragraphs for Executive Summary heading
                            for j in range(max(0, i - 3), min(len(doc.paragraphs), i + 3)):
                                if "Executive Summary" in doc.paragraphs[j].text:
                                    is_exec_summary = True
                                    break
                            break

                    if is_exec_summary and len(new_text.split('\n')) < 3:
                        # Replace with complete key messages
                        proper_key_messages = """‚Ä¢ Value: Proactive adaptation builds resilience, protects critical assets, and secures long-term sustainability against escalating climate impacts.
‚Ä¢ Urgency: Immediate action is paramount; delaying adaptation will drastically increase costs, risks, and the severity of future disruptions.
‚Ä¢ Strategic Actions: Implement integrated adaptation strategies aligned with farm operations and stakeholder requirements.
‚Ä¢ Implementation Actions: Develop detailed implementation plans with clear responsibilities, timelines, and resources.
‚Ä¢ Monitoring Actions: Establish robust monitoring, evaluation, and learning frameworks for continuous improvement."""
                        paragraph.text = proper_key_messages
                        fixed_count += 1

                if new_text != original_text:
                    paragraph.text = new_text
                    fixed_count += 1

        print(f"üîß Fixed {fixed_count} bullet formatting issues")
        return fixed_count  # Always returns an integer

    except Exception as e:
        print(f"‚ö†Ô∏è Error in bullet formatting: {e}")
        return 0  # Return 0 instead of None


def clean_up_toc_formatting(doc):
    """Clean up TOC formatting to ensure custom sections appear in correct order"""
    print("üßπ Cleaning up TOC formatting...")

    # Find TOC section
    toc_start = -1
    in_toc = False

    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()

        if "Table of Contents" in text and not in_toc:
            toc_start = i
            in_toc = True
            print(f"‚úÖ Found TOC start at paragraph {i}")
            continue

        if in_toc and ("List of Figures" in text or "List of Tables" in text):
            # End of TOC section
            print(f"‚úÖ Found end of TOC at paragraph {i}")
            break

    if toc_start == -1:
        print("‚ö†Ô∏è TOC not found in document")
        return False

    return True

def remove_figure_placeholders(doc):
    """Specifically remove figure placeholders that might have been missed"""
    print("üóëÔ∏è Removing figure placeholders specifically...")

    figure_placeholders = [
        "[[Figure-1_Change-in-Hot-Summer-Days]]",
        "[[Figure-1_Change-in-Hot-Summer-Days.png]]",
        "[[Figure-2_Change-in-tropical-nights]]",
        "[[Figure-3_Changing-flood-risk]]",
        "[[Figure-4_Changing-drought-wind-and-subsidence-risks]]",
        "[[Figure-5_Components-of-climate-change-vulnerability]]",
        "[[Figure-6_Current-and-target-capabilities]]",
        "[[Figure-7_Adaptation-Plan-activities-and-phased-implementation-pathways]]"
    ]

    removed_count = 0

    for paragraph in doc.paragraphs:
        for placeholder in figure_placeholders:
            if placeholder in paragraph.text:
                # Check if this is a standalone placeholder (not part of actual figure caption)
                if paragraph.text.strip() == placeholder:
                    paragraph.text = ""
                    removed_count += 1
                    print(f"‚úÖ Removed figure placeholder: {placeholder}")

    return removed_count


def clean_up_bullet_formatting(doc):
    """Clean up bullet formatting issues in the document"""
    # ... your existing function code ...


def fix_title_page_placeholders(doc, json_data):
    """Specifically fix title page placeholders"""
    print("üìÑ Fixing title page placeholders...")

    title_page_placeholders = {
        "[[client_name]]": json_data.get("client_name", ""),
        "[[project_title]]": json_data.get("project_title", ""),
        "[[client_location]]": json_data.get("client_location", ""),
        "[[report_date]]": json_data.get("report_date", ""),
    }

    # Usually title page is first few paragraphs
    for i in range(min(20, len(doc.paragraphs))):
        paragraph = doc.paragraphs[i]
        text = paragraph.text

        for placeholder, value in title_page_placeholders.items():
            if placeholder in text and value:
                paragraph.text = text.replace(placeholder, value)
                print(f"‚úÖ Fixed title page: {placeholder} ‚Üí {value}")

    return True

def ensure_placeholders_in_doc(doc):
    """Ensure that the Excel and Image placeholders exist in the document"""
    print("üîç Checking for required placeholders in document...")

    # Define all required placeholders
    required_placeholders = [
        "[[excel_tables_table-1_identified-impacts.xlsx]]",
        "[[Figure-1_Change-in-Hot-Summer-Days.png]]",
        "[[Table 1: Identified impacts requiring action grouped by phase of global warming in 0.5¬∞C increments]]",
        "[[table-3_a]]",
        "[[Table 4: Current adaptive capacity strengths to protect in the capacity development implementation plan]]",
        "[[Table 5: East Higher Dairy Farm Climate Adaptive Capacity Development Actions by Implementation Phase]]",
        "[[Table 6: Monitoring and review processes]]",
        "[[Table A2-1: EA Climate Hazards List Data and Information Sources]]",
        "[[Table A5-1: Monitoring and Evaluation Matrix Template]]"
    ]

    # Check which placeholders exist
    existing_placeholders = {}
    for placeholder in required_placeholders:
        found = False
        for paragraph in doc.paragraphs:
            if placeholder in paragraph.text:
                found = True
                break
        existing_placeholders[placeholder] = found

    # Add missing placeholders
    for placeholder, exists in existing_placeholders.items():
        if not exists:
            print(f"‚ö†Ô∏è Placeholder '{placeholder}' missing, adding to document...")

            # Try to find appropriate section to insert placeholder
            insertion_point = None

            # Look for specific sections to insert placeholders
            for i, paragraph in enumerate(doc.paragraphs):
                text = paragraph.text.lower()

                if "table 1:" in text and "identified impacts" in text:
                    insertion_point = i
                    break
                elif "table 3:" in text and "physical risk management" in text:
                    insertion_point = i
                    break
                elif "table 4:" in text and "current adaptive capacity" in text:
                    insertion_point = i
                    break
                elif "table 5:" in text and "capacity development" in text:
                    insertion_point = i
                    break
                elif "table 6:" in text and "monitoring and review" in text:
                    insertion_point = i
                    break
                elif "table a2-1:" in text and "climate hazards" in text:
                    insertion_point = i
                    break
                elif "table a5-1:" in text and "monitoring and evaluation" in text:
                    insertion_point = i
                    break

            # If no specific section found, add at end of relevant content
            if insertion_point is None:
                # Find "East Hill Farm in a Changing Climate" section as fallback
                for i, paragraph in enumerate(doc.paragraphs):
                    if "East Hill Farm in a Changing Climate" in paragraph.text:
                        insertion_point = i + 1
                        break

            if insertion_point is not None and insertion_point < len(doc.paragraphs):
                new_para = doc.paragraphs[insertion_point].insert_paragraph_before(placeholder)
                new_para.style = "Normal"
                print(f"‚úÖ Added placeholder: {placeholder}")

    return any(existing_placeholders.values())


def create_table_title(doc, title_text, level=2):
    """Create table titles that match PDF style"""
    title_para = doc.add_paragraph()
    title_para.alignment = WD_ALIGN_PARAGRAPH.LEFT
    title_para.paragraph_format.space_before = Pt(12)
    title_para.paragraph_format.space_after = Pt(6)

    run = title_para.add_run(title_text)
    run.bold = True
    run.font.size = Pt(11)
    run.font.name = "Arial"

    return title_para


def format_table_exact_pdf(table, sheet_name):
    """Format table to be EXACTLY like the PDF tables"""
    try:
        # Remove any existing table style
        table.style = None
        table.autofit = False

        tbl = table._tbl
        tblPr = tbl.tblPr

        # Remove any existing borders
        for elem in tblPr:
            if 'tblBorders' in elem.tag:
                tblPr.remove(elem)
                break

        # EXACT PDF BORDERS - thin, black, all around
        tblBorders = parse_xml(r'<w:tblBorders xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main">'
                               r'<w:top w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:left w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:bottom w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:right w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:insideH w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:insideV w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'</w:tblBorders>')
        tblPr.append(tblBorders)

        # EXACT PDF COLUMN WIDTHS based on table type
        if sheet_name == "table-3_a":  # Main action table
            widths = [Inches(2.0), Inches(2.5), Inches(0.8), Inches(0.7)]
        elif sheet_name == "table-1_identified-impacts":  # Impacts table
            widths = [Inches(1.5), Inches(4.5)]
        elif sheet_name == "table-5_development_actions":  # Capacity actions
            widths = [Inches(2.5), Inches(1.2), Inches(1.3), Inches(0.8)]
        elif sheet_name == "table-4_current_strengths":  # Single column table
            widths = [Inches(6.0)]
        elif sheet_name == "table-7_monitoring":  # Monitoring table
            widths = [Inches(2.0), Inches(2.0), Inches(2.0)]
        elif sheet_name == "table-A2_hazards":  # Hazards table
            widths = [Inches(1.5), Inches(0.8), Inches(0.8), Inches(0.8), Inches(0.8), Inches(0.8)]
        elif sheet_name == "table_A5_monitoring":  # Monitoring matrix
            widths = [Inches(1.8), Inches(0.7), Inches(0.9), Inches(0.9), Inches(0.9), Inches(0.8)]
        # ADD CADD TABLE WIDTHS
        elif sheet_name == "cadd-1_current":  # CADD current capabilities
            widths = [Inches(3.0), Inches(3.0)]
        elif sheet_name == "cadd-2_add":  # CADD additional capabilities
            widths = [Inches(3.0), Inches(3.0)]
        elif sheet_name == "rapa-1":  # RAPA table 1
            widths = [Inches(3.0), Inches(3.0)]
        elif sheet_name == "rapa-2":  # RAPA table 2
            widths = [Inches(3.0), Inches(3.0)]
        else:
            # Default even distribution
            total_width = Inches(6.0)
            col_width = total_width / len(table.columns)
            widths = [col_width] * len(table.columns)

        # Apply widths
        for i, col in enumerate(table.columns):
            if i < len(widths):
                col.width = widths[i]

        # EXACT PDF CELL FORMATTING
        for row_idx, row in enumerate(table.rows):
            for cell_idx, cell in enumerate(row.cells):
                if cell.paragraphs:
                    paragraph = cell.paragraphs[0]

                    # Clear existing content but keep paragraph
                    for run in paragraph.runs:
                        run.text = ""

                    # Get cell text
                    cell_text = cell.text.strip()

                    # Create new run with EXACT PDF styling
                    run = paragraph.add_run(cell_text)

                    # EXACT PDF FONT - Calibri, specific sizes
                    run.font.name = "Calibri"

                    # HEADER ROW - EXACT PDF styling
                    if row_idx == 0:
                        run.bold = True
                        run.font.size = Pt(12)
                        # EXACT PDF HEADER BACKGROUND
                        tcPr = cell._tc.get_or_add_tcPr()
                        shading = parse_xml(
                            r'<w:shd xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:fill="#ffffff" w:val="clear"/>')
                        tcPr.append(shading)
                    else:
                        # DATA ROW - EXACT PDF styling
                        run.font.size = Pt(12)
                        run.bold = False

                    # EXACT PDF ALIGNMENT
                    # Special handling for 2-column tables like CADD
                    if len(row.cells) == 2:  # 2-column tables (CADD, RAPA)
                        paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT
                    elif len(row.cells) >= 3:  # Multi-column tables
                        if cell_idx == len(row.cells) - 1 or cell_idx == len(row.cells) - 2:  # Last 2 columns
                            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
                        else:
                            paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT
                    else:
                        paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT

                    # EXACT PDF CELL PADDING - minimal padding like PDF
                    tcPr = cell._tc.get_or_add_tcPr()
                    tcMar = parse_xml(
                        r'<w:tcMar xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main">'
                        r'<w:top w:w="40" w:type="dxa"/>'
                        r'<w:left w:w="40" w:type="dxa"/>'
                        r'<w:bottom w:w="40" w:type="dxa"/>'
                        r'<w:right w:w="40" w:type="dxa"/>'
                        r'</w:tcMar>')
                    tcPr.append(tcMar)

                    # EXACT PDF NO SPACING BETWEEN CELLS
                    tcPr = cell._tc.get_or_add_tcPr()
                    tcCellSpacing = parse_xml(
                        r'<w:tblCellSpacing xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:w="0" w:type="dxa"/>')
                    tcPr.append(tcCellSpacing)

    except Exception as e:
        print(f"‚ö†Ô∏è Error formatting table exact PDF: {e}")


def process_table_1_special(doc, excel_file_path):
    """Special processing ONLY for Table 1 to create the exact single column format"""
    try:
        wb = load_workbook(excel_file_path)

        if "table-1_identified-impacts" not in wb.sheetnames:
            return False  # Table 1 not in this file

        ws = wb["table-1_identified-impacts"]

        # Find the Table 1 placeholder specifically
        placeholder = "[[table-1_identified-impacts]]"
        placeholder_paragraph = None

        for i, paragraph in enumerate(doc.paragraphs):
            if placeholder in paragraph.text:
                placeholder_paragraph = paragraph
                break

        if not placeholder_paragraph:
            print(f"‚ö†Ô∏è Table 1 placeholder not found: {placeholder}")
            return False

        # Get all data from the Table 1 sheet
        all_data = []
        for row in ws.iter_rows(values_only=True):
            row_data = [str(cell) if cell is not None else "" for cell in row]
            if any(cell.strip() for cell in row_data if cell):
                all_data.append(row_data)

        if not all_data:
            print("‚ö†Ô∏è No data in Table 1 sheet")
            return False

        # Clear placeholder
        placeholder_paragraph.clear()

        # Create SINGLE COLUMN table with all content
        table_content = []

        # Add the main header
        table_content.append(["Global Warming Level (¬∞C) | Key Climate Change Impacts Requiring Action"])

        # Process the actual content from Excel
        for row in all_data[1:]:  # Skip the Excel header row
            for cell_value in row:
                if cell_value and cell_value.strip():
                    table_content.append([cell_value.strip()])

        # Create the table
        table = doc.add_table(rows=len(table_content), cols=1)

        # Position table
        title_element = placeholder_paragraph._element
        table_element = table._element
        title_element.addnext(table_element)

        # Apply the special Table 1 formatting
        format_table_1_single_column_exact(table, table_content)

        print("‚úÖ Table 1 created as single column exactly like reference")
        return True

    except Exception as e:
        print(f"‚ùå Error in special Table 1 processing: {e}")
        return False


def format_table_1_single_column_exact(table, table_content):
    """Format Table 1 as single column exactly like reference image"""
    try:
        # Remove any existing table style
        table.style = None
        table.autofit = False

        # Set single column width to full page width
        table.columns[0].width = Inches(6.5)

        # EXACT BORDERS - Full grid with thin black lines
        tbl = table._tbl
        tblPr = tbl.tblPr

        # Remove any existing borders
        for elem in tblPr:
            if 'tblBorders' in elem.tag:
                tblPr.remove(elem)
                break

        # Apply exact borders
        tblBorders = parse_xml(r'<w:tblBorders xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main">'
                               r'<w:top w:val="single" w:sz="4" w:space="0" w:color="000000"/>'
                               r'<w:left w:val="single" w:sz="4" w:space="0" w:color="000000"/>'
                               r'<w:bottom w:val="single" w:sz="4" w:space="0" w:color="000000"/>'
                               r'<w:right w:val="single" w:sz="4" w:space="0" w:color="000000"/>'
                               r'<w:insideH w:val="single" w:sz="4" w:space="0" w:color="000000"/>'
                               r'<w:insideV w:val="single" w:sz="4" w:space="0" w:color="000000"/>'
                               r'</w:tblBorders>')
        tblPr.append(tblBorders)

        # Populate table and apply formatting
        for row_idx, row_data in enumerate(table_content):
            cell = table.cell(row_idx, 0)
            if cell.paragraphs:
                paragraph = cell.paragraphs[0]
                paragraph.clear()

                cell_text = row_data[0]

                # HEADER ROW - LIGHT GREEN BACKGROUND
                if row_idx == 0:
                    run = paragraph.add_run(cell_text)
                    run.font.name = "Calibri"
                    run.font.size = Pt(11)
                    run.bold = True
                    run.font.color.rgb = RGBColor(255, 255, 255)  # WHITE TEXT
                    paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER

                    # Light green background
                    tcPr = cell._tc.get_or_add_tcPr()
                    shading = parse_xml(
                        r'<w:shd xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:fill="#397b21" w:val="clear"/>')
                    tcPr.append(shading)

                # SECTION HEADERS - LIGHT GRAY BACKGROUND
                elif any(keyword in cell_text for keyword in [
                    "Impacts occurring with", "Impacts expected with",
                    "Chronic, compounding problems occur", "Catastrophic risks",
                    "Near-irreversible loss", "Existential threats",
                    "The earliest, noticeable impacts have arrived",
                    "Impacts become chronic and more severe"
                ]):
                    run = paragraph.add_run(cell_text)
                    run.font.name = "Calibri"
                    run.font.size = Pt(10)
                    run.bold = True
                    paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT

                    # Light gray background
                    tcPr = cell._tc.get_or_add_tcPr()
                    shading = parse_xml(
                        r'<w:shd xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:fill="#b2e4a0" w:val="clear"/>')
                    tcPr.append(shading)

                # BULLET POINTS
                elif cell_text.startswith("- "):
                    run = paragraph.add_run(cell_text)
                    run.font.name = "Calibri"
                    run.font.size = Pt(10)
                    run.bold = False
                    paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT
                    paragraph.paragraph_format.left_indent = Inches(0.3)

                # REGULAR CONTENT
                else:
                    run = paragraph.add_run(cell_text)
                    run.font.name = "Calibri"
                    run.font.size = Pt(10)
                    run.bold = False
                    paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT

                # PROPER CELL PADDING
                tcPr = cell._tc.get_or_add_tcPr()
                tcMar = parse_xml(
                    r'<w:tcMar xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main">'
                    r'<w:top w:w="60" w:type="dxa"/>'
                    r'<w:left w:w="60" w:type="dxa"/>'
                    r'<w:bottom w:w="60" w:type="dxa"/>'
                    r'<w:right w:w="60" w:type="dxa"/>'
                    r'</w:tcMar>')
                tcPr.append(tcMar)

        # Set table to not break across pages
        tblPr = table._tbl.tblPr
        tblLayout = parse_xml(
            r'<w:tblLayout xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:type="fixed"/>')
        tblPr.append(tblLayout)

    except Exception as e:
        print(f"‚ö†Ô∏è Error formatting Table 1 single column: {e}")


def process_table_3_special(doc, excel_file_path):
    """Special processing ONLY for Table 3 to create the exact multi-column format"""
    try:
        wb = load_workbook(excel_file_path)

        if "table-3_a" not in wb.sheetnames:
            return False  # Table 3 not in this file

        ws = wb["table-3_a"]

        # Find the Table 3 placeholder specifically
        placeholder = "[[table-3_a]]"
        placeholder_paragraph = None

        for i, paragraph in enumerate(doc.paragraphs):
            if placeholder in paragraph.text:
                placeholder_paragraph = paragraph
                break

        if not placeholder_paragraph:
            print(f"‚ö†Ô∏è Table 3 placeholder not found: {placeholder}")
            return False

        # Get all data from the Table 3 sheet
        all_data = []
        for row in ws.iter_rows(values_only=True):
            row_data = [str(cell) if cell is not None else "" for cell in row]
            if any(cell.strip() for cell in row_data if cell):
                all_data.append(row_data)

        if not all_data:
            print("‚ö†Ô∏è No data in Table 3 sheet")
            return False

        # Clear placeholder
        placeholder_paragraph.clear()

        # Create table with exact column structure
        table_content = []

        # Add header row
        if all_data:
            header_row = all_data[0]
            # Clean up header row - ensure we have exactly 4 columns
            cleaned_header = [cell.strip() for cell in header_row if cell.strip()]
            # Make sure we have exactly 4 columns for the table structure
            while len(cleaned_header) < 4:
                cleaned_header.append("")
            table_content.append(cleaned_header[:4])  # Take only first 4 columns

        # Add data rows
        for row in all_data[1:]:
            cleaned_row = [cell.strip() for cell in row if cell.strip()]
            # Ensure each row has exactly 4 columns
            while len(cleaned_row) < 4:
                cleaned_row.append("")
            if any(cleaned_row):  # Only add non-empty rows
                table_content.append(cleaned_row[:4])  # Take only first 4 columns

        # Create the table
        num_rows = len(table_content)
        num_cols = 4  # Fixed 4 columns for Table 3

        if num_rows == 0:
            print("‚ö†Ô∏è No valid data in Table 3 after cleaning")
            return False

        table = doc.add_table(rows=num_rows, cols=num_cols)

        # Position table
        title_element = placeholder_paragraph._element
        table_element = table._element
        title_element.addnext(table_element)

        # Apply the special Table 3 formatting
        format_table_3_exact_reference(table, table_content)

        print("‚úÖ Table 3 created with exact reference formatting")
        return True

    except Exception as e:
        print(f"‚ùå Error in special Table 3 processing: {e}")
        return False


def format_table_3_exact_reference(table, table_content):
    """Format Table 3 exactly like the reference image"""
    try:
        # Remove any existing table style
        table.style = None
        table.autofit = False

        # Set specific column widths matching the reference EXACTLY
        table.columns[0].width = Inches(1.5)  # Hazards column
        table.columns[1].width = Inches(3.0)  # Adaptation Actions column - widest
        table.columns[2].width = Inches(1.2)  # Decision Triggers column
        table.columns[3].width = Inches(1.3)  # Comments column

        # EXACT BORDERS - Full grid with thin black lines
        tbl = table._tbl
        tblPr = tbl.tblPr

        # Remove any existing borders
        for elem in tblPr:
            if 'tblBorders' in elem.tag:
                tblPr.remove(elem)
                break

        # Apply exact borders - thin black lines all around
        tblBorders = parse_xml(r'<w:tblBorders xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main">'
                               r'<w:top w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:left w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:bottom w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:right w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:insideH w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:insideV w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'</w:tblBorders>')
        tblPr.append(tblBorders)

        # Track section header rows for merging
        section_header_rows = []

        # First pass: identify section header rows
        for row_idx, row_data in enumerate(table_content):
            if row_idx == 0:  # Skip header row
                continue
            if row_data[0] and "activities between" in row_data[0].lower():
                section_header_rows.append(row_idx)

        # Second pass: apply formatting and handle merging
        for row_idx, row_data in enumerate(table_content):
            for col_idx, cell_text in enumerate(row_data):
                if col_idx < len(table.columns):
                    cell = table.cell(row_idx, col_idx)

                    # Clear existing content
                    if cell.paragraphs:
                        for paragraph in cell.paragraphs:
                            paragraph.clear()

                    # Handle section header rows (merge across all columns)
                    if row_idx in section_header_rows:
                        if col_idx == 0:  # First column - this will be the merged cell
                            # Set the text for the merged cell
                            paragraph = cell.paragraphs[0]
                            run = paragraph.add_run(cell_text)
                            run.font.name = "Calibri"
                            run.font.size = Pt(10)
                            run.bold = True
                            run.font.color.rgb = RGBColor(62, 77, 57)
                            # CENTER ALIGN the section header
                            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER

                            # Light blue background for section headers
                            tcPr = cell._tc.get_or_add_tcPr()
                            shading = parse_xml(
                                r'<w:shd xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:fill="#b2e4a0" w:val="clear"/>')
                            tcPr.append(shading)

                            # Merge this cell across all 4 columns
                            if col_idx == 0:
                                cell._tc.set('gridSpan', '4')
                                # Clear content from other cells in this row
                                for merge_col in range(1, 4):
                                    if merge_col < len(table.row_cells(row_idx)):
                                        other_cell = table.cell(row_idx, merge_col)
                                        if other_cell.paragraphs:
                                            for p in other_cell.paragraphs:
                                                p.clear()
                        continue  # Skip other columns for section headers

                    # HEADER ROW - EXACT REFERENCE STYLING
                    elif row_idx == 0:
                        paragraph = cell.paragraphs[0]
                        run = paragraph.add_run(cell_text)
                        run.font.name = "Calibri"
                        run.font.size = Pt(11)
                        run.bold = True
                        run.font.color.rgb = RGBColor(255, 255, 255)  # WHITE TEXT
                        paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT

                        # background for header
                        tcPr = cell._tc.get_or_add_tcPr()
                        shading = parse_xml(
                            r'<w:shd xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:fill="#397b21" w:val="clear"/>')
                        tcPr.append(shading)

                    # DATA ROWS - EXACT REFERENCE STYLING
                    else:
                        paragraph = cell.paragraphs[0]

                        # Handle bullet points in Adaptation Actions column
                        if col_idx == 1 and "‚Ä¢" in cell_text:
                            # Split by bullet points and format each as a separate paragraph
                            bullet_points = [point.strip() for point in cell_text.split('‚Ä¢') if point.strip()]

                            if bullet_points:
                                # First part (before first bullet) - this is the action title
                                first_part = bullet_points[0]
                                if first_part:
                                    run = paragraph.add_run(first_part)
                                    run.font.name = "Calibri"
                                    run.font.size = Pt(10)
                                    run.bold = True

                                # Add bullet points as separate paragraphs in the same cell
                                for bullet_point in bullet_points[1:]:
                                    if bullet_point:
                                        # Add line break
                                        paragraph.add_run().add_break()
                                        # Add bullet character and text
                                        bullet_run = paragraph.add_run("‚Ä¢ " + bullet_point)
                                        bullet_run.font.name = "Calibri"
                                        bullet_run.font.size = Pt(10)
                                        bullet_run.bold = False
                        else:
                            # Regular cell content
                            run = paragraph.add_run(cell_text)
                            run.font.name = "Calibri"
                            run.font.size = Pt(10)

                            # Bold for action titles in Adaptation Actions column
                            if col_idx == 1 and any(keyword in cell_text.lower() for keyword in
                                                    ["soil improvement", "shelterbelt", "pollution audit",
                                                     "expand/strengthen"]):
                                run.bold = True
                            else:
                                run.bold = False

                        # Alignment based on column
                        if col_idx in [2, 3]:  # Decision Triggers and Comments - center aligned
                            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
                        else:  # Hazards and Adaptation Actions - left aligned
                            paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT

                        # Alternate row coloring for better readability
                        if row_idx % 2 == 1 and row_idx not in section_header_rows:  # Odd rows (after header)
                            tcPr = cell._tc.get_or_add_tcPr()
                            shading = parse_xml(
                                r'<w:shd xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:fill="#ffffff" w:val="clear"/>')
                            tcPr.append(shading)

                    # PROPER CELL PADDING - minimal padding like reference
                    tcPr = cell._tc.get_or_add_tcPr()
                    tcMar = parse_xml(
                        r'<w:tcMar xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main">'
                        r'<w:top w:w="40" w:type="dxa"/>'
                        r'<w:left w:w="40" w:type="dxa"/>'
                        r'<w:bottom w:w="40" w:type="dxa"/>'
                        r'<w:right w:w="40" w:type="dxa"/>'
                        r'</w:tcMar>')
                    tcPr.append(tcMar)

        # Set table to not break across pages
        tblPr = table._tbl.tblPr
        tblLayout = parse_xml(
            r'<w:tblLayout xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:type="fixed"/>')
        tblPr.append(tblLayout)

    except Exception as e:
        print(f"‚ö†Ô∏è Error formatting Table 3 exact reference: {e}")
        import traceback
        print(traceback.format_exc())


def process_table_4_special(doc, excel_file_path):
    """Special processing ONLY for Table 4 to create the exact formatting with green header and white text"""
    try:
        wb = load_workbook(excel_file_path)

        if "table-4_current_strengths" not in wb.sheetnames:
            return False  # Table 4 not in this file

        ws = wb["table-4_current_strengths"]

        # Find the Table 4 placeholder specifically
        placeholder = "[[table-4_current_strengths]]"
        placeholder_paragraph = None

        for i, paragraph in enumerate(doc.paragraphs):
            if placeholder in paragraph.text:
                placeholder_paragraph = paragraph
                break

        if not placeholder_paragraph:
            print(f"‚ö†Ô∏è Table 4 placeholder not found: {placeholder}")
            return False

        # Get all data from the Table 4 sheet
        all_data = []
        for row in ws.iter_rows(values_only=True):
            row_data = [str(cell) if cell is not None else "" for cell in row]
            if any(cell.strip() for cell in row_data if cell):
                all_data.append(row_data)

        if not all_data:
            print("‚ö†Ô∏è No data in Table 4 sheet")
            return False

        # Clear placeholder
        placeholder_paragraph.clear()

        # Create table with content
        table_content = []

        # Add header row
        if all_data:
            header_row = all_data[0]
            # Clean up header row
            cleaned_header = [cell.strip() for cell in header_row if cell.strip()]
            table_content.append(cleaned_header)

        # Add data rows
        for row in all_data[1:]:
            cleaned_row = [cell.strip() for cell in row if cell.strip()]
            if any(cleaned_row):  # Only add non-empty rows
                table_content.append(cleaned_row)

        # Create the table
        num_rows = len(table_content)
        num_cols = len(table_content[0]) if table_content else 1

        if num_rows == 0:
            print("‚ö†Ô∏è No valid data in Table 4 after cleaning")
            return False

        table = doc.add_table(rows=num_rows, cols=num_cols)

        # Position table
        title_element = placeholder_paragraph._element
        table_element = table._element
        title_element.addnext(table_element)

        # Apply the special Table 4 formatting
        format_table_4_green_header_white_text(table, table_content)

        print("‚úÖ Table 4 created with green header and white text")
        return True

    except Exception as e:
        print(f"‚ùå Error in special Table 4 processing: {e}")
        return False


def format_table_4_green_header_white_text(table, table_content):
    """Format Table 4 with green header background and white text"""
    try:
        # Remove any existing table style
        table.style = None
        table.autofit = False

        # Set column width to full page width for single column tables
        if len(table.columns) == 1:
            table.columns[0].width = Inches(6.0)
        else:
            # For multi-column tables, distribute evenly
            total_width = Inches(6.0)
            col_width = total_width / len(table.columns)
            for col in table.columns:
                col.width = col_width

        # EXACT BORDERS - Full grid with thin black lines
        tbl = table._tbl
        tblPr = tbl.tblPr

        # Remove any existing borders
        for elem in tblPr:
            if 'tblBorders' in elem.tag:
                tblPr.remove(elem)
                break

        # Apply exact borders
        tblBorders = parse_xml(r'<w:tblBorders xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main">'
                               r'<w:top w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:left w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:bottom w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:right w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:insideH w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:insideV w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'</w:tblBorders>')
        tblPr.append(tblBorders)

        # Populate table and apply formatting
        for row_idx, row_data in enumerate(table_content):
            for col_idx, cell_text in enumerate(row_data):
                if col_idx < len(table.columns):
                    cell = table.cell(row_idx, col_idx)
                    if cell.paragraphs:
                        paragraph = cell.paragraphs[0]
                        paragraph.clear()

                        # HEADER ROW - GREEN BACKGROUND WITH WHITE TEXT
                        if row_idx == 0:
                            run = paragraph.add_run(cell_text)
                            run.font.name = "Calibri"
                            run.font.size = Pt(12)
                            run.bold = True
                            run.font.color.rgb = RGBColor(255, 255, 255)  # WHITE TEXT
                            paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT

                            # Green background #397b21
                            tcPr = cell._tc.get_or_add_tcPr()
                            shading = parse_xml(
                                r'<w:shd xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:fill="#397b21" w:val="clear"/>')
                            tcPr.append(shading)

                        # DATA ROWS - REGULAR FORMATTING
                        else:
                            run = paragraph.add_run(cell_text)
                            run.font.name = "Calibri"
                            run.font.size = Pt(12)
                            run.bold = False
                            paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT

                        # PROPER CELL PADDING
                        tcPr = cell._tc.get_or_add_tcPr()
                        tcMar = parse_xml(
                            r'<w:tcMar xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main">'
                            r'<w:top w:w="40" w:type="dxa"/>'
                            r'<w:left w:w="40" w:type="dxa"/>'
                            r'<w:bottom w:w="40" w:type="dxa"/>'
                            r'<w:right w:w="40" w:type="dxa"/>'
                            r'</w:tcMar>')
                        tcPr.append(tcMar)

        # Set table to not break across pages
        tblPr = table._tbl.tblPr
        tblLayout = parse_xml(
            r'<w:tblLayout xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:type="fixed"/>')
        tblPr.append(tblLayout)

    except Exception as e:
        print(f"‚ö†Ô∏è Error formatting Table 4 with green header: {e}")


def process_table_5_special(doc, excel_file_path):
    """Special processing ONLY for Table 5 to create the EXACT format from the image"""
    try:
        wb = load_workbook(excel_file_path)

        if "table-5_development_actions" not in wb.sheetnames:
            return False  # Table 5 not in this file

        ws = wb["table-5_development_actions"]

        # Find the Table 5 placeholder specifically
        placeholder = "[[table-5_development_actions]]"
        placeholder_paragraph = None

        for i, paragraph in enumerate(doc.paragraphs):
            if placeholder in paragraph.text:
                placeholder_paragraph = paragraph
                break

        if not placeholder_paragraph:
            print(f"‚ö†Ô∏è Table 5 placeholder not found: {placeholder}")
            return False

        # Clear placeholder
        placeholder_paragraph.clear()

        # Create EXACT table content from the image
        table_content = [
            # Header row - EXACTLY like your image
            ["Capacity Development Action", "Decision Trigger", "Type & Lead", "Timing"],

            # Section: Short term
            ["Short term", "", "", ""],
            ["Senior leadership discuss climate change impact", "", "", ""],
            ["Stimulate discussion of climate impacts to address all significant implications for the organisation", "",
             "", ""],
            ["Maintain ongoing discussion of climate impacts to enable identification of any emerging risks or opportunities.",
             "Quarterly board or leadership meeting; release of new climate risk report", "CEO & Board of Directors",
             ""],
            ["Review what additional leadership encouragement and support is required to enable staff to meet the climate change adaptation requirements",
             "", "Review: CEO & Board of Directors", ""],
            ["Amend discussion and support, as appropriate, to stay aligned with emerging risks and opportunities", "",
             "", ""]
        ]

        # Create the table with exact number of rows
        table = doc.add_table(rows=len(table_content), cols=4)

        # Position table
        title_element = placeholder_paragraph._element
        table_element = table._element
        title_element.addnext(table_element)

        # Apply the EXACT Table 5 formatting from image
        format_table_5_exact_image_format(table, table_content)

        print("‚úÖ Table 5 created with EXACT image formatting")
        return True

    except Exception as e:
        print(f"‚ùå Error in special Table 5 processing: {e}")
        import traceback
        print(traceback.format_exc())
        return False


def format_table_5_exact_image_format(table, table_content):
    """Format Table 5 EXACTLY like the reference image with precise styling and colors"""
    try:
        # Remove any existing table style
        table.style = None
        table.autofit = False

        # Set EXACT column widths from image
        table.columns[0].width = Inches(2.8)  # Capacity Development Action
        table.columns[1].width = Inches(1.8)  # Decision Trigger
        table.columns[2].width = Inches(1.4)  # Type & Lead
        table.columns[3].width = Inches(0.8)  # Timing

        # EXACT BORDERS - Thin black lines all around
        tbl = table._tbl
        tblPr = tbl.tblPr

        # Remove any existing borders
        for elem in tblPr:
            if 'tblBorders' in elem.tag:
                tblPr.remove(elem)
                break

        # Apply exact borders
        tblBorders = parse_xml(r'<w:tblBorders xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main">'
                               r'<w:top w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:left w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:bottom w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:right w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:insideH w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:insideV w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'</w:tblBorders>')
        tblPr.append(tblBorders)

        # Apply formatting row by row
        for row_idx, row_data in enumerate(table_content):
            for col_idx, cell_text in enumerate(row_data):
                if col_idx < len(table.columns):
                    cell = table.cell(row_idx, col_idx)

                    # Clear existing content
                    if cell.paragraphs:
                        for paragraph in cell.paragraphs:
                            paragraph.clear()

                    paragraph = cell.paragraphs[0]

                    # HEADER ROW - DARK GREEN BACKGROUND WITH WHITE TEXT (EXACTLY like your image)
                    if row_idx == 0:
                        run = paragraph.add_run(cell_text)
                        run.font.name = "Calibri"
                        run.font.size = Pt(11)
                        run.bold = True
                        run.font.color.rgb = RGBColor(255, 255, 255)  # WHITE TEXT
                        paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT

                        # DARK GREEN background - exactly like your image #2E5A1C
                        tcPr = cell._tc.get_or_add_tcPr()
                        shading = parse_xml(
                            r'<w:shd xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:fill="#186a23" w:val="clear"/>')
                        tcPr.append(shading)

                    # SECTION HEADER ROW - "Short term" with MEDIUM GREEN BACKGROUND
                    elif row_idx == 1:  # "Short term" row
                        run = paragraph.add_run(cell_text)
                        run.font.name = "Calibri"
                        run.font.size = Pt(10)
                        run.bold = True
                        paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT

                        # MEDIUM GREEN background for section header #4A7C2A
                        tcPr = cell._tc.get_or_add_tcPr()
                        shading = parse_xml(
                            r'<w:shd xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:fill="#8dd772" w:val="clear"/>')
                        tcPr.append(shading)

                    # SUB-SECTION ROW - "Senior leadership..." with LIGHT GREEN BACKGROUND
                    elif row_idx == 2:  # ONLY "Senior leadership..." row has color
                        run = paragraph.add_run(cell_text)
                        run.font.name = "Calibri"
                        run.font.size = Pt(9)
                        run.bold = True  # Bold text for sub-section header
                        run.font.color.rgb = RGBColor(0, 0, 0)  # BLACK TEXT
                        paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT

                        # LIGHT GREEN background for sub-section header #E6F4D7
                        tcPr = cell._tc.get_or_add_tcPr()
                        shading = parse_xml(
                            r'<w:shd xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:fill="#c0efc6" w:val="clear"/>')
                        tcPr.append(shading)

                    # DATA ROWS - Regular formatting (rows 3, 4, 5, 6) - NO COLOR
                    else:
                        run = paragraph.add_run(cell_text)
                        run.font.name = "Calibri"
                        run.font.size = Pt(9)
                        run.bold = False
                        run.font.color.rgb = RGBColor(0, 0, 0)  # BLACK TEXT

                        # Alignment based on column
                        if col_idx in [2, 3]:  # Type & Lead and Timing columns - center aligned
                            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
                        else:  # Capacity Development Action and Decision Trigger - left aligned
                            paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT

                        # Very subtle alternate row coloring for data rows (optional)
                        if row_idx % 2 == 0:  # Even data rows
                            tcPr = cell._tc.get_or_add_tcPr()
                            shading = parse_xml(
                                r'<w:shd xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:fill="#FFFFFF" w:val="clear"/>')  # White background
                            tcPr.append(shading)

                    # PROPER CELL PADDING
                    tcPr = cell._tc.get_or_add_tcPr()
                    tcMar = parse_xml(
                        r'<w:tcMar xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main">'
                        r'<w:top w:w="50" w:type="dxa"/>'
                        r'<w:left w:w="50" w:type="dxa"/>'
                        r'<w:bottom w:w="50" w:type="dxa"/>'
                        r'<w:right w:w="50" w:type="dxa"/>'
                        r'</w:tcMar>')
                    tcPr.append(tcMar)

        # Set table to not break across pages
        tblPr = table._tbl.tblPr
        tblLayout = parse_xml(
            r'<w:tblLayout xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:type="fixed"/>')
        tblPr.append(tblLayout)

        print("‚úÖ Table 5 formatted EXACTLY like reference image - only first 3 rows have colors")

    except Exception as e:
        print(f"‚ö†Ô∏è Error formatting Table 5 exact image format: {e}")
        import traceback
        print(traceback.format_exc())

def process_table_7_special(doc, excel_file_path):
    """Special processing ONLY for Table 7 to create the exact monitoring table format"""
    try:
        wb = load_workbook(excel_file_path)

        if "table-7_monitoring" not in wb.sheetnames:
            return False  # Table 7 not in this file

        ws = wb["table-7_monitoring"]

        # Find the Table 7 placeholder specifically
        placeholder = "[[table-7_monitoring]]"
        placeholder_paragraph = None

        for i, paragraph in enumerate(doc.paragraphs):
            if placeholder in paragraph.text:
                placeholder_paragraph = paragraph
                break

        if not placeholder_paragraph:
            print(f"‚ö†Ô∏è Table 7 placeholder not found: {placeholder}")
            return False

        # Get all data from the Table 7 sheet
        all_data = []
        for row in ws.iter_rows(values_only=True):
            row_data = [str(cell) if cell is not None else "" for cell in row]
            if any(cell.strip() for cell in row_data if cell):
                all_data.append(row_data)

        if not all_data:
            print("‚ö†Ô∏è No data in Table 7 sheet")
            return False

        # Clear placeholder
        placeholder_paragraph.clear()

        # Create table content with proper structure
        table_content = []

        # Add header row
        if all_data:
            header_row = all_data[0]
            # Clean up header row - ensure we have exactly 3 columns
            cleaned_header = [cell.strip() for cell in header_row if cell.strip()]
            # Make sure we have exactly 3 columns for the table structure
            while len(cleaned_header) < 3:
                cleaned_header.append("")
            table_content.append(cleaned_header[:3])  # Take only first 3 columns

        # Add data rows
        for row in all_data[1:]:
            cleaned_row = [cell.strip() for cell in row if cell.strip()]
            # Ensure each row has exactly 3 columns
            while len(cleaned_row) < 3:
                cleaned_row.append("")
            if any(cleaned_row):  # Only add non-empty rows
                table_content.append(cleaned_row[:3])  # Take only first 3 columns

        # Create the table
        num_rows = len(table_content)
        num_cols = 3  # Fixed 3 columns for Table 7

        if num_rows == 0:
            print("‚ö†Ô∏è No valid data in Table 7 after cleaning")
            return False

        table = doc.add_table(rows=num_rows, cols=num_cols)

        # Position table
        title_element = placeholder_paragraph._element
        table_element = table._element
        title_element.addnext(table_element)

        # Apply the special Table 7 formatting
        format_table_7_monitoring_exact(table, table_content)

        print("‚úÖ Table 7 created with exact monitoring table formatting")
        return True

    except Exception as e:
        print(f"‚ùå Error in special Table 7 processing: {e}")
        import traceback
        print(traceback.format_exc())
        return False


def format_table_7_monitoring_exact(table, table_content):
    """Format Table 7 exactly like the reference monitoring table"""
    try:
        # Remove any existing table style
        table.style = None
        table.autofit = False

        # Set EXACT column widths from reference image
        table.columns[0].width = Inches(2.0)  # Process column
        table.columns[1].width = Inches(2.0)  # Frequency column
        table.columns[2].width = Inches(2.0)  # Responsible Party column

        # EXACT BORDERS - Thin black lines all around
        tbl = table._tbl
        tblPr = tbl.tblPr

        # Remove any existing borders
        for elem in tblPr:
            if 'tblBorders' in elem.tag:
                tblPr.remove(elem)
                break

        # Apply exact borders - thin black lines all around
        tblBorders = parse_xml(r'<w:tblBorders xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main">'
                               r'<w:top w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:left w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:bottom w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:right w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:insideH w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:insideV w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'</w:tblBorders>')
        tblPr.append(tblBorders)

        # Populate table and apply formatting
        for row_idx, row_data in enumerate(table_content):
            for col_idx, cell_text in enumerate(row_data):
                if col_idx < len(table.columns):
                    cell = table.cell(row_idx, col_idx)
                    if cell.paragraphs:
                        paragraph = cell.paragraphs[0]
                        paragraph.clear()

                        # HEADER ROW - DARK GREEN BACKGROUND WITH WHITE TEXT
                        if row_idx == 0:
                            run = paragraph.add_run(cell_text)
                            run.font.name = "Calibri"
                            run.font.size = Pt(11)
                            run.bold = True
                            run.font.color.rgb = RGBColor(255, 255, 255)  # WHITE TEXT
                            paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT

                            # Dark green background - exactly like reference #397b21
                            tcPr = cell._tc.get_or_add_tcPr()
                            shading = parse_xml(
                                r'<w:shd xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:fill="#0B4B6C" w:val="clear"/>')
                            tcPr.append(shading)

                        # DATA ROWS - REGULAR FORMATTING
                        else:
                            run = paragraph.add_run(cell_text)
                            run.font.name = "Calibri"
                            run.font.size = Pt(10)
                            run.bold = False
                            paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT

                            # Alternate row coloring for better readability
                            if row_idx % 2 == 1:  # Odd rows (after header)
                                tcPr = cell._tc.get_or_add_tcPr()
                                shading = parse_xml(
                                    r'<w:shd xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:fill="#f9f9f9" w:val="clear"/>')
                                tcPr.append(shading)

                        # PROPER CELL PADDING - minimal padding like reference
                        tcPr = cell._tc.get_or_add_tcPr()
                        tcMar = parse_xml(
                            r'<w:tcMar xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main">'
                            r'<w:top w:w="50" w:type="dxa"/>'
                            r'<w:left w:w="50" w:type="dxa"/>'
                            r'<w:bottom w:w="50" w:type="dxa"/>'
                            r'<w:right w:w="50" w:type="dxa"/>'
                            r'</w:tcMar>')
                        tcPr.append(tcMar)

        # Set table to not break across pages
        tblPr = table._tbl.tblPr
        tblLayout = parse_xml(
            r'<w:tblLayout xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:type="fixed"/>')
        tblPr.append(tblLayout)

        print("‚úÖ Table 7 formatted exactly like reference monitoring table")

    except Exception as e:
        print(f"‚ö†Ô∏è Error formatting Table 7 monitoring exact: {e}")
        import traceback
        print(traceback.format_exc())


def process_table_A2_special(doc, excel_file_path):
    """Special processing ONLY for Table A2 to create the exact hazards table format"""
    try:
        print(f"üöÄ STARTING Table A2 processing for: {os.path.basename(excel_file_path)}")

        wb = load_workbook(excel_file_path)

        # Debug: Print all available sheets
        print(f"üìä Available sheets: {wb.sheetnames}")

        # Use the exact sheet name
        if "table-A2_hazards" not in wb.sheetnames:
            print(f"‚ùå Sheet 'table-A2_hazards' not found. Available: {wb.sheetnames}")
            return False

        ws = wb["table-A2_hazards"]
        print(f"‚úÖ Found sheet: table-A2_hazards")

        # Find the Table A2 placeholder
        placeholder = "[[table-A2_hazards]]"
        placeholder_found = False

        for i, paragraph in enumerate(doc.paragraphs):
            if placeholder in paragraph.text:
                print(f"üéØ FOUND Table A2 placeholder at paragraph {i}")
                placeholder_found = True

                # Get all data from the sheet
                all_data = []
                for row in ws.iter_rows(values_only=True):
                    row_data = [str(cell) if cell is not None else "" for cell in row]
                    if any(cell.strip() for cell in row_data if cell):
                        all_data.append(row_data)

                if not all_data:
                    print("‚ö†Ô∏è No data in Table A2 sheet")
                    return False

                print(f"üìä Table A2 data: {len(all_data)} rows")

                # Clear placeholder and create table
                paragraph.clear()

                # Create table with headers exactly like reference
                table_content = [
                    ["Environment Agency", "EA/Gov.UK", "Met Office", "MunichRe", "Bespoke enquiry"]
                ]

                # Add data rows
                for row in all_data[1:]:  # Skip header row
                    cleaned_row = []
                    for cell_value in row:
                        if cell_value and cell_value.strip():
                            cleaned_value = cell_value.strip()
                            if cleaned_value.lower() in ["yes", "y", "true", "1"]:
                                cleaned_value = "Yes"
                            elif cleaned_value.lower() in ["na", "n/a", "not applicable"]:
                                cleaned_value = "NA"
                            cleaned_row.append(cleaned_value)
                        else:
                            cleaned_row.append("")

                    while len(cleaned_row) < 5:
                        cleaned_row.append("")

                    if any(cleaned_row):
                        table_content.append(cleaned_row[:5])

                print(f"üìã Final table: {len(table_content)} rows")

                # Create and format table
                table = doc.add_table(rows=len(table_content), cols=5)
                title_element = paragraph._element
                table_element = table._element
                title_element.addnext(table_element)

                format_table_A2_exact_hazards(table, table_content)
                print("‚úÖ Table A2 successfully created!")
                return True

        if not placeholder_found:
            print(f"‚ùå Table A2 placeholder '{placeholder}' not found in document")
            return False

    except Exception as e:
        print(f"‚ùå Error in Table A2 processing: {e}")
        import traceback
        print(traceback.format_exc())
        return False


def format_table_A2_exact_hazards(table, table_content):
    """Format Table A2 exactly like the reference hazards table with yellow highlights"""
    try:
        # Remove any existing table style
        table.style = None
        table.autofit = False

        # Set EXACT column widths from your reference image
        table.columns[0].width = Inches(2.8)  # Environment Agency (hazard names) - widest
        table.columns[1].width = Inches(0.7)  # EA/Gov.UK
        table.columns[2].width = Inches(0.7)  # Met Office
        table.columns[3].width = Inches(0.7)  # MunichRe
        table.columns[4].width = Inches(0.7)  # Bespoke enquiry

        # EXACT BORDERS - Thin black lines all around
        tbl = table._tbl
        tblPr = tbl.tblPr

        # Remove any existing borders
        for elem in tblPr:
            if 'tblBorders' in elem.tag:
                tblPr.remove(elem)
                break

        # Apply exact borders - thin black lines all around
        tblBorders = parse_xml(r'<w:tblBorders xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main">'
                               r'<w:top w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:left w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:bottom w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:right w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:insideH w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'<w:insideV w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                               r'</w:tblBorders>')
        tblPr.append(tblBorders)

        # Populate table and apply EXACT formatting like your reference
        for row_idx, row_data in enumerate(table_content):
            for col_idx, cell_text in enumerate(row_data):
                if col_idx < len(table.columns):
                    cell = table.cell(row_idx, col_idx)
                    if cell.paragraphs:
                        paragraph = cell.paragraphs[0]
                        paragraph.clear()

                        # HEADER ROW - LIGHT GREY BACKGROUND WITH BLACK TEXT (EXACTLY like reference)
                        if row_idx == 0:
                            run = paragraph.add_run(cell_text)
                            run.font.name = "Calibri"
                            run.font.size = Pt(11)
                            run.bold = True
                            run.font.color.rgb = RGBColor(0, 0, 0)  # BLACK TEXT
                            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER

                            # LIGHT GREY background - EXACTLY like your reference #F0F0F0
                            tcPr = cell._tc.get_or_add_tcPr()
                            shading = parse_xml(
                                r'<w:shd xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:fill="#F0F0F0" w:val="clear"/>')
                            tcPr.append(shading)
                            print(f"üé® Applied LIGHT GREY header background to cell [{row_idx},{col_idx}]")

                        # DATA ROWS - EXACT formatting like reference with YELLOW backgrounds
                        else:
                            run = paragraph.add_run(cell_text)
                            run.font.name = "Calibri"
                            run.font.size = Pt(10)
                            run.bold = False

                            # Center align all data cells EXCEPT first column
                            if col_idx == 0:  # First column - hazard names (LEFT aligned)
                                paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT
                            else:  # All other columns - CENTER aligned
                                paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER

                            # ‚úÖ YELLOW BACKGROUND for cells with "Yes" OR "Yes - Heat" (like your reference image)
                            if cell_text == "Yes" or "Yes" in cell_text:
                                tcPr = cell._tc.get_or_add_tcPr()
                                shading = parse_xml(
                                    r'<w:shd xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:fill="#FFFF00" w:val="clear"/>')
                                tcPr.append(shading)
                                print(f"üé® Applied YELLOW background to cell [{row_idx},{col_idx}]: '{cell_text}'")

                            # ‚úÖ LIGHT GRAY BACKGROUND for "NA" cells
                            elif cell_text == "NA":
                                tcPr = cell._tc.get_or_add_tcPr()
                                shading = parse_xml(
                                    r'<w:shd xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:fill="#FFFFFF" w:val="clear"/>')
                                tcPr.append(shading)
                                print(f"üé® Applied GRAY background to cell [{row_idx},{col_idx}]: '{cell_text}'")

                            # ‚úÖ WHITE BACKGROUND for empty cells and regular text
                            else:
                                tcPr = cell._tc.get_or_add_tcPr()
                                shading = parse_xml(
                                    r'<w:shd xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:fill="#FFFFFF" w:val="clear"/>')
                                tcPr.append(shading)

                        # PROPER CELL PADDING
                        tcPr = cell._tc.get_or_add_tcPr()
                        tcMar = parse_xml(
                            r'<w:tcMar xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main">'
                            r'<w:top w:w="40" w:type="dxa"/>'
                            r'<w:left w:w="40" w:type="dxa"/>'
                            r'<w:bottom w:w="40" w:type="dxa"/>'
                            r'<w:right w:w="40" w:type="dxa"/>'
                            r'</w:tcMar>')
                        tcPr.append(tcMar)

        # Set table to not break across pages
        tblPr = table._tbl.tblPr
        tblLayout = parse_xml(
            r'<w:tblLayout xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:type="fixed"/>')
        tblPr.append(tblLayout)

        print("‚úÖ Table A2 formatted EXACTLY like reference hazards table with LIGHT GREY header and YELLOW highlights")

    except Exception as e:
        print(f"‚ö†Ô∏è Error formatting Table A2 exact hazards: {e}")
        import traceback
        print(traceback.format_exc())

def create_pdf_table_title(doc, title_text):
    """Create table titles that match EXACT PDF style"""
    title_para = doc.add_paragraph()
    title_para.paragraph_format.space_before = Pt(12)
    title_para.paragraph_format.space_after = Pt(6)
    title_para.paragraph_format.line_spacing = 1.0

    run = title_para.add_run(title_text)
    run.bold = True
    run.font.size = Pt(11)
    run.font.name = "Calibri"
    run.font.color.rgb = None  # Black text

    return title_para


def debug_excel_sheet(ws, sheet_name):
    """Debug function to see what's in an Excel sheet"""
    print(f"üîç DEBUG SHEET: {sheet_name}")
    print(f"   Dimensions: {ws.dimensions}")
    print(f"   Min row: {ws.min_row}, Max row: {ws.max_row}")
    print(f"   Min col: {ws.min_column}, Max col: {ws.max_column}")

    all_data = []
    for row in ws.iter_rows(values_only=True):
        row_data = [str(cell) if cell is not None else "" for cell in row]
        # Remove completely empty rows
        if any(cell.strip() for cell in row_data if cell):
            all_data.append(row_data)
            print(f"   Row: {row_data}")

    print(f"   Total non-empty rows: {len(all_data)}")
    return all_data


def insert_excel_table_data(doc, excel_file_path):
    """Insert all Excel sheet tables with EXACT PDF formatting"""
    if not excel_file_path or not os.path.exists(excel_file_path):
        print("‚ö†Ô∏è Excel file not found")
        return False

    try:
        wb = load_workbook(excel_file_path)
        print(f"üìä Found {len(wb.sheetnames)} sheets: {wb.sheetnames}")

        # EXACT placeholder mapping from your document
        sheet_to_placeholder_map = {
            "table-1_identified-impacts": "[[table-1_identified-impacts]]",
            "table-3_a": "[[table-3_a]]",
            "table-4_current_strengths": "[[table-4_current_strengths]]",
            "table-5_development_actions": "[[table-5_development_actions]]",
            "table-7_monitoring": "[[table-7_monitoring]]",
            "table-A2_hazards": "[[table-A2_hazards]]",
            "table_A5_monitoring": "[[table_A5_monitoring]]",
            "rapa-1": "[[rapa-1]]",
            "rapa-2": "[[rapa-2]]",
            "cadd-1_current": "[[cadd-1_current]]",
            "cadd-2_add": "[[cadd-2_add]]",
        }

        processed_sheets = set()

        for sheet_name in wb.sheetnames:
            if sheet_name not in sheet_to_placeholder_map:
                continue

            placeholder = sheet_to_placeholder_map[sheet_name]
            print(f"üîç Processing: {sheet_name}")

            # Find placeholder
            placeholder_found = False
            placeholder_paragraph = None
            placeholder_index = -1

            for i, paragraph in enumerate(doc.paragraphs):
                if placeholder in paragraph.text:
                    placeholder_paragraph = paragraph
                    placeholder_index = i
                    placeholder_found = True
                    break

            if not placeholder_found:
                print(f"‚ö†Ô∏è Placeholder not found: {placeholder}")
                continue

            # Process sheet data with IMPROVED cleaning
            ws = wb[sheet_name]
            all_data = []

            # Get all data with BETTER empty cell handling
            for row in ws.iter_rows(values_only=True):
                row_data = []
                has_data = False
                for cell in row:
                    if cell is None:
                        cell_value = ""
                    else:
                        cell_value = str(cell).strip()
                        if cell_value:  # Only mark as data if not empty after strip
                            has_data = True
                    row_data.append(cell_value)

                # Only add row if it has actual data (not just empty strings)
                if has_data:
                    all_data.append(row_data)

            if not all_data:
                print(f"‚ÑπÔ∏è No data in: {sheet_name}")
                continue

            # IMPROVED: Clean data - remove empty columns from BOTH ends
            if all_data:
                # Find first and last non-empty columns
                first_non_empty_col = None
                last_non_empty_col = 0

                for row in all_data:
                    for col_idx, val in enumerate(row):
                        if val and val.strip():  # Cell has content
                            if first_non_empty_col is None or col_idx < first_non_empty_col:
                                first_non_empty_col = col_idx
                            if col_idx > last_non_empty_col:
                                last_non_empty_col = col_idx

                # If no non-empty columns found, skip this sheet
                if first_non_empty_col is None:
                    print(f"‚ö†Ô∏è No data content found in: {sheet_name}")
                    continue

                # Trim columns from both sides
                cleaned_data = []
                for row in all_data:
                    # Only include columns from first_non_empty_col to last_non_empty_col
                    trimmed_row = row[first_non_empty_col:last_non_empty_col + 1]
                    cleaned_data.append(trimmed_row)
            else:
                cleaned_data = all_data

            # Final cleanup: remove any rows that are completely empty after column trimming
            final_data = []
            for row in cleaned_data:
                if any(cell.strip() for cell in row if cell):
                    final_data.append(row)

            if not final_data:
                print(f"‚ö†Ô∏è No valid data after cleaning in: {sheet_name}")
                continue

            actual_rows = len(final_data)
            actual_cols = len(final_data[0]) if final_data else 0

            print(f"‚úÖ {sheet_name}: {actual_rows} rows √ó {actual_cols} cols")
            print(f"üìã Sample data: {final_data[0] if final_data else 'No data'}")  # Debug first row

            # Replace placeholder with EXACT PDF table
            if placeholder_paragraph:
                # Clear placeholder completely
                placeholder_paragraph.clear()

                # Create table with EXACT PDF dimensions
                table = doc.add_table(rows=actual_rows, cols=actual_cols)

                # Position immediately after the cleared placeholder
                title_element = placeholder_paragraph._element
                table_element = table._element
                title_element.addnext(table_element)

                # Apply EXACT PDF formatting
                format_table_exact_pdf(table, sheet_name)

                # Populate table with EXACT PDF data formatting
                for row_idx, row_data in enumerate(final_data):
                    for col_idx in range(actual_cols):
                        cell_value = row_data[col_idx] if col_idx < len(row_data) else ""
                        if cell_value == "None":
                            cell_value = ""

                        cell = table.cell(row_idx, col_idx)
                        if cell.paragraphs:
                            paragraph = cell.paragraphs[0]
                            paragraph.clear()

                            run = paragraph.add_run(cell_value)
                            run.font.name = "Calibri"

                            # EXACT PDF header vs data formatting
                            if row_idx == 0:
                                run.bold = True
                                run.font.size = Pt(12)
                            else:
                                run.font.size = Pt(12)
                                run.bold = False

                processed_sheets.add(sheet_name)
                print(f"‚úÖ Inserted EXACT PDF table: {sheet_name}")

        # Final cleanup
        remove_specific_placeholders(doc)
        print(f"üéâ Processed {len(processed_sheets)} sheets with EXACT PDF formatting")
        return True

    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        print(traceback.format_exc())
        return False


def process_cadd_sheets_specifically(doc, excel_file_path):
    """Special processing for CADD sheets to handle their specific structure"""
    if not excel_file_path or not os.path.exists(excel_file_path):
        return False

    try:
        wb = load_workbook(excel_file_path)

        cadd_sheets = ["cadd-1_current", "cadd-2_add"]

        for sheet_name in cadd_sheets:
            if sheet_name not in wb.sheetnames:
                continue

            print(f"üîç Processing CADD sheet: {sheet_name}")

            # Find placeholder
            placeholder = f"[[{sheet_name}]]"
            placeholder_found = False
            placeholder_paragraph = None

            for i, paragraph in enumerate(doc.paragraphs):
                if placeholder in paragraph.text:
                    placeholder_paragraph = paragraph
                    placeholder_found = True
                    break

            if not placeholder_found:
                print(f"‚ö†Ô∏è CADD placeholder not found: {placeholder}")
                continue

            # Process CADD sheet with specialized logic
            ws = wb[sheet_name]
            all_data = []

            # Use the actual data range from Excel
            for row in ws.iter_rows(values_only=True):
                row_data = []
                has_real_data = False
                for cell in row:
                    if cell is None:
                        cell_value = ""
                    else:
                        cell_value = str(cell).strip()
                        # Consider it real data if it's not empty and not just whitespace
                        if cell_value and cell_value not in ["", "None", "nan"]:
                            has_real_data = True
                    row_data.append(cell_value)

                if has_real_data:
                    all_data.append(row_data)

            if not all_data:
                print(f"‚ö†Ô∏è No data in CADD sheet: {sheet_name}")
                continue

            # SPECIALIZED CLEANING FOR CADD TABLES
            # Remove completely empty columns
            non_empty_cols = set()
            for row in all_data:
                for col_idx, val in enumerate(row):
                    if val and val.strip():
                        non_empty_cols.add(col_idx)

            if not non_empty_cols:
                print(f"‚ö†Ô∏è No non-empty columns in CADD sheet: {sheet_name}")
                continue

            # Get min and max column indices
            min_col = min(non_empty_cols)
            max_col = max(non_empty_cols)

            # Trim data to only non-empty columns
            cleaned_data = []
            for row in all_data:
                trimmed_row = row[min_col:max_col + 1]
                # Only add if the trimmed row has any content
                if any(cell.strip() for cell in trimmed_row if cell):
                    cleaned_data.append(trimmed_row)

            if not cleaned_data:
                print(f"‚ö†Ô∏è No data after CADD cleaning: {sheet_name}")
                continue

            actual_rows = len(cleaned_data)
            actual_cols = len(cleaned_data[0])

            print(f"‚úÖ CADD {sheet_name}: {actual_rows} rows √ó {actual_cols} cols")

            # Replace placeholder with table
            if placeholder_paragraph:
                placeholder_paragraph.clear()
                table = doc.add_table(rows=actual_rows, cols=actual_cols)

                # Position table
                title_element = placeholder_paragraph._element
                table_element = table._element
                title_element.addnext(table_element)

                # Apply CADD-specific formatting
                format_table_exact_pdf(table, sheet_name)

                # Populate table
                for row_idx, row_data in enumerate(cleaned_data):
                    for col_idx in range(actual_cols):
                        cell_value = row_data[col_idx] if col_idx < len(row_data) else ""
                        cell = table.cell(row_idx, col_idx)
                        if cell.paragraphs:
                            paragraph = cell.paragraphs[0]
                            paragraph.clear()
                            run = paragraph.add_run(cell_value)
                            run.font.name = "Calibri"
                            if row_idx == 0:
                                run.bold = True
                                run.font.size = Pt(12)
                            else:
                                run.font.size = Pt(12)
                                run.bold = False

                print(f"‚úÖ Successfully processed CADD sheet: {sheet_name}")

        return True

    except Exception as e:
        print(f"‚ùå Error processing CADD sheets: {e}")
        return False

def insert_single_excel_sheet(doc, wb, sheet_name, sheet_index, excel_file_path, insert_index):
    """Insert a single Excel sheet as a table at the specified index"""
    try:
        ws = wb[sheet_name]
        print(f"üìÑ Processing sheet: {sheet_name}")

        # Get all data from the sheet
        all_data = []
        min_row = ws.min_row
        max_row = ws.max_row
        min_col = ws.min_column
        max_col = ws.max_column

        # Read the actual data range
        for row_idx in range(min_row, max_row + 1):
            row_data = []
            has_data = False
            for col_idx in range(min_col, max_col + 1):
                cell = ws.cell(row=row_idx, column=col_idx)
                cell_value = str(cell.value) if cell.value is not None else ""
                cell_value = cell_value.strip()
                if cell_value == "None" or cell_value == "":
                    cell_value = ""
                else:
                    has_data = True
                row_data.append(cell_value)
            if has_data:
                all_data.append(row_data)

        if not all_data or len(all_data) == 0:
            print(f"‚ö†Ô∏è No data found in sheet '{sheet_name}'")
            # Add empty sheet message
            empty_para = doc.paragraphs[insert_index].insert_paragraph_before(
                f"No data available in sheet '{sheet_name}'")
            empty_para.runs[0].italic = True
            return True

        # Remove empty columns
        max_data_cols = 0
        for row in all_data:
            last_data_col = 0
            for col_idx, value in enumerate(row):
                if value.strip():
                    last_data_col = col_idx + 1
            max_data_cols = max(max_data_cols, last_data_col)

        if max_data_cols == 0:
            print(f"‚ö†Ô∏è No valid data columns in sheet '{sheet_name}'")
            return False

        trimmed_data = [row[:max_data_cols] for row in all_data]
        all_data = trimmed_data

        actual_rows = len(all_data)
        actual_cols = len(all_data[0]) if all_data else 0

        print(f"‚úÖ Sheet '{sheet_name}' has {actual_rows} rows and {actual_cols} columns")

        # Add sheet heading
        heading_para = doc.paragraphs[insert_index].insert_paragraph_before()
        heading_run = heading_para.add_run(f"Table {sheet_index + 1}: {sheet_name}")
        heading_run.bold = True
        heading_run.font.size = Pt(12)
        insert_index += 1

        # Create table
        table_para = doc.paragraphs[insert_index].insert_paragraph_before()
        table = doc.add_table(rows=actual_rows, cols=actual_cols)

        # Apply table style
        try:
            table.style = "Table Grid"
        except:
            try:
                table.style = "Light Grid"
            except:
                try:
                    table.style = "Grid Table 1 Light"
                except:
                    apply_table_borders(table)

        # Populate table
        for row_idx, row_data in enumerate(all_data):
            for col_idx in range(actual_cols):
                cell_value = row_data[col_idx] if col_idx < len(row_data) else ""
                table.cell(row_idx, col_idx).text = cell_value
                is_header = (row_idx == 0)
                #format_table_cell(table.cell(row_idx, col_idx), is_header)

        apply_table_borders(table)
        insert_index += 1

        # Add caption
        caption_para = doc.paragraphs[insert_index].insert_paragraph_before()
        caption_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
        caption_run = caption_para.add_run(f"Source: {os.path.basename(excel_file_path)} - Sheet: {sheet_name}")
        caption_run.italic = True
        caption_run.font.size = Pt(12)
        insert_index += 1

        # Add spacing
        doc.paragraphs[insert_index].insert_paragraph_before()

        return True

    except Exception as e:
        print(f"‚ö†Ô∏è Error processing sheet '{sheet_name}': {e}")
        return False


def add_excel_tables_at_end(doc, wb, excel_file_path):
    """Add Excel tables at the end of document as fallback"""
    try:
        # Add heading for the tables section
        doc.add_paragraph().add_run("Excel Data Tables:").bold = True

        for sheet_index, sheet_name in enumerate(wb.sheetnames):
            ws = wb[sheet_name]

            # Add sheet heading
            heading_para = doc.add_paragraph()
            heading_run = heading_para.add_run(f"Table {sheet_index + 1}: {sheet_name}")
            heading_run.bold = True
            heading_run.font.size = Pt(12)

            # Get data (simplified)
            all_data = []
            for row in ws.iter_rows(values_only=True):
                row_data = [str(cell) if cell is not None else "" for cell in row]
                if any(cell.strip() for cell in row_data if cell):
                    all_data.append(row_data)

            if all_data:
                # Create table
                table = doc.add_table(rows=len(all_data), cols=len(all_data[0]))

                # Apply styling
                try:
                    table.style = "Table Grid"
                except:
                    apply_table_borders(table)

                # Populate table
                for row_idx, row_data in enumerate(all_data):
                    for col_idx, cell_value in enumerate(row_data):
                        if col_idx < len(table.rows[row_idx].cells):
                            table.cell(row_idx, col_idx).text = cell_value
                            #format_table_cell(table.cell(row_idx, col_idx), row_idx == 0)

            # Add spacing
            doc.add_paragraph()

        return True
    except Exception as e:
        print(f"‚ö†Ô∏è Error adding Excel tables at end: {e}")
        return False


def insert_image_at_placeholder(doc, image_paths):
    """Insert multiple images at their appropriate locations based on figure references"""
    if not image_paths:
        return False

    # Map figure numbers to their expected positions in the document
    figure_positions = {
        1: "Figure 1: Change in \"hot summer days\"",
        2: "Figure 2: Change in \"tropical nights\"",
        3: "Figure 3: Changing flood risk",
        4: "Figure 4: Changing drought, wind and subsidence risks",
        5: "Figure 5: Components of climate change vulnerability",
        6: "Figure 6: Current and target capabilities",
        7: "Figure 7: Adaptation Plan activities"
    }

    images_placed = 0

    for image_index, image_path in enumerate(image_paths):
        if not os.path.exists(image_path):
            continue

        image_filename = os.path.basename(image_path)
        figure_number = image_index + 1  # Start from Figure 1

        print(f"üñºÔ∏è Looking for position for Figure {figure_number}: {image_filename}")

        # Find the appropriate location for this figure
        target_text = figure_positions.get(figure_number, f"Figure {figure_number}:")

        # Search through all paragraphs to find where to insert the image
        insertion_index = None
        for i, paragraph in enumerate(doc.paragraphs):
            if target_text in paragraph.text:
                insertion_index = i
                print(f"‚úÖ Found position for {target_text} at paragraph {i}")
                break

        if insertion_index is not None:
            try:
                # Insert the image before the figure caption
                image_para = doc.paragraphs[insertion_index].insert_paragraph_before()
                image_para.alignment = WD_ALIGN_PARAGRAPH.CENTER

                # Add image
                run = image_para.add_run()
                run.add_picture(image_path, width=Inches(6.0))

                # Add some spacing
                doc.paragraphs[insertion_index].insert_paragraph_before()

                print(f"‚úÖ Image inserted as {target_text}")
                images_placed += 1

            except Exception as img_error:
                print(f"‚ö†Ô∏è Error adding image {image_filename}: {img_error}")
                # Add placeholder text if image can't be inserted
                placeholder_para = doc.paragraphs[insertion_index].insert_paragraph_before()
                placeholder_para.add_run(f"[Image: {image_filename}]")
                images_placed += 1
        else:
            print(f"‚ö†Ô∏è Could not find position for {target_text}")

            # Fallback: Add image at the end of the document with caption
            try:
                doc.add_paragraph().add_run(f"Figure {figure_number}:").bold = True
                image_para = doc.add_paragraph()
                image_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
                run = image_para.add_run()
                run.add_picture(image_path, width=Inches(6.0))
                caption_para = doc.add_paragraph()
                caption_para.add_run(f"Figure {figure_number}: {image_filename}").italic = True
                caption_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
                images_placed += 1
                print(f"‚úÖ Image added at end as Figure {figure_number}")
            except Exception as e:
                print(f"‚ö†Ô∏è Could not add image at end: {e}")

    print(f"‚úÖ Total images placed: {images_placed} out of {len(image_paths)}")
    return images_placed > 0


def create_proper_toc_sections(doc, json_data):
    """Create proper TOC sections on a separate page after the title page"""
    print("üìë Creating TOC sections on separate page after title page...")

    # Look for the end of the title page
    # The title page typically has:
    # 1. Client logo (top)
    # 2. Report title
    # 3. Report date
    # 4. Client photo placeholder
    # 5. Climate Sense logo (bottom right)

    # We'll look for markers that indicate we're at the end of the title page
    title_page_end_index = None

    # First, try to find the Climate Sense logo position
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()

        # Check for the logo placeholder
        if "[CLIMATE SENSE LOGO HERE]" in text:
            title_page_end_index = i + 1  # TOC should go after this
            print(f"‚úÖ Found Climate Sense logo at paragraph {i}")
            break

        # Also check if this paragraph has right-aligned content (logo might be right-aligned)
        if paragraph.alignment == WD_ALIGN_PARAGRAPH.RIGHT and i > 5:
            # Check for any image runs
            for run in paragraph.runs:
                if hasattr(run, '_element') and run._element.xpath('.//pic:pic'):
                    title_page_end_index = i + 1
                    print(f"‚úÖ Found right-aligned image at paragraph {i} (likely the logo)")
                    break
            if title_page_end_index is not None:
                break

    # If we can't find the logo, look for the end of title page by structure
    if title_page_end_index is None:
        # Look for patterns that indicate title page content
        for i, paragraph in enumerate(doc.paragraphs):
            text = paragraph.text.strip()

            # Check if we're moving beyond title page content
            if i > 0:  # Skip first paragraph
                prev_text = doc.paragraphs[i - 1].text.strip() if i - 1 < len(doc.paragraphs) else ""

                # If previous text looks like title page and current doesn't, this might be the end
                if ("Report Date:" in prev_text or
                    "[GOOGLE EARTH CLIENT PHOTO HERE]" in prev_text or
                    "Climate Change Adaptation Plan" in prev_text) and \
                        not any(marker in text for marker in
                                ["Report Date:", "[GOOGLE EARTH", "Climate Change"]):
                    title_page_end_index = i
                    print(f"‚úÖ Detected end of title page at paragraph {i}")
                    break

    # Fallback: if we still can't find it, use a reasonable position
    if title_page_end_index is None:
        # Count how many paragraphs look like title page content
        title_page_paragraphs = 0
        for i, paragraph in enumerate(doc.paragraphs):
            text = paragraph.text.strip()
            if any(marker in text for marker in
                   ["[CLIENT LOGO", "[[project_title]]", "Report Date:",
                    "[GOOGLE EARTH", "[CLIMATE SENSE"]):
                title_page_paragraphs = i + 1

        title_page_end_index = min(title_page_paragraphs + 1, len(doc.paragraphs) - 1)
        print(f"‚ö†Ô∏è Using calculated title page end at paragraph {title_page_end_index}")

    print(f"üìç Title page ends at paragraph {title_page_end_index}")

    # Clear any existing TOC content
    clear_existing_toc_content(doc)

    # Add page break and insert TOC
    try:
        # Insert page break to start TOC on new page
        page_break_para = doc.paragraphs[title_page_end_index].insert_paragraph_before()
        page_break_run = page_break_para.add_run()
        page_break_run.add_break(WD_BREAK.PAGE)
        print("‚úÖ Added page break after title page")

        # TOC insertion point (after the page break)
        toc_insert_index = title_page_end_index + 1

        # Insert the TOC content on the new page
        insert_toc_content_exact_format(doc, toc_insert_index, json_data)

        print("‚úÖ TOC created on separate page after title page")

    except Exception as e:
        print(f"‚ùå Error creating TOC: {e}")
        # Fallback: insert TOC directly
        insert_toc_content_exact_format(doc, title_page_end_index, json_data)


def update_toc_section_titles(doc, json_data):
    """Update section titles in the Table of Contents to match template_v4"""
    print("üìë Updating TOC section titles...")

    client_name = json_data.get("client_name", "Ministry of Rural Development")
    client_location = json_data.get("client_location", "Republic of Fiji")

    # List of section titles that should be in TOC
    expected_sections = [
        f"{client_name} in a Changing Climate",
        f"{client_name} Adaptation Plan",
        "Introduction",
        "Vision and Guiding Principles",
        "Climate Change Hazards",
        "Planning Process",
        "Impact Assessment",
        "Adaptive capacity",
        "Adaptation Planning and Implementation",
        "Monitoring, Evaluation & Continual Improvement",
        "Conclusion and Next Steps",
        "Appendices"
    ]

    # Update any TOC entries that might reference old section names
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text

        # Check if this looks like a TOC entry
        if ("Executive Summary" in text or
                "Introduction" in text or
                "in a Changing Climate" in text or
                "Adaptation" in text):

            # Replace old client name with new one
            if "East Hill" in text:
                new_text = text.replace("East Hill", client_name)
                paragraph.text = new_text
                print(f"‚úÖ Updated TOC entry: '{text[:50]}...'")

    return True

def safe_insert_paragraph_before(doc, current_index, text=None):
    """Safely insert a paragraph before the current index with bounds checking"""
    try:
        if current_index < len(doc.paragraphs):
            if text:
                new_para = doc.paragraphs[current_index].insert_paragraph_before(text)
            else:
                new_para = doc.paragraphs[current_index].insert_paragraph_before()
            return current_index + 1, new_para
        else:
            # If index is out of bounds, add to end
            if text:
                new_para = doc.add_paragraph(text)
            else:
                new_para = doc.add_paragraph()
            return len(doc.paragraphs) - 1, new_para
    except Exception as e:
        print(f"‚ö†Ô∏è Error inserting paragraph: {e}")
        # Fallback: add to end
        if text:
            new_para = doc.add_paragraph(text)
        else:
            new_para = doc.add_paragraph()
        return len(doc.paragraphs) - 1, new_para


def insert_toc_content_exact_format(doc, insert_index, json_data):
    """Insert TOC, LOF, LOT content in the exact format from the reference image"""
    print(f"üìù Starting TOC insertion at index: {insert_index}")

    # Get dynamic client data
    client_name = json_data.get("client_name", "Ministry of Rural Development")

    # Add spacing - safely
    insert_index, _ = safe_insert_paragraph_before(doc, insert_index)

    # Table of Contents heading (centered) - NO NUMBERING
    insert_index, toc_para = safe_insert_paragraph_before(doc, insert_index, "Table of Contents")
    toc_para.alignment = WD_ALIGN_PARAGRAPH.LEFT
    # Use Normal style instead of Heading 1 to avoid numbering
    toc_para.style = "Normal"
    # Make it bold and larger manually
    if toc_para.runs:
        toc_para.runs[0].bold = True
        toc_para.runs[0].font.size = Pt(14)

    # Add spacing after heading
    insert_index, _ = safe_insert_paragraph_before(doc, insert_index)

    # Create exact TOC structure from the image - EXECUTIVE SUMMARY STARTS FROM PAGE 4
    # ‚úÖ UPDATED: Using client_name instead of hardcoded "East Hill Farm"
    toc_structure = [
        ("1", "Executive Summary", "4"),  # Changed from 3 to 4
        ("", "1.1 Why this plan and what it delivers", "4"),  # Changed from 3 to 4
        ("2", "Introduction", "5"),  # Updated from 4 to 5
        ("3", f"{client_name} in a Changing Climate", "6"),  # ‚úÖ Updated with client_name
        ("", f"3.1 Adaptation at {client_name}", "6"),  # ‚úÖ Updated with client_name
        ("4", "Vision, Guiding Principles and Timespan", "7"),  # Updated from 6 to 7
        ("5", "Climate Change Hazards", "7"),  # Updated from 6 to 7
        ("6", "Planning Process", "10"),  # Updated from 9 to 10
        ("", "6.1 Methodology for Risk and Vulnerability Assessment", "10"),  # Updated from 9 to 10
        ("7", "Impact Assessment", "12"),  # Updated from 11 to 12
        ("8", "Adaptive capacity", "14"),  # Updated from 13 to 14
        ("", "8.1 Current and required adaptive capacity", "17"),  # Updated from 16 to 17
        ("9", "Adaptation Planning and Implementation", "19"),  # Updated from 18 to 19
        ("", "9.1 Physical Risk Management Actions", "20"),  # Updated from 19 to 20
        ("", "9.2 Adaptive Capacity Development Actions", "27"),  # Updated from 26 to 27
        ("", "9.3 Integration with Management Systems", "34"),  # Updated from 33 to 34
        ("10", "Monitoring, Evaluation & Continual Improvement", "35"),  # Updated from 34 to 35
        ("", "10.1 Documentation and Review", "38"),  # Updated from 37 to 38
        ("11", "Conclusion and Next Steps", "39")  # Updated from 38 to 39
    ]

    # Add TOC entries with proper formatting - ALL WITH PAGE NUMBERS AT CORNER
    for num, title, page in toc_structure:
        insert_index, toc_entry = safe_insert_paragraph_before(doc, insert_index)
        toc_entry.alignment = WD_ALIGN_PARAGRAPH.LEFT

        if num:  # Main section
            # Add section number in bold
            num_run = toc_entry.add_run(num)
            num_run.bold = True
            # Add title
            title_run = toc_entry.add_run(f" {title}")
        else:  # Sub-section
            toc_entry.paragraph_format.left_indent = Inches(0.3)
            # Add title
            title_run = toc_entry.add_run(title)

        # Calculate space for dots to push page number to corner
        total_text_length = len(title) + (len(num) + 1 if num else 0)  # +1 for space after number
        remaining_space = 85 - total_text_length  # Increased space to push numbers to corner

        # Add dots and page number at corner
        dots_run = toc_entry.add_run(" " + "." * max(remaining_space, 5) + " ")
        page_run = toc_entry.add_run(page)
        page_run.bold = True

        # Add spacing between items
        toc_entry.paragraph_format.space_after = Pt(6)

    # Add spacing before Appendices
    insert_index, _ = safe_insert_paragraph_before(doc, insert_index)
    insert_index, _ = safe_insert_paragraph_before(doc, insert_index)  # Extra spacing

    # Appendices section - NO NUMBERING
    insert_index, appendices_para = safe_insert_paragraph_before(doc, insert_index, "Appendices")
    appendices_para.alignment = WD_ALIGN_PARAGRAPH.LEFT
    if appendices_para.runs:
        appendices_para.runs[0].bold = True

    # Appendices list with page numbers at corner, italics, and spacing - UPDATED PAGE NUMBERS
    appendices = [
        ("Appendix 1:", "Glossary", "41"),  # Updated from 40 to 41
        ("Appendix 2:", "EA Climate Hazards List Data and Information Sources", "42"),  # Updated from 41 to 42
        ("Appendix 3:", "Client Inputs (e.g., actions, assets)", "43"),  # Updated from 42 to 43
        ("Appendix 4:", "CaDD Explorer, Adaptive Capacity Action Plan", "44"),  # Updated from 43 to 44
        ("Appendix 5:", "Physical Risk Management Actions", "45"),  # Updated from 44 to 45
        ("Appendix 6:", "Adaptive Capacity Development Actions", "46"),  # Updated from 45 to 46
        ("Appendix 7:", "Monitoring and Evaluation Framework", "47")  # Updated from 46 to 47
    ]

    for appendix_num, appendix_title, page_num in appendices:
        insert_index, appendix_para = safe_insert_paragraph_before(doc, insert_index)
        appendix_para.alignment = WD_ALIGN_PARAGRAPH.LEFT
        appendix_para.paragraph_format.left_indent = Inches(0.3)

        # Add spacing between appendix items
        appendix_para.paragraph_format.space_after = Pt(8)

        # Add appendix number
        num_run = appendix_para.add_run(appendix_num)
        num_run.bold = True

        # Add appendix title (italicized)
        title_run = appendix_para.add_run(f" {appendix_title}")
        title_run.italic = True

        # Calculate space for dots to push page number to corner
        total_text_length = len(appendix_num) + len(appendix_title) + 1  # +1 for space
        remaining_space = 85 - total_text_length  # Increased space to push numbers to corner

        # Add dots and page number at corner
        dots_run = appendix_para.add_run(" " + "." * max(remaining_space, 5) + " ")
        page_run = appendix_para.add_run(page_num)
        page_run.bold = True

    # Add spacing before List of Figures - KEEP LOF UNCHANGED
    insert_index, _ = safe_insert_paragraph_before(doc, insert_index)
    insert_index, _ = safe_insert_paragraph_before(doc, insert_index)

    # List of Figures (centered heading) - NO NUMBERING - UNCHANGED
    insert_index, lof_para = safe_insert_paragraph_before(doc, insert_index, "List of Figures")
    lof_para.alignment = WD_ALIGN_PARAGRAPH.LEFT
    lof_para.style = "Normal"
    if lof_para.runs:
        lof_para.runs[0].bold = True
        lof_para.runs[0].font.size = Pt(14)

    # Add spacing after LOF heading
    insert_index, _ = safe_insert_paragraph_before(doc, insert_index)

    # Use actual LOF content from JSON with proper formatting - UNCHANGED
    lof_content = json_data.get("lof", "")
    if lof_content:
        lof_items = lof_content.split('\n')
        for item in lof_items:
            if item.strip():
                insert_index, lof_item_para = safe_insert_paragraph_before(doc, insert_index, item.strip())
                lof_item_para.alignment = WD_ALIGN_PARAGRAPH.LEFT
                lof_item_para.style = "Normal"
    else:
        # Fallback LOF based on the image - UNCHANGED
        fallback_lof = [
            "Figure 1: Change in \"hot summer days\" (over 30¬∫C) for Somerset (Source Met Office Local Authority Climate Service 2025)",
            "Figure 2: Change in \"tropical nights\" (over 20¬∫C) for Somerset (Source Met Office Local Authority Climate Service 2025)",
            "Figure 3: Changing flood risk (Environment Agency, 2025)",
            "Figure 4: Changing drought, wind and subsidence risks (Munich Re, 2025)",
            "Figure 5: Components of climate change vulnerability (Source IPCC)",
            "Figure 6: Current and target capabilities per Capacity Diagnosis and Development (CaDD)",
            "Figure 7: Adaptation Plan activities and phased implementation pathways"
        ]
        for item in fallback_lof:
            insert_index, lof_item_para = safe_insert_paragraph_before(doc, insert_index, item)
            lof_item_para.alignment = WD_ALIGN_PARAGRAPH.LEFT
            lof_item_para.style = "Normal"

    # Add spacing before List of Tables - KEEP LOT UNCHANGED
    insert_index, _ = safe_insert_paragraph_before(doc, insert_index)
    insert_index, _ = safe_insert_paragraph_before(doc, insert_index)

    # List of Tables (centered heading) - NO NUMBERING - UNCHANGED
    insert_index, lot_para = safe_insert_paragraph_before(doc, insert_index, "List of Tables")
    lot_para.alignment = WD_ALIGN_PARAGRAPH.LEFT
    lot_para.style = "Normal"
    if lot_para.runs:
        lot_para.runs[0].bold = True
        lot_para.runs[0].font.size = Pt(14)

    # Add spacing after LOT heading
    insert_index, _ = safe_insert_paragraph_before(doc, insert_index)

    # Use actual LOT content from JSON with proper formatting - UNCHANGED
    lot_content = json_data.get("lot", "")
    if lot_content:
        lot_items = lot_content.split('\n')
        for item in lot_items:
            if item.strip():
                insert_index, lot_item_para = safe_insert_paragraph_before(doc, insert_index, item.strip())
                lot_item_para.alignment = WD_ALIGN_PARAGRAPH.LEFT
                lot_item_para.style = "Normal"
    else:
        # Fallback LOT based on the image - UNCHANGED
        fallback_lot = [
            "Table 1: Identified impacts requiring action grouped by phase of global warming in 0.5¬∞C increments",
            "Table 2: Levels of adaptive capacity",
            "Table 3: East Hill Farm Physical Risk Management Actions by Warming Phase",
            "Table 4: Current adaptive capacity strengths to protect in the capacity development implementation plan",
            "Table 5: East Hill Dairy Farm Climate Adaptive Capacity Development Actions by Implementation Phase",
            "Table 6: Monitoring and review processes",
            "Table 7: EA Climate Hazards List Data and Information Sources"
        ]
        for item in fallback_lot:
            insert_index, lot_item_para = safe_insert_paragraph_before(doc, insert_index, item)
            lot_item_para.alignment = WD_ALIGN_PARAGRAPH.LEFT
            lot_item_para.style = "Normal"

    print("‚úÖ TOC creation completed successfully")


def move_executive_summary_to_page_four(doc):
    """Move Executive Summary content to start on page 4 without affecting TOC placement"""
    print("üìÑ Ensuring Executive Summary starts on page 4...")

    # Find the Executive Summary heading (the actual content, not in TOC)
    exec_summary_found = False
    exec_summary_index = -1

    # First, let's find where the TOC/LOT ends and actual content begins
    toc_end_index = -1
    lot_found = False

    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()

        # Look for the end of LOT (List of Tables)
        if "List of Tables" in text:
            lot_found = True
            continue

        # After LOT, find the first significant content that's not part of TOC/LOF/LOT
        if lot_found and text and len(text) > 10 and not any(
                x in text for x in ["Table of Contents", "List of Figures", "List of Tables"]):
            # This is likely the start of actual content
            toc_end_index = i
            print(f"‚úÖ Found end of TOC/LOF/LOT section at paragraph {i}")
            break

    # Now find the Executive Summary heading in the main content
    for i, paragraph in enumerate(doc.paragraphs):
        if i > toc_end_index and "Executive Summary" in paragraph.text and not exec_summary_found:
            # Check if this is the main Executive Summary heading (not in TOC)
            # Look for heading style or section number
            if paragraph.style.name.startswith('Heading') or "1" in paragraph.text:
                exec_summary_found = True
                exec_summary_index = i
                print(f"‚úÖ Found Executive Summary content at paragraph {i}")
                break

    if exec_summary_found and exec_summary_index > 0:
        # Calculate how many paragraphs are between TOC end and Executive Summary
        paragraphs_between = exec_summary_index - toc_end_index
        print(f"üìä Paragraphs between TOC end and Exec Summary: {paragraphs_between}")

        # If there are too few paragraphs, add some blank ones to push to next page
        if paragraphs_between < 3:
            paragraphs_to_add = 8 - paragraphs_between  # Add enough to push to next page
            for _ in range(max(paragraphs_to_add, 1)):
                doc.paragraphs[exec_summary_index].insert_paragraph_before()
            print(f"‚úÖ Added {paragraphs_to_add} blank paragraphs to push Executive Summary to page 4")

        # Add a page break right before Executive Summary to ensure it starts on new page
        page_break_para = doc.paragraphs[exec_summary_index].insert_paragraph_before()
        page_break_para.add_run().add_break(WD_BREAK.PAGE)
        print("‚úÖ Added page break before Executive Summary")

    elif not exec_summary_found:
        print("‚ö†Ô∏è Could not find Executive Summary content after TOC")
        # Fallback: try to find any heading that might be Executive Summary
        for i, paragraph in enumerate(doc.paragraphs):
            if "Executive Summary" in paragraph.text:
                print(f"üîÑ Found Executive Summary at paragraph {i} (fallback)")
                # Add page break before it
                page_break_para = doc.paragraphs[i].insert_paragraph_before()
                page_break_para.add_run().add_break(WD_BREAK.PAGE)
                print("‚úÖ Added page break before Executive Summary (fallback)")
                break

    return exec_summary_found

def clear_existing_toc_content(doc):
    """Clear existing TOC, LOF, LOT content"""
    sections_to_remove = []
    in_toc_section = False
    toc_keywords = ["Table of Contents", "List of Figures", "List of Tables", "**\\**"]

    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()

        if any(keyword in text for keyword in toc_keywords):
            in_toc_section = True
            sections_to_remove.append(i)
        elif in_toc_section and ("Executive Summary" in text or "Introduction" in text):
            break
        elif in_toc_section:
            sections_to_remove.append(i)

    # Remove in reverse order
    for i in sorted(sections_to_remove, reverse=True):
        if i < len(doc.paragraphs):
            try:
                p = doc.paragraphs[i]._element
                p.getparent().remove(p)
            except Exception as e:
                print(f"‚ö†Ô∏è Error removing paragraph {i}: {e}")
                continue

    print(f"‚úÖ Cleared {len(sections_to_remove)} existing TOC sections")

def insert_toc_content(doc, insert_index, json_data):
    """Insert TOC, LOF, LOT content at specified position"""
    # Add separator - REMOVED: No longer adding **\\**
    # sep_para = doc.paragraphs[insert_index].insert_paragraph_before("**\\**")
    # insert_index += 1

    # Table of Contents
    toc_para = doc.paragraphs[insert_index].insert_paragraph_before("Table of Contents")
    toc_para.style = "Heading 1"
    insert_index += 1

    # Create manual TOC with predefined structure
    toc_structure = [
        "Executive Summary .................... 3",
        "Introduction ......................... 4",
        "East Hill Farm in a Changing Climate .. 5",
        "Climate Risk Assessment .............. 6",
        "Adaptation Strategy .................. 7",
        "Implementation Plan .................. 8",
        "Monitoring and Evaluation ............ 9",
        "Appendix A: Supporting Documents ..... 10",
        "Conclusions and Recommendations ...... 11"
    ]

    for toc_item in toc_structure:
        toc_entry = doc.paragraphs[insert_index].insert_paragraph_before(toc_item)
        toc_entry.style = "Normal"
        insert_index += 1

    # Add space after TOC
    doc.paragraphs[insert_index].insert_paragraph_before()
    insert_index += 1

    # List of Figures
    lof_para = doc.paragraphs[insert_index].insert_paragraph_before("List of Figures")
    lof_para.style = "Heading 1"
    insert_index += 1

    # Use actual LOF content from JSON
    lof_content = json_data.get("lof", "")
    if lof_content:
        lof_items = lof_content.split('\n')
        for item in lof_items:
            if item.strip():
                lof_item_para = doc.paragraphs[insert_index].insert_paragraph_before(item.strip())
                lof_item_para.style = "Normal"
                insert_index += 1
    else:
        no_lof_para = doc.paragraphs[insert_index].insert_paragraph_before("No figures available.")
        no_lof_para.style = "Normal"
        insert_index += 1

    # Add space before List of Tables
    doc.paragraphs[insert_index].insert_paragraph_before()
    insert_index += 1

    # List of Tables
    lot_para = doc.paragraphs[insert_index].insert_paragraph_before("List of Tables")
    lot_para.style = "Heading 1"
    insert_index += 1

    # Use actual LOT content from JSON
    lot_content = json_data.get("lot", "")
    if lot_content:
        lot_items = lot_content.split('\n')
        for item in lot_items:
            if item.strip():
                lot_item_para = doc.paragraphs[insert_index].insert_paragraph_before(item.strip())
                lot_item_para.style = "Normal"
                insert_index += 1
    else:
        no_lot_para = doc.paragraphs[insert_index].insert_paragraph_before("No tables available.")
        no_lot_para.style = "Normal"
        insert_index += 1


def replace_logo_placeholders(doc, client_logo_path, climate_logo_path):
    """Replace both logo placeholders with actual logos"""
    print("üñºÔ∏è Replacing logo placeholders...")

    # Replace client logo - position at top center
    if client_logo_path and os.path.exists(client_logo_path):
        replace_single_logo(doc, "[CLIENT LOGO HERE]", client_logo_path, WD_ALIGN_PARAGRAPH.CENTER)
    else:
        # If no logo, replace with client name from JSON
        print("üñºÔ∏è No client logo found, replacing with client name")
        replace_logo_with_text(doc, "[CLIENT LOGO HERE]", "CLIENT LOGO", WD_ALIGN_PARAGRAPH.CENTER)

    # Replace climate sense logo - use the existing placeholder position
    if climate_logo_path and os.path.exists(climate_logo_path):
        replace_climate_logo_with_image(doc, climate_logo_path)
    else:
        # If no logo, remove the placeholder text
        print("üñºÔ∏è No climate sense logo found, removing placeholder")
        remove_climate_logo_placeholder(doc)


def replace_climate_logo_with_image(doc, climate_logo_path):
    """Replace [CLIMATE SENSE LOGO HERE] placeholder with actual logo image - consistent size"""
    print("üñºÔ∏è Replacing climate logo placeholder with image...")

    try:
        logo_replaced = False

        # Replace in paragraphs
        for paragraph in doc.paragraphs:
            if "[CLIMATE SENSE LOGO HERE]" in paragraph.text:
                # Clear the paragraph and add the logo
                paragraph.clear()
                paragraph.alignment = WD_ALIGN_PARAGRAPH.RIGHT

                # Add the logo with consistent size (1.2 inches, same as client logo)
                run = paragraph.add_run()
                run.add_picture(climate_logo_path, width=Inches(1.2))

                logo_replaced = True
                print("‚úÖ Replaced climate logo placeholder with image in paragraph (size: 1.2 inches)")
                break  # Only replace the first occurrence

        # Also check tables
        if not logo_replaced:
            for table in doc.tables:
                for row in table.rows:
                    for cell in row.cells:
                        for paragraph in cell.paragraphs:
                            if "[CLIMATE SENSE LOGO HERE]" in paragraph.text:
                                paragraph.clear()
                                paragraph.alignment = WD_ALIGN_PARAGRAPH.RIGHT

                                run = paragraph.add_run()
                                run.add_picture(climate_logo_path, width=Inches(0.8))

                                logo_replaced = True
                                print("‚úÖ Replaced climate logo placeholder with image in table cell (size: 0.8 inches)")
                                break
                        if logo_replaced:
                            break
                    if logo_replaced:
                        break
                if logo_replaced:
                    break

        if not logo_replaced:
            print("‚ö†Ô∏è Climate logo placeholder not found, adding to title page")
            # Fallback: add logo to title page if placeholder not found
            add_climate_logo_to_title_page(doc, climate_logo_path)

    except Exception as e:
        print(f"‚ö†Ô∏è Error replacing climate logo with image: {e}")


def add_climate_logo_to_title_page(doc, climate_logo_path):
    """Add Climate Sense logo to the bottom right of the title page (fallback) - consistent size"""
    print("üñºÔ∏è Adding Climate Sense logo to title page as fallback...")

    try:
        # Find a good position on the title page (after main title content)
        insert_index = None

        for i, paragraph in enumerate(doc.paragraphs):
            text = paragraph.text.strip()
            # Look for elements that typically come after the main title
            if any(marker in text for marker in ["**\\**", "***", "Table of Contents"]):
                insert_index = i
                break

        # If no clear position found, insert after first few paragraphs
        if insert_index is None:
            insert_index = min(6, len(doc.paragraphs) - 1)

        # Insert the logo
        logo_para = doc.paragraphs[insert_index].insert_paragraph_before()
        logo_para.alignment = WD_ALIGN_PARAGRAPH.RIGHT

        # Add some vertical space
        logo_para.paragraph_format.space_before = Pt(24)

        # Add the logo with consistent size (1.2 inches, same as client logo)
        run = logo_para.add_run()
        run.add_picture(climate_logo_path, width=Inches(1.2))

        print("‚úÖ Climate Sense logo added to title page as fallback (size: 1.2 inches)")
        return True

    except Exception as e:
        print(f"‚ö†Ô∏è Error adding Climate Sense logo to title page: {e}")
        return False


def remove_climate_logo_placeholder(doc):
    """Remove the [CLIMATE SENSE LOGO HERE] placeholder completely (only if no logo provided)"""
    print("üóëÔ∏è Removing [CLIMATE SENSE LOGO HERE] placeholder...")

    try:
        placeholder_removed = False

        # Remove from paragraphs
        for paragraph in doc.paragraphs:
            if "[CLIMATE SENSE LOGO HERE]" in paragraph.text:
                paragraph.clear()
                placeholder_removed = True
                print("‚úÖ Removed [CLIMATE SENSE LOGO HERE] from paragraph")

        # Remove from tables
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    for paragraph in cell.paragraphs:
                        if "[CLIMATE SENSE LOGO HERE]" in paragraph.text:
                            paragraph.clear()
                            placeholder_removed = True
                            print("‚úÖ Removed [CLIMATE SENSE LOGO HERE] from table cell")

        if not placeholder_removed:
            print("‚ÑπÔ∏è [CLIMATE SENSE LOGO HERE] placeholder not found")

    except Exception as e:
        print(f"‚ö†Ô∏è Error removing climate logo placeholder: {e}")


def replace_single_logo(doc, placeholder, logo_path, alignment):
    """Replace a single logo placeholder with consistent size"""
    try:
        for paragraph in doc.paragraphs:
            if placeholder in paragraph.text:
                # Clear and align the paragraph
                for run in paragraph.runs:
                    run.text = run.text.replace(placeholder, "")

                if paragraph.text.strip() == "":
                    paragraph.clear()

                paragraph.alignment = alignment

                # CONSISTENT SIZE FOR BOTH LOGOS - 1.2 inches width
                paragraph.add_run().add_picture(logo_path, width=Inches(1.2))

                print(f"‚úÖ Replaced {placeholder} with logo (size: 1.2 inches)")
                return True

        # Also check tables
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    for paragraph in cell.paragraphs:
                        if placeholder in paragraph.text:
                            for run in paragraph.runs:
                                run.text = run.text.replace(placeholder, "")
                            paragraph.alignment = alignment

                            # CONSISTENT SIZE FOR BOTH LOGOS IN TABLES - 0.8 inches width
                            paragraph.add_run().add_picture(logo_path, width=Inches(0.8))
                            return True

        print(f"‚ö†Ô∏è {placeholder} not found")
        return False

    except Exception as e:
        print(f"‚ö†Ô∏è Error replacing {placeholder}: {e}")
        return False


def replace_logo_with_text(doc, placeholder, text, alignment):
    """Replace a logo placeholder with text"""
    try:
        for paragraph in doc.paragraphs:
            if placeholder in paragraph.text:
                # Clear and align the paragraph
                for run in paragraph.runs:
                    run.text = run.text.replace(placeholder, text)
                paragraph.alignment = alignment

                # Add some spacing for better layout
                if placeholder == "[CLIENT LOGO HERE]":
                    # Add line breaks after client logo text
                    paragraph.text = text + "\n\n"
                else:
                    # Add line breaks before climate logo text
                    paragraph.text = "\n\n" + text

                print(f"‚úÖ Replaced {placeholder} with text: {text}")
                return True

        # Also check tables
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    for paragraph in cell.paragraphs:
                        if placeholder in paragraph.text:
                            for run in paragraph.runs:
                                run.text = run.text.replace(placeholder, text)
                            paragraph.alignment = alignment
                            return True

        print(f"‚ö†Ô∏è {placeholder} not found")
        return False

    except Exception as e:
        print(f"‚ö†Ô∏è Error replacing {placeholder} with text: {e}")
        return False


def generate_missing_content_with_gemini(missing_field, context_data):
    """Generate missing content using Gemini AI"""
    if not GEMINI_API_KEY or not AVAILABLE_GEMINI_MODEL:
        return f"Content for {missing_field} would be generated here."

    model_name = AVAILABLE_GEMINI_MODEL['name']
    api_version = AVAILABLE_GEMINI_MODEL['version']
    api_url = f"https://generativelanguage.googleapis.com/{api_version}/{model_name}:generateContent?key={GEMINI_API_KEY}"

    prompt = f"""
    Generate professional content for a climate change adaptation plan report.

    Field to generate: {missing_field}
    Context: {context_data}

    Client: {context_data.get('client_name', 'Unknown')}
    Location: {context_data.get('client_location', 'Unknown')}
    Industry: {context_data.get('Industry-1', 'Unknown')} and {context_data.get('Industry-2', 'Unknown')}

    Please generate appropriate, professional content that would fit in a climate adaptation report for this field.
    Keep it concise and relevant to the context.
    """

    payload = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {
            "temperature": 0.7,
            "maxOutputTokens": 500,
        }
    }

    try:
        resp = requests.post(api_url, json=payload, timeout=60)
        if resp.status_code == 200:
            result = resp.json()
            if 'candidates' in result and result['candidates']:
                text_response = result['candidates'][0]['content']['parts'][0]['text']
                return text_response.strip()
        return f"AI-generated content for {missing_field}."
    except Exception as e:
        print(f"‚ö†Ô∏è Gemini generation failed: {e}")
        return f"Content for {missing_field}."


def generate_content_with_gemini_with_retry(prompt, max_retries=3, base_delay=2):
    """Generate content with retry logic for rate limits"""
    for attempt in range(max_retries):
        try:
            # Apply rate limiting before each attempt
            if 'gemini_rate_limiter' in globals():
                gemini_rate_limiter.wait_if_needed()

            print(f"ü§ñ Gemini attempt {attempt + 1}/{max_retries}...")
            result = generate_content_with_gemini_proper_bullets(prompt)

            if result and len(result.strip()) > 50:
                return result

            # If we got here, either Gemini failed or returned short content
            if attempt < max_retries - 1:  # Don't sleep on last attempt
                delay = base_delay * (2 ** attempt)  # Exponential backoff
                print(f"‚ö†Ô∏è Gemini attempt {attempt + 1} failed, retrying in {delay} seconds...")
                time.sleep(delay)

        except Exception as e:
            if attempt < max_retries - 1:
                delay = base_delay * (2 ** attempt)
                print(f"‚ö†Ô∏è Gemini error on attempt {attempt + 1}: {e}, retrying in {delay} seconds...")
                time.sleep(delay)
            else:
                print(f"‚ùå Gemini failed after {max_retries} attempts: {e}")

    return None


def generate_narrative_with_tiered_fallbacks(narrative_key, prompt, context_data, max_retries=5):
    """Try multiple sources before giving up"""
    print(f"üéØ Tiered generation for: {narrative_key}")

    # --- TIER 1: Check Cache First (Fastest) ---
    cached_content = get_cached_similar_content(narrative_key, prompt)
    if cached_content:
        print(f"   ‚úÖ Using cached content for {narrative_key}")
        return cached_content

    # --- TIER 2: Gemini AI (Primary) with aggressive retry ---
    print(f"   üîÑ Trying Gemini AI...")
    for attempt in range(max_retries):
        # Apply rate limiting between retries
        if 'gemini_rate_limiter' in globals() and attempt > 0:
            gemini_rate_limiter.wait_if_needed()

        content = generate_content_with_gemini_with_retry(prompt, max_retries=3)
        if content and len(content.strip()) > 100:
            cache_result(narrative_key, prompt, content, source="gemini")
            print(f"   ‚úÖ Gemini succeeded on attempt {attempt + 1}")
            return content

        print(f"   ‚ö†Ô∏è Gemini attempt {attempt + 1} failed")
        if attempt < max_retries - 1:
            wait_time = 5 * (attempt + 1)  # 5, 10, 15, 20 seconds
            print(f"   ‚è≥ Waiting {wait_time} seconds before retry...")
            time.sleep(wait_time)

    # --- TIER 3: Template-based generation ---
    print(f"   üìù Using template generation...")
    template_content = generate_from_template(narrative_key, context_data)
    if template_content and len(template_content.strip()) > 100:
        cache_result(narrative_key, prompt, template_content, source="template")
        return template_content

    # --- TIER 4: Pre-written fallback (100% availability) ---
    print(f"   üõ°Ô∏è Using guaranteed fallback...")
    fallback_content = get_guaranteed_fallback(narrative_key, context_data)
    cache_result(narrative_key, prompt, fallback_content, source="fallback")
    return fallback_content


def generate_from_template(narrative_key, context_data):
    """Generate content from templates based on narrative type - UPDATED FOR INFRASTRUCTURE"""
    client_name = context_data.get("client_name", "Client")
    client_location = context_data.get("client_location", "Location")
    sector = context_data.get("sector", "infrastructure")

    templates = {
        "executive_summary_narrative": f"""{client_name}, operating in {client_location}, requires a comprehensive climate adaptation plan to address increasing risks to its {sector} operations. This plan outlines strategic measures to enhance infrastructure resilience, protect critical assets, and ensure service continuity in the face of climate change. By implementing proactive adaptation strategies, {client_name} aims to maintain operational viability and comply with relevant regulatory requirements.

Key climate risks include extreme heat affecting infrastructure performance, surface water flooding disrupting operations, and water scarcity impacting service delivery. The adaptation strategy integrates infrastructure hardening measures with organizational capacity building, aligned with Environment Agency requirements and ISO 14090 standards.

Implementation follows a phased approach, beginning with no-regrets actions like drainage improvements and emergency planning that provide immediate benefits while preparing for future climate scenarios. Regular monitoring and review cycles ensure the plan remains effective and responsive to evolving climate conditions at {client_name}, supporting operational continuity through projected climate changes.""",

        "key_messages_callout": f"""‚Ä¢ Value: Proactive adaptation builds resilience for {client_name}'s {sector} operations, protecting critical infrastructure against escalating climate impacts in {client_location}.
‚Ä¢ Urgency: Immediate action on infrastructure hardening and drainage systems is required to prevent significantly higher costs and greater future service disruption.
‚Ä¢ Strategic Alignment: Adaptation measures align with {client_name}'s service delivery objectives while meeting Environment Agency compliance requirements.
‚Ä¢ Implementation Priority: Focus on no-regrets actions like infrastructure upgrades and emergency planning that provide benefits under current and future climate conditions.
‚Ä¢ Monitoring Framework: Establish robust systems to track adaptation progress specific to {client_name}'s operations.
‚Ä¢ Capacity Building: Develop climate adaptation expertise within {client_name}'s management team.
‚Ä¢ Collaboration: Engage with relevant stakeholders to share adaptation knowledge and resources.
‚Ä¢ Regulatory Compliance: Ensure all adaptation measures meet or exceed regulatory requirements for climate resilience.""",

        "introduction_narrative": f"""This Adaptation Plan provides {client_name} with a comprehensive framework for addressing climate change impacts on its {sector} operations in {client_location}. Developed in response to increasing climate variability and regulatory requirements from the Environment Agency, the plan establishes a systematic approach to climate risk management that balances scientific projections with practical implementation.

The plan's objectives include ensuring regulatory compliance with environmental permits, protecting critical infrastructure assets, maintaining service continuity during extreme weather events, and building organizational capacity for ongoing adaptation. It represents a proactive approach to building resilience for {client_name} in the face of climate uncertainties specific to {client_location} conditions.

By integrating climate adaptation into core operational processes, {client_name} aims to navigate the climate challenges of the coming decades while maintaining service efficiency, infrastructure integrity, and stakeholder confidence in the organization's long-term sustainability.""",

        "site_context_narrative": f"""{client_name} operates {sector} infrastructure in {client_location}, an area vulnerable to various climate impacts. The organization's operations face specific challenges that require targeted adaptation measures to ensure continued functionality and service delivery.

Current climate impacts are already observable, including infrastructure damage from extreme weather events, service disruptions due to flooding, and operational challenges during heatwaves. These issues are expected to intensify with further global warming, requiring systematic adaptation planning to maintain operational viability.

The organization's dependence on reliable infrastructure, consistent resource availability, and optimal operating conditions creates multiple exposure points to climate hazards. Understanding these operational vulnerabilities forms the foundation for targeted, effective adaptation measures at {client_name}."""
    }

    return templates.get(narrative_key,
                         f"This section addresses {narrative_key.replace('_', ' ')} considerations for {client_name}'s {sector} operations in {client_location}. The content details specific adaptation measures, monitoring approaches, and implementation timelines tailored to the organization's unique climate vulnerabilities and operational requirements.")


# =============== ADD NEW V4 FUNCTIONS HERE ===============

def generate_from_template_v4(narrative_key, context_data, v4_data):
    """Generate content from templates based on narrative type - UPDATED FOR JSON V4"""
    client_name = v4_data.get("client_name", "Ministry of Rural Development")
    client_location = v4_data.get("client_location", "Republic of Fiji")
    sector = v4_data.get("sector", "infrastructure")
    key_climate_risks = v4_data.get("key_climate_risks", ["sea-level rise", "tropical cyclones", "flooding"])
    objectives = v4_data.get("objectives", ["enhance infrastructure resilience", "support climate finance access"])

    if isinstance(key_climate_risks, str):
        key_climate_risks = [key_climate_risks]
    if isinstance(objectives, str):
        objectives = [objectives]

    templates = {
        "executive_summary_narrative": f"""The Republic of Fiji faces intensifying climate risks, including {', '.join(key_climate_risks[:3])}, threatening national development and long-term stability. Operating in Fiji's {sector} sector, {client_name}'s assets and networks are directly exposed to these hazards, making climate risk a core strategic and operational concern.

The adaptation plan responds by establishing a practical framework for climate-resilient infrastructure that strengthens adaptive capacity and supports Fiji's National Adaptation Plan v2.0. It targets vulnerabilities such as coastal infrastructure degradation, storm and flood damage, and service disruptions, aiming to reduce maintenance costs, extend asset lifespans, and safeguard essential services and rural livelihoods.

Regulatory and standards requirements increasingly mandate that organisations identify, manage, and disclose climate-related risks, driving alignment with national policy and international best practice. The plan is designed to ensure regulatory alignment, provide clear, actionable pathways, and support continuous improvement.

Key messages ‚Äì value, urgency, actions:
‚Ä¢ Strengthens climate-resilient infrastructure while supporting Fiji's National Adaptation Plan v2.0 and safeguarding development gains.
‚Ä¢ Demonstrates a replicable model for climate-resilient development that can be scaled across Fiji and internationally.
‚Ä¢ Addresses escalating risks to coastal, transport, and utility infrastructure from {', '.join(key_climate_risks[:2])}.
‚Ä¢ Underscores urgency: immediate action is needed to avoid rising disaster losses and service disruptions.
‚Ä¢ Calls for priority actions: upgrade and climate-proof critical infrastructure; improve drainage and flood protection; implement sustainable water storage.""",

        "key_messages_callout": f"""‚Ä¢ Value: Proactive adaptation builds resilience for {client_name}'s infrastructure operations in {client_location}, protecting critical assets against escalating climate impacts.
‚Ä¢ Urgency: Immediate action on infrastructure hardening and drainage systems is required to prevent significantly higher costs and greater future service disruption.
‚Ä¢ Strategic Alignment: Adaptation measures align with {client_name}'s service delivery objectives while meeting National Adaptation Plan compliance requirements.
‚Ä¢ Implementation Priority: Focus on no-regrets actions like infrastructure upgrades and emergency planning that provide benefits under current and future climate conditions.
‚Ä¢ Monitoring Framework: Establish robust systems to track adaptation progress specific to {client_name}'s operations.""",

        "introduction_narrative": f"""{client_name} operates within Fiji's critical {sector} sector, with assets and networks that underpin economic activity, rural livelihoods, and access to essential services across the country. Its infrastructure portfolio spans coastal, transport, and utility systems that are increasingly exposed to {', '.join(key_climate_risks[:2])}. In this context, climate adaptation is central to safeguarding development gains, protecting vulnerable communities, and ensuring the continuity of operations in a rapidly changing climate.

Against this backdrop, the organisation's climate adaptation objectives focus on embedding resilience within core strategies, investment decisions, and day-to-day operations. The plan seeks to move beyond high-level commitments by providing a practical, evidence-based framework that links climate risk insights to concrete actions on the ground. It aims to position the organisation as a leader in climate-resilient infrastructure, demonstrating a robust business case for adaptation that reduces future disaster costs and service disruptions.

A central rationale for the plan is the need for strong vertical alignment with national policy and planning frameworks. {client_name} recognises that aligning its work with Fiji's National Development Plan, National Adaptation Plan v2.0, and Nationally Determined Contributions ensures coherence, eligibility for climate finance, and contribution to national resilience targets. This alignment also supports transparent reporting on climate risk and adaptation progress in line with evolving regulatory and standards requirements.

Equally important is horizontal alignment across government and key partners, which the plan is designed to enable. By coordinating with ministries such as the Ministry of Environment and Climate Change and the Ministry of Rural and Maritime Development and Disaster Management, the organisation can avoid duplication, leverage shared data and expertise, and deliver integrated solutions in rural and maritime areas. This collaborative approach is essential to addressing cross-cutting challenges such as coastal protection, rural infrastructure resilience, and food and water security.

Finally, the plan is grounded in the need to transform climate risk analysis into actionable pathways and to build lasting internal capacity. It establishes clear, prioritized adaptation actions for immediate implementation while allowing flexibility to adjust as climate conditions and knowledge evolve over time. At the same time, it invests in adaptive decision-making, monitoring, review, and continuous improvement so that resilience becomes an enduring organisational capability rather than a one-off project output.""",

        "site_context_narrative": f"""The site comprises critical infrastructure assets and networks located predominantly along Fiji's coasts, river floodplains, and key rural corridors, linking villages, markets, ports, and airports that underpin trade, tourism, and service delivery. These assets include roads, bridges, jetties, utilities, public facilities, and associated rural infrastructure that connect highly exposed communities and economic hubs on Viti Levu, Vanua Levu, and outer islands.

Current climate impacts are already significant, with recurrent floods, tropical cyclones, and coastal storms causing physical damage, service disruption, and asset degradation across the transport, water, energy, health, and education systems. Events such as Tropical Cyclone Winston and major river floods have generated substantial losses, eroding development gains and straining government and community coping capacity.

Emerging vulnerabilities are driven by sea-level rise, more intense cyclones, and increasingly variable rainfall, which together amplify coastal erosion, inundation, landslides, and riverine flooding at the site. Large portions of the asset base lie in low-lying coastal zones and floodplains, where even moderate increases in flood depth or storm surge can trigger cascading failures in road access, electricity supply, water services, and critical public buildings.

These physical risks intersect with rapid urbanisation, informal settlement growth, and maintenance backlogs, compounding vulnerability for rural and peri-urban communities that rely on aging, under-designed infrastructure. Inadequate drainage, limited redundancy in the road network, and legacy siting of facilities close to rivers and shorelines increase the likelihood of prolonged outages, costly emergency repairs, and livelihood disruption as hazards intensify.

Looking ahead, projected changes in climate and exposure patterns point to rising average annual losses and more frequent "high-impact" events that exceed current design standards. Without a deliberate shift toward climate-resilient siting, design, operations, and community-level preparedness, the site's infrastructure system risks lock-in to escalating damage, higher lifecycle costs, and growing threats to rural stability, food security, and safe access to essential services."""
    }

    return templates.get(narrative_key,
                         f"This section addresses {narrative_key.replace('_', ' ')} considerations for {client_name}'s {sector} operations in {client_location}. The content details specific adaptation measures, monitoring approaches, and implementation timelines tailored to the organisation's unique climate vulnerabilities and operational requirements.")


def get_guaranteed_fallback_v4(narrative_key, context_data, v4_data):
    """100% available fallback content for JSON v4"""
    client_name = v4_data.get("client_name", "Ministry of Rural Development")
    client_location = v4_data.get("client_location", "Republic of Fiji")
    sector = v4_data.get("sector", "infrastructure")

    fallbacks = {
        "executive_summary_narrative": f"Climate Adaptation Plan for {client_name} in {client_location} addressing {sector} resilience.",
        "key_messages_callout": f"‚Ä¢ Build resilience for {client_name}'s infrastructure\n‚Ä¢ Implement adaptation measures\n‚Ä¢ Monitor and review progress",
        "introduction_narrative": f"Introduction to the adaptation plan for {client_name}.",
        "site_context_narrative": f"Site context for {client_name} in {client_location}.",
        "hazard_narrative": f"Climate hazards affecting {client_name} in {client_location}.",
        "conclusion_narrative": f"Conclusion and next steps for {client_name}'s adaptation plan."
    }

    return fallbacks.get(narrative_key, f"Content for {narrative_key.replace('_', ' ')}")


def update_template_for_v4_structure(doc, json_data):
    """Update the document structure to match JSON v4 requirements"""
    print("üîÑ Updating template for JSON v4 structure...")

    client_name = json_data.get("client_name", "Ministry of Rural Development")
    project_title = json_data.get("project_title", f"{client_name} Adaptation Plan")
    client_location = json_data.get("client_location", "Republic of Fiji")
    industry_1 = json_data.get("Industry-1", "infrastructure")
    industry_2 = json_data.get("Industry-2", "rural development systems")

    # Track changes made
    changes_made = []

    # Find and update ALL section titles using placeholders
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text

        # Update ALL placeholders in headings
        if "[[client_name]]" in text:
            new_text = text.replace("[[client_name]]", client_name)
            paragraph.text = new_text
            if new_text != text:
                changes_made.append(f"Updated client_name: '{text}' ‚Üí '{new_text}'")

        if "[[client_location]]" in text:
            new_text = text.replace("[[client_location]]", client_location)
            paragraph.text = new_text
            if new_text != text:
                changes_made.append(f"Updated client_location: '{text}' ‚Üí '{new_text}'")

        if "[[project_title]]" in text:
            new_text = text.replace("[[project_title]]", project_title)
            paragraph.text = new_text
            if new_text != text:
                changes_made.append(f"Updated project_title: '{text}' ‚Üí '{new_text}'")

        # Fix the specific section 3 title
        if "in a Changing Climate" in text and "[[" not in text:
            # This is the hardcoded version, update it
            new_title = f"{client_name} in a Changing Climate"
            paragraph.text = new_title
            changes_made.append(f"Updated section title: '{text}' ‚Üí '{new_title}'")

    # Update ALL industry references throughout the document
    industry_replacements = {
        "dairy and beef farm": f"{industry_1} operations",
        "Dairy and beef farm": f"{industry_1} operations",
        "livestock and processing systems": f"{industry_2} systems",
        "Livestock and processing systems": f"{industry_2} systems",
        "farm": industry_1,
        "Farm": industry_1,
        "cattle production": f"{industry_1} operations",
        "Cattle production": f"{industry_1} operations",
        "East Hill Farm": client_name,
        "East Hill Dairy Farm": client_name,
        "East Hill": client_name,
        "Somerset, England": client_location,
        "England": client_location.split(',')[-1].strip() if ',' in client_location else client_location,
        "Mendip Hills": "operational area"
    }

    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text
        new_text = text
        for old_term, new_term in industry_replacements.items():
            if old_term in new_text:
                new_text = new_text.replace(old_term, new_term)

        if new_text != text:
            paragraph.text = new_text
            changes_made.append(f"Replaced industry terms in paragraph {i}")

    print(f"‚úÖ Template updated with {len(changes_made)} changes")
    for change in changes_made[:5]:
        print(f"   ‚Ä¢ {change}")
    if len(changes_made) > 5:
        print(f"   ... and {len(changes_made) - 5} more changes")

    return True


# =============== END OF NEW V4 FUNCTIONS ===============

def get_guaranteed_fallback(narrative_key, context_data):
    """100% available fallback content"""
    client_name = context_data.get("client_name", "Client")
    client_location = context_data.get("client_location", "Location")

    fallbacks = {
        "executive_summary_narrative": f"Climate Adaptation Plan for {client_name} in {client_location}.",
        "key_messages_callout": f"‚Ä¢ Build resilience for {client_name}\n‚Ä¢ Implement adaptation measures\n‚Ä¢ Monitor and review progress",
        "introduction_narrative": f"Introduction to the adaptation plan for {client_name}.",
        "site_context_narrative": f"Site context for {client_name} in {client_location}.",
        "hazard_narrative": f"Climate hazards affecting {client_name} in {client_location}.",
        "conclusion_narrative": f"Conclusion and next steps for {client_name}'s adaptation plan."
    }

    return fallbacks.get(narrative_key, f"Content for {narrative_key.replace('_', ' ')}")

def generate_ai_narratives_with_prompts(json_data, prompt_context=None):
    """Generate all AI narratives using EXACT prompts from Prompts_v3.docx with 100% reliability"""
    print("ü§ñ Generating AI narratives with JSON v4 data...")

    # If no prompt_context provided, use basic context
    if prompt_context is None:
        prompt_context = build_default_prompt_context(json_data)

    # Parse JSON v4 data
    v4_data = parse_json_v4_data(json_data)

    client_name = v4_data["client_name"]
    client_location = v4_data["client_location"]
    sector = v4_data["sector"]
    key_climate_risks = v4_data["key_climate_risks"]
    regulatory_context = v4_data["regulatory_context"]
    organisation_profile = v4_data["organisation_profile"]
    objectives = v4_data["objectives"]
    regulatory_requirements = v4_data["regulatory_requirements"]
    industry_1 = v4_data["industry_1"]
    industry_2 = v4_data["industry_2"]

    print(f"üìù Generating narratives for: {client_name}, {client_location}")
    print(f"üìä Using JSON v4: Sector={sector}, Industry1={industry_1}, Industry2={industry_2}")
    print(f"üìã Climate Risks: {key_climate_risks}")

    # Define EXACT prompts for JSON v4 structure
    exact_prompts = {
        "executive_summary_narrative": {
            "system_prompt": "You are generating a professionally written executive summary for a climate adaptation plan. Use neutral, objective language. Use proper bullet points (‚Ä¢) not asterisks (*). IMPORTANT: The document already contains a section '1.1 Why this plan and what it delivers' with three specific bullet points. DO NOT repeat or recreate this content.",
            "user_prompt": f"""IMPORTANT: The document template already contains the static text section "1.1 Why this plan and what it delivers" with three bullet points about Regulatory alignment, Actionable pathway, and Continuous improvement. Your task is to write the MAIN executive summary narrative that comes BEFORE that static section.

Produce 250-300 words summarising the climate context, organisational risk profile, regulatory drivers, and overall purpose of the adaptation plan for {client_name} in {client_location}.

CLIENT CONTEXT:
- Organisation: {client_name}
- Location: {client_location}
- Sector: {sector}
- Key Climate Risks: {', '.join(key_climate_risks[:5]) if isinstance(key_climate_risks, list) else key_climate_risks}
- Focus: {industry_1} and {industry_2} operations

STRUCTURE YOUR RESPONSE AS:
1. First paragraph: Climate context and key risks facing the organisation
2. Second paragraph: Purpose and regulatory drivers of the adaptation plan
3. Third paragraph: Overall approach and strategic focus
4. End with "Key messages:" section with 5-7 concise bullet points

KEY MESSAGES FORMAT (use ‚Ä¢ not *):
‚Ä¢ Value: [Why adaptation is valuable for this organisation]
‚Ä¢ Urgency: [Why immediate action is needed]
‚Ä¢ Action: [Key required actions - be specific to {industry_1}]
‚Ä¢ Strategic: [Strategic considerations]
‚Ä¢ Implementation: [Implementation priorities]

CRITICAL: Do NOT include any text about "Regulatory alignment:", "Actionable pathway:", or "Continuous improvement:" - these are already in the template. Focus only on the narrative summary and key messages.

Return professional, concise content that flows naturally into the existing static section."""
        },

        "key_messages_callout": {
            "system_prompt": "Generate concise bullet points for a climate adaptation plan. Use proper bullet characters (‚Ä¢) NOT asterisks (*). Do not use markdown formatting.",
            "user_prompt": f"""Generate 5 concise bullet-point key messages summarising the adaptation plan's value, urgency, and required actions for {client_name}.

CLIENT CONTEXT:
- Organisation: {client_name}
- Location: {client_location}
- Sector: {sector}
- Key Risks: {', '.join(key_climate_risks[:3]) if isinstance(key_climate_risks, list) else key_climate_risks}

CRITICAL FORMATTING:
1. Use proper bullet points: ‚Ä¢ (not * or -)
2. One bullet per line
3. No markdown formatting
4. Focus on infrastructure resilience, regulatory compliance, and practical actions
5. Example format:
‚Ä¢ Strengthens climate-resilient infrastructure while supporting Fiji's National Adaptation Plan
‚Ä¢ Addresses escalating risks to coastal, transport, and utility infrastructure
‚Ä¢ Underscores urgency: immediate action needed to avoid rising disaster losses

Return only bullet points with proper formatting."""
        },

        "introduction_narrative": {
            "system_prompt": "You are generating a professional introduction for a climate adaptation plan. Use proper bullet points (‚Ä¢) not asterisks (*).",
            "user_prompt": f"""Generate an introductory narrative describing the organisation, its climate adaptation objectives, and the rationale for creating the plan. Return 5 paragraphs.

ORGANISATION CONTEXT:
- Organisation: {client_name}
- Location: {client_location}
- Sector: {sector}
- Infrastructure Focus: {industry_1}
- Key Operations: {industry_2}
- Objectives: {', '.join(objectives[:3]) if objectives else 'Build climate resilience, ensure regulatory compliance, protect operations'}
- Regulatory Requirements: {', '.join(regulatory_requirements[:2]) if regulatory_requirements else 'National Adaptation Plan v2.0, ISO 14090'}

STRUCTURE YOUR 5 PARAGRAPHS AS:
1. Organisation's role and exposure to climate risks in Fiji's infrastructure sector
2. Climate adaptation objectives and practical framework
3. Alignment with national policies (National Development Plan, NAP v2.0)
4. Coordination with partners and government ministries
5. Building internal capacity and actionable pathways

Write fluid, integrated content specific to infrastructure in Fiji."""
        },

        "site_context_narrative": {
            "system_prompt": "You are generating a professional site description for a climate adaptation plan. Use proper bullet points (‚Ä¢) not asterisks (*).",
            "user_prompt": f"""Draft a concise overview of the site, current climate impacts, and emerging vulnerabilities. Return 5 paragraphs.

SITE CONTEXT:
- Organisation: {client_name}
- Location: {client_location}
- Sector: {sector}
- Key Infrastructure: Coastal, transport, and utility systems across Fiji's islands
- Exposure: {', '.join(key_climate_risks[:3]) if isinstance(key_climate_risks, list) else key_climate_risks}
- Geographic Scope: Viti Levu, Vanua Levu, and outer islands

STRUCTURE YOUR 5 PARAGRAPHS AS:
1. Site composition and location (coastal assets, rural corridors, critical infrastructure)
2. Current climate impacts (floods, tropical cyclones, service disruptions)
3. Emerging vulnerabilities (sea-level rise, intense cyclones, variable rainfall)
4. Intersection with other risks (urbanization, maintenance backlogs, community vulnerability)
5. Future projections and risks without adaptation

Be specific about Fiji's infrastructure context and use examples like Tropical Cyclone Winston."""
        },

        "integration_management_narrative": {
            "system_prompt": "You are describing management system integration for a climate adaptation plan. Use proper bullet points (‚Ä¢) not asterisks (*).",
            "user_prompt": f"""Describe how climate adaptation will be embedded in {client_name}'s existing management systems in Fiji.

ORGANISATION CONTEXT:
- Organisation: {client_name}
- Sector: {sector}
- Key Management Systems: ["Environmental Management System", "Operational Management System", "Disaster Risk Management"]
- Integration Needs: ["permits compliance", "asset management", "emergency planning", "climate finance access"]

STRUCTURE YOUR RESPONSE AS:
1. First paragraph: Overview of integration approach
2. Second paragraph: Specific management systems for integration
3. Third paragraph: Benefits and implementation considerations

Return 3 paragraphs with proper formatting."""
        },

        "vision_narrative": {
            "system_prompt": "You are writing a vision statement for a climate adaptation plan. Use proper bullet points (‚Ä¢) not asterisks (*).",
            "user_prompt": f"""Write a future-oriented resilience vision tailored to {client_name} in Fiji.

ORGANISATION CONTEXT:
- Organisation: {client_name}
- Location: {client_location}
- Sector: {sector}
- Long-term Goals: ["maintain critical services through climate impacts", "protect infrastructure assets", "ensure business continuity", "support rural livelihoods"]
- Planning Horizon: "to 2050 and beyond aligned with Fiji's National Adaptation Plan"

STRUCTURE YOUR RESPONSE AS:
1. First paragraph: Vision statement for resilient operations
2. Second paragraph: Guiding principles and approach
3. Third paragraph: Long-term objectives and milestones

Return 2-3 paragraphs with proper bullet formatting if needed."""
        },

        "hazard_narrative": {
            "system_prompt": "You are generating a hazard overview for a climate adaptation plan. Use proper bullet points (‚Ä¢) not asterisks (*).",
            "user_prompt": f"""Generate a hazard overview explaining current and future hazard trends for {client_name} in {client_location}.

HAZARD CONTEXT:
- Organisation: {client_name}
- Location: {client_location}
- Key Hazards: {key_climate_risks}
- Scenario Assumptions: ["intensifying tropical cyclones", "accelerating sea-level rise", "more variable rainfall"]

STRUCTURE YOUR RESPONSE AS:
1. First paragraph: Current hazard landscape
2. Second paragraph: Future projections and trends
3. Third paragraph: Key vulnerabilities and exposure points

Return 2-3 paragraphs with proper bullet formatting if needed."""
        },

        "methodology_narrative": {
            "system_prompt": "You are summarizing methodology for a climate adaptation plan. Use proper bullet points (‚Ä¢) not asterisks (*).",
            "user_prompt": f"""Summarise the rapid risk and vulnerability assessment methodology used for {client_name}.

METHODOLOGY CONTEXT:
- Organisation: {client_name}
- Sector: {sector}
- Methodology Parameters: ["exposure analysis of infrastructure assets", "vulnerability assessment of rural communities", "adaptive capacity analysis of ministry systems"]
- Approach: ["workshop-based", "stakeholder engagement", "data-driven analysis"]

STRUCTURE YOUR RESPONSE AS:
1. First paragraph: Overall methodology approach
2. Second paragraph: Key assessment components
3. Third paragraph: Stakeholder involvement and data sources

Return 2-3 paragraphs with proper bullet formatting if needed."""
        },

        "impact_narrative": {
            "system_prompt": "You are describing climate impacts for an adaptation plan. Use proper bullet points (‚Ä¢) not asterisks (*).",
            "user_prompt": f"""Using the climate risks, produce a narrative describing key climate impacts on {client_name}'s {sector} operations and when they become significant.

IMPACT CONTEXT:
- Organisation: {client_name}
- Sector: {sector}
- Key Climate Risks: {key_climate_risks}
- Impact Assessment: ["1.0-1.5¬∞C: early impacts on coastal infrastructure", "1.5-2.0¬∞C: chronic issues with transport disruptions", "2.0-2.5¬∞C: compounding problems for utility services"]

STRUCTURE YOUR RESPONSE AS:
1. First paragraph: Near-term impacts (1.0-1.5¬∞C warming)
2. Second paragraph: Medium-term impacts (1.5-2.0¬∞C warming)
3. Third paragraph: Long-term impacts (2.0-2.5¬∞C+ warming)

Return 3 paragraphs with proper bullet formatting if needed."""
        },

        "adaptive_capacity_narrative": {
            "system_prompt": "You are describing adaptive capacity for an adaptation plan. Use proper bullet points (‚Ä¢) not asterisks (*).",
            "user_prompt": f"""Describe the current capacity, strengths, and gaps for {client_name}.

CAPACITY CONTEXT:
- Organisation: {client_name}
- Sector: {sector}
- Capacity Current: {{"level": "Response Level 2", "strengths": ["national mandate", "technical expertise", "stakeholder networks"]}}
- Capacity Gaps: ["climate-informed infrastructure design", "specialized monitoring systems", "integrated decision-making"]

STRUCTURE YOUR RESPONSE AS:
1. First paragraph: Current capacity assessment
2. Second paragraph: Key strengths and capabilities
3. Third paragraph: Identified gaps and development needs

Return 2-3 paragraphs with proper bullet formatting if needed."""
        },

        "capacity_comparison_narrative": {
            "system_prompt": "You are comparing adaptive capacity levels for an adaptation plan. Use proper bullet points (‚Ä¢) not asterisks (*).",
            "user_prompt": f"""Generate text comparing current adaptive capacity to target capacity for {client_name}.

CAPACITY CONTEXT:
- Organisation: {client_name}
- Capacity Current: {{"level": "Response Level 2", "description": "stakeholder responsive"}}
- Capacity Target: {{"level": "Response Level 4", "description": "breakthrough projects"}}

STRUCTURE YOUR RESPONSE AS:
1. First paragraph: Current capacity level and characteristics
2. Second paragraph: Target capacity level and requirements
3. Third paragraph: Development pathway and transition needs

Return 2 paragraphs with proper bullet formatting if needed."""
        },

        "physical_risk_narrative": {
            "system_prompt": "You are summarizing physical risk management for an adaptation plan. Use proper bullet points (‚Ä¢) not asterisks (*).",
            "user_prompt": f"""Summarise physical risk management strategies aligned with climate hazards for {client_name}.

PHYSICAL RISK CONTEXT:
- Organisation: {client_name}
- Sector: {sector}
- Key Hazards: {key_climate_risks[:3]}
- Physical Actions: ["coastal protection infrastructure", "climate-resilient road design", "flood-proofing of critical facilities", "water storage solutions"]

STRUCTURE YOUR RESPONSE AS:
1. First paragraph: Overview of physical risk management approach
2. Second paragraph: Key infrastructure protection measures
3. Third paragraph: Implementation strategy and phasing

Return 2-3 paragraphs with proper bullet formatting if needed."""
        },

        "capacity_development_narrative": {
            "system_prompt": "You are describing capacity development for an adaptation plan. Use proper bullet points (‚Ä¢) not asterisks (*).",
            "user_prompt": f"""Describe the phased approach to building adaptive capacity for {client_name}.

CAPACITY DEVELOPMENT CONTEXT:
- Organisation: {client_name}
- Sector: {sector}
- Capacity Actions: ["leadership engagement on climate risks", "technical staff training", "community empowerment programs"]
- Phasing: ["short-term (0-2 years)", "medium-term (2-5 years)", "long-term (5+ years)"]

STRUCTURE YOUR RESPONSE AS:
1. First paragraph: Short-term capacity building activities
2. Second paragraph: Medium-term development objectives
3. Third paragraph: Long-term sustainability and institutionalization

Return 2 paragraphs with proper bullet formatting if needed."""
        },

        "monitoring_narrative": {
            "system_prompt": "You are summarizing M&E framework for an adaptation plan. Use proper bullet points (‚Ä¢) not asterisks (*).",
            "user_prompt": f"""Summarise the M&E framework, review cycles, and continual improvement process for {client_name}.

MONITORING CONTEXT:
- Organisation: {client_name}
- Sector: {sector}
- Monitoring Framework: ["six-monthly infrastructure performance reviews", "climate impact tracking", "community feedback mechanisms"]
- Review Cycles: ["quarterly operational reviews", "annual strategic reviews", "five-year comprehensive reviews"]

STRUCTURE YOUR RESPONSE AS:
1. First paragraph: Monitoring framework overview
2. Second paragraph: Review cycles and processes
3. Third paragraph: Continual improvement approach

Return 2 paragraphs with proper bullet formatting if needed."""
        },

        "conclusion_narrative": {
            "system_prompt": "You are writing a conclusion for an adaptation plan. Use proper bullet points (‚Ä¢) not asterisks (*).",
            "user_prompt": f"""Write a closing section summarising the path forward, immediate next steps, and long-term considerations for {client_name}.

CONCLUSION CONTEXT:
- Organisation: {client_name}
- Sector: {sector}
- Priorities: ["embed adaptation into infrastructure plans", "assign accountability", "establish monitoring"]
- Timelines: ["immediate: endorse plan", "short-term: develop implementation schedule", "medium-term: execute first adaptation actions"]
- Integration Steps: ["align with National Adaptation Plan cycles", "integrate with ministry management systems", "coordinate with rural development partners"]

STRUCTURE YOUR RESPONSE AS:
1. First paragraph: Summary of key findings and recommendations
2. Second paragraph: Immediate next steps and priorities
3. Third paragraph: Long-term vision and sustainability

Return 2 paragraphs with proper bullet formatting if needed."""
        }
    }

    generated_content = {}
    narrative_count = 0
    total_narratives = len(exact_prompts)

    # Prepare context data for all narratives
    context_data = {
        "client_name": client_name,
        "client_location": client_location,
        "sector": sector,
        "Industry-1": industry_1,
        "Industry-2": industry_2,
        "prompt_context": prompt_context,
        "v4_data": v4_data
    }

    # Track narrative keys for ordering
    narrative_keys = list(exact_prompts.keys())

    # Generate each narrative using tiered fallback system
    for i, narrative_key in enumerate(narrative_keys):
        prompt_info = exact_prompts[narrative_key]

        try:
            print(f"\nüìù Generating {i + 1}/{total_narratives}: {narrative_key}")

            # Build complete prompt
            complete_prompt = f"{prompt_info['system_prompt']}\n\n{prompt_info['user_prompt']}"

            # DEBUG: Print first 100 chars of prompt
            print(f"   Prompt: {complete_prompt[:100]}...")

            # Add delay between calls to prevent API overload (except first)
            if i > 0:
                delay_seconds = 4  # 4 seconds between calls
                print(f"‚è≥ Waiting {delay_seconds} seconds between narratives...")
                time.sleep(delay_seconds)

            # ===== TIERED FALLBACK GENERATION =====
            # 1. Check cache first (instant)
            cached_content = get_cached_similar_content(narrative_key, complete_prompt)
            if cached_content:
                print(f"   ‚úÖ Using cached content for {narrative_key}")
                generated_content[narrative_key] = cached_content
                narrative_count += 1
                continue

            # 2. Try Gemini AI with retry
            print(f"   üîÑ Trying Gemini AI...")
            gemini_success = False
            gemini_content = None

            if GEMINI_API_KEY and AVAILABLE_GEMINI_MODEL:
                for attempt in range(3):  # 3 attempts max
                    try:
                        # Apply rate limiting
                        if 'gemini_rate_limiter' in globals():
                            gemini_rate_limiter.wait_if_needed()

                        print(f"   ü§ñ Gemini attempt {attempt + 1}/3...")
                        gemini_content = generate_content_with_gemini_proper_bullets(complete_prompt)

                        if gemini_content and len(gemini_content.strip()) > 100:
                            # Cache successful result
                            cache_result(narrative_key, complete_prompt, gemini_content, source="gemini")
                            generated_content[narrative_key] = gemini_content
                            narrative_count += 1
                            gemini_success = True
                            print(f"   ‚úÖ Gemini succeeded")
                            break
                        else:
                            print(f"   ‚ö†Ô∏è Gemini returned insufficient content")

                    except Exception as gemini_error:
                        print(f"   ‚ö†Ô∏è Gemini error: {str(gemini_error)[:100]}")

                    # Wait before retry
                    if attempt < 2:
                        wait_time = 5 * (attempt + 1)  # 5, 10 seconds
                        print(f"   ‚è≥ Waiting {wait_time} seconds before retry...")
                        time.sleep(wait_time)

            if gemini_success:
                continue

            # 3. Use template-based generation
            print(f"   üìù Using template generation...")
            # Use V4 template if we have V4 data, otherwise use original
            if 'v4_data' in context_data and context_data['v4_data']:
                template_content = generate_from_template_v4(narrative_key, context_data, context_data['v4_data'])
            else:
                template_content = generate_from_template(narrative_key, context_data)

            if template_content and len(template_content.strip()) > 50:
                # Cache template result
                cache_result(narrative_key, complete_prompt, template_content, source="template")
                generated_content[narrative_key] = template_content
                narrative_count += 1
                print(f"   ‚úÖ Template generation succeeded")
                continue

            # 4. Ultimate fallback (guaranteed)
            print(f"   üõ°Ô∏è Using guaranteed fallback...")
            # Use V4 fallback if we have V4 data
            if 'v4_data' in context_data and context_data['v4_data']:
                fallback_content = get_guaranteed_fallback_v4(narrative_key, context_data, context_data['v4_data'])
            else:
                fallback_content = get_guaranteed_fallback(narrative_key, context_data)

            cache_result(narrative_key, complete_prompt, fallback_content, source="fallback")
            generated_content[narrative_key] = fallback_content
            narrative_count += 1
            print(f"   ‚úÖ Fallback content provided")

        except Exception as e:
            print(f"‚ùå Critical error generating {narrative_key}: {e}")
            import traceback
            traceback.print_exc()

            # Emergency fallback
            emergency_content = f"Climate adaptation content for {client_name}. This section addresses {narrative_key.replace('_', ' ')}."
            generated_content[narrative_key] = emergency_content
            narrative_count += 1
            print(f"   üö® Emergency fallback used")

    print(f"\nüìä TIERED GENERATION COMPLETE: {narrative_count}/{total_narratives} narratives generated")
    print(f"   Success rate: 100% (guaranteed by fallback system)")

    return generated_content


def generate_content_with_gemini_proper_bullets(prompt):
    """Gemini content generation with proper bullet formatting"""
    if not GEMINI_API_KEY or not AVAILABLE_GEMINI_MODEL:
        return None

    try:
        model_name = AVAILABLE_GEMINI_MODEL['name']
        api_version = AVAILABLE_GEMINI_MODEL['version']
        api_url = f"https://generativelanguage.googleapis.com/{api_version}/{model_name}:generateContent?key={GEMINI_API_KEY}"

        # Enhance prompt to ensure proper bullet formatting
        enhanced_prompt = f"""{prompt}

CRITICAL FORMATTING INSTRUCTIONS FOR WORD DOCUMENT:
1. For bullet points, ALWAYS use: ‚Ä¢ (proper bullet character)
2. NEVER use: * (asterisk) or - (dash) for bullets
3. NEVER use markdown formatting like **bold** or *italic*
4. If listing items, format as:
‚Ä¢ First item
‚Ä¢ Second item
‚Ä¢ Third item
5. Use plain text only, no special formatting codes
6. Each bullet should be on its own line starting with ‚Ä¢
"""

        payload = {
            "contents": [{"parts": [{"text": enhanced_prompt}]}],
            "generationConfig": {
                "temperature": 0.3,
                "maxOutputTokens": 2000,
                "stopSequences": ["*", "**", "- "]  # Prevent asterisk and dash usage
            }
        }

        response = requests.post(api_url, json=payload, timeout=60)

        if response.status_code == 200:
            result = response.json()
            if 'candidates' in result and result['candidates']:
                content = result['candidates'][0]['content']['parts'][0]['text']

                # Post-process to fix any remaining asterisks
                content = clean_ai_generated_bullets(content)
                return content.strip()
            else:
                print(f"‚ö†Ô∏è No candidates in Gemini response")
        else:
            print(f"‚ö†Ô∏è Gemini API returned status {response.status_code}")
            print(f"   Response: {response.text[:200]}")

        return None

    except requests.exceptions.Timeout:
        print(f"‚ö†Ô∏è Gemini API timeout for prompt")
        return None
    except Exception as e:
        print(f"‚ö†Ô∏è Gemini API error: {e}")
        return None


def generate_content_with_gemini_with_retry(prompt, max_retries=3, base_delay=2):
    """Generate content with retry logic for rate limits"""
    for attempt in range(max_retries):
        try:
            # Apply rate limiting before each attempt
            gemini_rate_limiter.wait_if_needed()

            print(f"ü§ñ Gemini attempt {attempt + 1}/{max_retries}...")
            result = generate_content_with_gemini_proper_bullets(prompt)

            if result and len(result.strip()) > 50:
                return result

            # If we got here, either Gemini failed or returned short content
            if attempt < max_retries - 1:  # Don't sleep on last attempt
                delay = base_delay * (2 ** attempt)  # Exponential backoff
                print(f"‚ö†Ô∏è Gemini attempt {attempt + 1} failed, retrying in {delay} seconds...")
                time.sleep(delay)

        except Exception as e:
            if attempt < max_retries - 1:
                delay = base_delay * (2 ** attempt)
                print(f"‚ö†Ô∏è Gemini error on attempt {attempt + 1}: {e}, retrying in {delay} seconds...")
                time.sleep(delay)
            else:
                print(f"‚ùå Gemini failed after {max_retries} attempts: {e}")

    return None

def clean_ai_generated_bullets(content):
    """Clean up bullet formatting in AI-generated content"""
    if not content:
        return content

    # First, normalize line endings
    content = content.replace('\r\n', '\n')

    # Replace common bullet formats with proper bullets
    bullet_replacements = [
        (r'^\s*\*\s+', '‚Ä¢ '),  # Asterisk at line start
        (r'^\s*-\s+', '‚Ä¢ '),  # Dash at line start
        (r'\*\s+', '‚Ä¢ '),  # Asterisk with space anywhere
        (r'-\s+', '‚Ä¢ '),  # Dash with space anywhere
        (r'\*\*', ''),  # Remove bold markers
        (r'^\s*\d+\.\s+', ''),  # Remove numbered lists at start
        (r'‚Ä¢\s{2,}', '‚Ä¢ '),  # Fix multiple spaces after bullet
    ]

    # Apply replacements
    for pattern, replacement in bullet_replacements:
        if pattern.startswith('^'):  # Line start patterns
            lines = content.split('\n')
            cleaned_lines = []
            for line in lines:
                cleaned_line = re.sub(pattern, replacement, line)
                cleaned_lines.append(cleaned_line)
            content = '\n'.join(cleaned_lines)
        else:  # Global patterns
            content = re.sub(pattern, replacement, content)

    # Ensure bullets are properly formatted
    lines = content.split('\n')
    formatted_lines = []

    for line in lines:
        stripped = line.strip()
        # If line looks like it should be a bullet but doesn't start with ‚Ä¢
        if stripped and len(stripped) > 10 and not stripped.startswith('‚Ä¢'):
            # Check if it's a bullet point without proper formatting
            if stripped[0] in ['*', '-']:
                line = '‚Ä¢ ' + stripped[1:].strip()
            elif any(x in stripped.lower() for x in ['value:', 'urgency:', 'action:', 'priority:', 'key message:']):
                line = '‚Ä¢ ' + stripped

        formatted_lines.append(line)

    return '\n'.join(formatted_lines)


# ===== ADD THIS HELPER FUNCTION =====
def generate_content_with_gemini_simple(prompt):
    """Simple Gemini content generation without complex formatting rules"""
    if not GEMINI_API_KEY or not AVAILABLE_GEMINI_MODEL:
        return None

    try:
        model_name = AVAILABLE_GEMINI_MODEL['name']
        api_version = AVAILABLE_GEMINI_MODEL['version']
        api_url = f"https://generativelanguage.googleapis.com/{api_version}/{model_name}:generateContent?key={GEMINI_API_KEY}"

        payload = {
            "contents": [{"parts": [{"text": prompt}]}],
            "generationConfig": {
                "temperature": 0.3,
                "maxOutputTokens": 2000,
            }
        }

        response = requests.post(api_url, json=payload, timeout=60)

        if response.status_code == 200:
            result = response.json()
            if 'candidates' in result and result['candidates']:
                content = result['candidates'][0]['content']['parts'][0]['text']
                return content.strip()

        return None

    except Exception as e:
        print(f"‚ö†Ô∏è Gemini API error: {e}")
        return None


# ===== ADD THIS FALLBACK FUNCTION =====
def get_fallback_narrative_exact(narrative_key, client_name, client_location, industry_1, industry_2):
    """Get exact fallback narratives matching Prompts_v3.docx structure"""

    fallback_narratives = {
        # ... your existing fallbacks ...

        # Add these if missing:
        "vision_narrative": f"{client_name} envisions a resilient future where its {industry_1} operations continue to thrive despite increasing climate challenges. The vision is to maintain operational viability through approximately 3¬∞C of global warming by implementing proactive adaptation measures that protect assets, ensure business continuity, and support sustainable growth in {client_location}.",

        "adaptive_capacity_narrative": f"{client_name} currently demonstrates a responsive approach to climate adaptation, with established awareness of key risks and basic compliance measures in place. Current strengths include stakeholder engagement capabilities and adherence to regulatory requirements. However, gaps exist in specialized climate expertise, advanced monitoring systems, and integrated decision-making processes that consider long-term climate projections.",

        "methodology_narrative": f"The adaptation planning methodology employed for {client_name} combines rapid risk assessment techniques with detailed vulnerability analysis. This approach examines exposure to climate hazards, assesses sensitivity of {industry_1} operations, and evaluates adaptive capacity across organizational, technical, and financial dimensions. The methodology ensures that adaptation measures are proportionate, evidence-based, and aligned with both immediate needs and long-term climate projections for {client_location}.",

        "integration_management_narrative": f"Climate adaptation will be systematically integrated into {client_name}'s existing management systems, including environmental management, operational planning, and emergency response frameworks. This integration ensures that adaptation considerations become routine elements of decision-making, capital investment planning, and performance monitoring across all {industry_1} operations in {client_location}."
    }

    # Return the exact narrative or a generic one if not found
    return fallback_narratives.get(narrative_key,
                                   f"Content for {narrative_key.replace('_', ' ')} specific to {client_name}'s {industry_1} in {client_location}. This section addresses climate adaptation considerations tailored to the operational context and vulnerabilities.")


# ===== MODIFY THE integrate_bespoke_content_with_prompts FUNCTION =====
def integrate_bespoke_content_with_prompts(doc, json_data, form_prompts=None):
    """Main integration function with EXACT prompt support"""
    print("üîç Starting content integration with EXACT prompts...")

    # Generate AI narratives using EXACT prompts
    ai_narratives = generate_ai_narratives_with_prompts(json_data, form_prompts)

    # Update json_data with generated narratives
    for key, value in ai_narratives.items():
        json_data[key] = value

    # Build comprehensive content mapping
    content_mapping = build_comprehensive_content_mapping(json_data)

    print(f"üîß Replacing placeholders with {len(content_mapping)} content items...")

    # Replace all placeholders in the document
    replace_all_narrative_placeholders(doc, content_mapping)

    # Clean up any remaining placeholders
    remove_specific_placeholders(doc)

    # Clean up bullet formatting
    clean_up_bullet_formatting(doc)

    print("‚úÖ Content integration completed with EXACT prompts")
    return True


# ===== ADD THIS FUNCTION =====
def build_comprehensive_content_mapping(json_data):
    """Build mapping of ALL narrative placeholders to their content"""
    content_mapping = {}

    # List of ALL narrative placeholders that should be in the document
    narrative_placeholders = [
        "executive_summary_narrative",
        "key_messages_callout",
        "introduction_narrative",
        "site_context_narrative",
        "integration_management_narrative",
        "vision_narrative",
        "hazard_narrative",
        "methodology_narrative",
        "impact_narrative",
        "adaptive_capacity_narrative",
        "capacity_comparison_narrative",
        "physical_risk_narrative",
        "capacity_development_narrative",
        "monitoring_narrative",
        "conclusion_narrative"
    ]

    # Add each narrative with [[ ]] brackets
    for placeholder in narrative_placeholders:
        content_key = f"[[{placeholder}]]"
        content_mapping[content_key] = json_data.get(placeholder, "")

    # Add basic placeholders
    content_mapping.update({
        "[[project_title]]": json_data.get("project_title", ""),
        "[[client_name]]": json_data.get("client_name", ""),
        "[[client_location]]": json_data.get("client_location", ""),
        "[[report_date]]": json_data.get("report_date", ""),
        "[[industry-1]]": json_data.get("Industry-1", ""),
        "[[Industry-1]]": json_data.get("Industry-1", ""),
        "[[industry-2]]": json_data.get("Industry-2", ""),
        "[[Industry-2]]": json_data.get("Industry-2", ""),
        "[[exec-summ_bespoke_text]]": json_data.get("exec-summ_bespoke_text", ""),
        "[[intro-bespoke_text]]": json_data.get("intro-bespoke_text", ""),
        "[[client-desc_bespoke_text]]": json_data.get("client-desc_bespoke_text", ""),
        "[[lof]]": json_data.get("lof", ""),
        "[[lot]]": json_data.get("lot", ""),
    })

    return content_mapping


# ===== ADD THIS FUNCTION =====
def replace_all_narrative_placeholders(doc, content_mapping):
    """Replace ALL narrative placeholders in the document"""
    print(f"üîÑ Replacing {len(content_mapping)} narrative placeholders...")

    replaced_count = 0

    # Replace in paragraphs
    for paragraph in doc.paragraphs:
        original_text = paragraph.text
        if original_text:
            new_text = original_text
            for placeholder, content in content_mapping.items():
                if placeholder in original_text and content:
                    new_text = new_text.replace(placeholder, content)
                    replaced_count += 1
                    print(f"‚úÖ Replaced '{placeholder}' in paragraph")

            if new_text != original_text:
                paragraph.text = new_text

    # Replace in tables
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                for paragraph in cell.paragraphs:
                    original_text = paragraph.text
                    if original_text:
                        new_text = original_text
                        for placeholder, content in content_mapping.items():
                            if placeholder in original_text and content:
                                new_text = new_text.replace(placeholder, content)
                                replaced_count += 1

                        if new_text != original_text:
                            paragraph.text = new_text

    # Replace in headers and footers
    for section in doc.sections:
        if section.header:
            for paragraph in section.header.paragraphs:
                original_text = paragraph.text
                if original_text:
                    new_text = original_text
                    for placeholder, content in content_mapping.items():
                        if placeholder in original_text and content:
                            new_text = new_text.replace(placeholder, content)

                    if new_text != original_text:
                        paragraph.text = new_text

        if section.footer:
            for paragraph in section.footer.paragraphs:
                original_text = paragraph.text
                if original_text:
                    new_text = original_text
                    for placeholder, content in content_mapping.items():
                        if placeholder in original_text and content:
                            new_text = new_text.replace(placeholder, content)

                    if new_text != original_text:
                        paragraph.text = new_text

    print(f"‚úÖ Replaced {replaced_count} narrative placeholders")


def build_enhanced_narrative_prompt(base_prompt, narrative_data, narrative_key, narrative_type, prompt_context,
                                    json_data):
    """Build enhanced prompt for narrative generation"""

    # Extract client context
    client_name = prompt_context.get("client_context", {}).get("name", json_data.get("client_name", "the client"))
    client_location = prompt_context.get("client_context", {}).get("location",
                                                                   json_data.get("client_location", "the location"))
    industry_1 = prompt_context.get("client_context", {}).get("primary_industry", json_data.get("Industry-1", "farm"))
    industry_2 = prompt_context.get("client_context", {}).get("secondary_industry",
                                                              json_data.get("Industry-2", "livestock operations"))

    # Build focus areas string
    focus_areas = ""
    focus_list = prompt_context.get("focus_areas", [])
    if focus_list:
        focus_areas = f"\nFOCUS AREAS: {', '.join(focus_list)}."

    # Get general guidance
    general_guidance = prompt_context.get("general_guidance",
                                          "Generate professional, accurate content for a climate adaptation plan.")

    # Get specific instructions
    instructions = prompt_context.get("instructions", "")

    # Build the complete prompt
    complete_prompt = f"""TASK: Generate content for a climate adaptation plan report.

CLIENT SPECIFICS:
- Client: {client_name}
- Location: {client_location}
- Farm Type: {industry_1} (dairy/beef operations)
- Key Operations: {industry_2}

GENERAL GUIDANCE: {general_guidance}

{focus_areas}

SPECIFIC TASK FOR THIS SECTION: {base_prompt}

SECTION TYPE: {narrative_type.replace('_', ' ').title()}

{instructions if instructions else "IMPORTANT: Write fluid, integrated content. DO NOT add boilerplate like 'Context: This content is specific to...'. Be specific about the farm's actual situation."}

RELEVANT DATA FROM CLIENT:
{narrative_data if narrative_data else "No specific data provided for this section."}

ADDITIONAL CONTEXT:
- Farm elevation: 190m in Mendip Hills
- Current issues: Surface water flooding, livestock heat stress
- Transport dependencies: Vulnerable to flooded roads
- Regulatory: Environment Agency compliance, ISO 14090 standards

FORMATTING REQUIREMENTS:
1. Use professional but practical farming business tone
2. Be specific to {client_name}'s actual dairy/beef operations
3. Include practical examples relevant to Somerset farming
4. Avoid generic statements - reference actual farm conditions
5. For bullet points, use '‚Ä¢' not '*' or '-'
6. Write complete, integrated paragraphs
7. DO NOT use markdown formatting (no **bold** or *italic*)
8. DO NOT add section headers like "AI Analysis" or "Context"
9. Content should flow naturally as part of the report

Generate content that is tailored specifically to {client_name}'s situation as described above."""

    return complete_prompt

def get_default_context_for_narrative_with_prompt(narrative_key, json_data, prompt_context):
    """Get default context for a narrative with prompt awareness"""
    client_name = prompt_context.get("client_context", {}).get("name", json_data.get("client_name", "East Higher Farm"))
    client_location = prompt_context.get("client_context", {}).get("location", json_data.get("client_location", "Somerset, England"))
    industry_1 = prompt_context.get("client_context", {}).get("primary_industry", json_data.get("Industry-1", "farm"))
    industry_2 = prompt_context.get("client_context", {}).get("secondary_industry", json_data.get("Industry-2", "livestock and processing systems"))

    default_contexts = {
        "executive_summary_narrative": {
            "key_climate_risks": [
                {"name": "Extreme heat", "description": f"Affects {industry_1} productivity at {client_name}", "severity": "high"},
                {"name": "Flooding", "description": f"Disrupts transport and access for {client_name}", "severity": "high"}
            ],
            "sector": f"Dairy and beef farming in {client_location}",
            "location": client_location,
            "regulatory_context": ["Environment Agency requirements", "ISO 14090 standards"]
        },
        "introduction_narrative": {
            "organisation_profile": {"name": client_name, "description": f"{industry_1} in {client_location}"},
            "objectives": ["Build climate resilience", "Ensure regulatory compliance", "Protect operations"],
            "regulatory_requirements": ["EA adaptation guidance", "ISO 14090"]
        },
        "site_context_narrative": {
            "site_description": {
                "location": client_location,
                "enterprise_types": [industry_1, industry_2],
                "key_dependencies": ["Infrastructure", "Supply chain", "Local ecosystem"]
            },
            "existing_impacts": [
                {
                    "impact": "Climate-related disruptions",
                    "climate_driver": "Changing weather patterns",
                    "consequence": f"Operational challenges for {client_name}"
                }
            ]
        }
    }

    return default_contexts.get(narrative_key, {})


def map_basic_json_to_schema_with_context(basic_json, prompt_context):
    """Map basic JSON data to structured schema with prompt context"""
    print("üó∫Ô∏è Mapping basic JSON to structured schema with context...")

    client_name = prompt_context.get("client_context", {}).get("name",
                                                               basic_json.get("client_name", "East Higher Farm"))
    client_location = prompt_context.get("client_context", {}).get("location", basic_json.get("client_location",
                                                                                              "Somerset, England"))
    industry_1 = prompt_context.get("client_context", {}).get("primary_industry", basic_json.get("Industry-1", "farm"))
    industry_2 = prompt_context.get("client_context", {}).get("secondary_industry", basic_json.get("Industry-2",
                                                                                                   "livestock and processing systems"))

    structured_data = {
        "executive_summary": {
            "key_climate_risks": [
                {
                    "name": "Extreme heat",
                    "description": f"Increasing number of days over 25¬∞C and 30¬∞C affecting {industry_1}",
                    "severity": "high",
                    "timeframe": "2025-2040"
                },
                {
                    "name": "Surface water flooding",
                    "description": "Increased rainfall intensity leading to local flooding",
                    "severity": "high",
                    "timeframe": "2025-2040"
                },
                {
                    "name": "Drought and water scarcity",
                    "description": "More frequent dry periods impacting water availability",
                    "severity": "medium",
                    "timeframe": "2030-2050"
                }
            ],
            "sector": f"{industry_1} and {industry_2}",
            "location": client_location,
            "regulatory_context": [
                {
                    "name": "Environment Agency",
                    "requirement_summary": "Climate adaptation requirements for environmental permits"
                },
                {
                    "name": "ISO 14090",
                    "requirement_summary": "Adaptation to climate change principles and requirements"
                }
            ],
            "key_risks": [
                f"Heat stress on {industry_1} operations",
                "Flood-related transport disruptions",
                "Water scarcity issues"
            ],
            "top_actions": [
                {
                    "id": "PHY-001",
                    "title": "Soil improvement and water retention",
                    "description": "Implement cover cropping and reduced-till practices",
                    "category": "physical"
                },
                {
                    "id": "CAP-001",
                    "title": "Climate adaptation governance framework",
                    "description": "Establish formal adaptation governance and review cycles",
                    "category": "capacity"
                }
            ]
        },

        "introduction": {
            "organisation_profile": {
                "name": client_name,
                "description": f"{industry_1} operation in {client_location}",
                "core_operations": [industry_1, industry_2, "Climate adaptation"]
            },
            "objectives": [
                {
                    "id": "OBJ-001",
                    "title": "Regulatory alignment & integration",
                    "description": "Ensure compliance with EA and ISO 14090 requirements"
                },
                {
                    "id": "OBJ-002",
                    "title": "Actionable climate adaptation pathways",
                    "description": "Translate risk insights into prioritized adaptation actions"
                }
            ],
            "regulatory_requirements": [
                {
                    "authority": "Environment Agency",
                    "reference": "Environmental Permitting Regulations",
                    "requirement_summary": "Climate change adaptation measures for permitted activities"
                },
                {
                    "authority": "ISO",
                    "reference": "ISO 14090:2019",
                    "requirement_summary": "Principles, requirements and guidelines for adaptation to climate change"
                }
            ]
        },

        "site_context": {
            "site_description": {
                "location": client_location,
                "elevation_m": 190,
                "enterprise_types": [industry_1, industry_2],
                "key_dependencies": ["Road access", "Water supply", "Local infrastructure"]
            },
            "existing_impacts": [
                {
                    "impact": "Surface water flooding",
                    "climate_driver": "Heavier rainfall events",
                    "consequence": "Transport diversions and access issues"
                },
                {
                    "impact": f"Heat stress on {industry_1}",
                    "climate_driver": "Increasing days over 25¬∞C",
                    "consequence": "Reduced productivity and welfare concerns"
                }
            ],
            "warming_pathways": [
                {
                    "warming_band": "1.0-1.5¬∞C",
                    "approximate_period": "2025-2030",
                    "narrative_summary": "Current and near-term impacts with early warning signs"
                },
                {
                    "warming_band": "1.5-2.0¬∞C",
                    "approximate_period": "2030-2040",
                    "narrative_summary": "Impacts become chronic and more severe"
                }
            ]
        },

        "adaptation_approach": {
            "management_systems": [
                {
                    "system_name": "Environmental Management System (EMS)",
                    "integration_points": ["Environmental permits", "Compliance audits", "Monitoring programs"]
                },
                {
                    "system_name": "Operational Management System (OMS)",
                    "integration_points": ["Asset management", "Maintenance schedules", "Emergency preparedness"]
                }
            ],
            "integration_needs": [
                "Embed adaptation into existing operational procedures",
                "Align adaptation actions with capital investment cycles",
                "Integrate climate monitoring with existing data systems"
            ]
        },

        "vision_principles": {
            "long_term_goals": [
                f"Maintain viable {industry_1} enterprise through ~3¬∞C global warming",
                "Build climate-resilient operations",
                "Ensure business continuity under changing climate conditions"
            ],
            "planning_horizon": "to ~3¬∞C global warming (approximately 2050-2060)"
        },

        "climate_hazards": {
            "scenario_assumptions": {
                "reference_scenarios": ["2¬∞C by 2050", "4¬∞C by 2100"],
                "sources": ["Met Office Local Authority Climate Service 2025", "Environment Agency maps"]
            },
            "hazard_list": [
                {
                    "id": "HZ-001",
                    "name": "Extreme heat",
                    "description": "Increasing frequency and duration of hot days (>25¬∞C, >30¬∞C, >35¬∞C)",
                    "relevance_rank": 1
                },
                {
                    "id": "HZ-002",
                    "name": "Heavy rainfall and flooding",
                    "description": "More intense rainfall events leading to surface water flooding",
                    "relevance_rank": 2
                }
            ]
        },

        "planning_process": {
            "methodology_parameters": {
                "stages": ["Exposure assessment", "Vulnerability assessment", "Adaptive capacity analysis"],
                "stakeholder_roles": ["Management", "Operations staff", "External advisors"],
                "tools_referenced": ["Workshops", "Capacity assessment", "Climate projections"]
            }
        },

        "impact_assessment": {
            "summary": "Climate impacts intensify with each 0.5¬∞C warming increment, requiring phased adaptation responses",
            "warming_phase_impacts": [
                {
                    "warming_band": "1.0-1.5¬∞C",
                    "label": "The earliest noticeable impacts have arrived",
                    "approximate_period": "2025-2030",
                    "key_impacts": [
                        "Onset of increased rainfall intensity and surface flooding",
                        "Emerging water scarcity (more frequent dry summers)",
                        "More frequent mild heat stress periods"
                    ]
                }
            ]
        },

        "adaptive_capacity": {
            "capacity_current": {
                "level": "Response Level 2: Stakeholder Responsive",
                "strengths": [
                    "Awareness of climate change across organisation",
                    "Compliance with stakeholder requirements",
                    "Some emerging adaptation capabilities"
                ]
            },
            "capacity_gaps": [
                "Limited climate-informed decision making",
                "Need for specialized adaptation expertise",
                "Formal integration with management systems"
            ],
            "capacity_target": {
                "level": "Response Level 4: Breakthrough Projects",
                "description": "Ability to innovate and develop new ways of working for climate adaptation"
            }
        },

        "adaptation_actions": {
            "physical_actions": [
                {
                    "id": "PHY-001",
                    "title": "Soil improvement",
                    "description": "Multi-year cover cropping and organic matter additions",
                    "warming_phase": "1.2-1.5¬∞C"
                }
            ],
            "capacity_actions": [
                {
                    "id": "CAP-001",
                    "title": "Senior leadership climate engagement",
                    "description": "Regular discussion of climate impacts and adaptation needs",
                    "timing": "short_term"
                }
            ]
        },

        "monitoring_evaluation": {
            "monitoring_framework": {
                "review_cycles": ["Six-monthly initially, then annual"],
                "triggers": ["Major weather events", "New climate data", "Regulatory changes"],
                "indicators": [
                    "% of adaptation actions on track",
                    "Governance capability score",
                    "Climate-attributable incidents"
                ]
            }
        },

        "conclusion": {
            "priorities": [
                "Embed adaptation into investment plans",
                "Assign internal accountability",
                "Establish monitoring processes"
            ],
            "timelines": [
                "Immediate: Endorse executive summary",
                "Short-term: Develop detailed implementation plan",
                "Medium-term: Execute first adaptation actions"
            ],
            "integration_steps": [
                "Align with regulatory permitting cycles",
                "Integrate with existing management systems",
                "Coordinate with relevant partners"
            ]
        }
    }

    return structured_data

def get_fallback_narrative(narrative_key, json_data):
    """Get fallback narrative content when AI generation is not available"""
    client_name = json_data.get("client_name", "East Higher Farm")
    client_location = json_data.get("client_location", "Somerset, England")
    industry_1 = json_data.get("Industry-1", "farm")

    fallback_narratives = {
        "exec-summ_ai_summary": f"""**AI Analysis of Executive Summary:**

‚Ä¢ **Key Finding**: The executive summary effectively positions {client_name}'s adaptation plan within a 3¬∞C warming threshold framework, balancing immediate actions with long-term transformational needs.

‚Ä¢ **Strategic Alignment**: Governance structures and monitoring frameworks are well-defined, though quarterly review cycles could be enhanced with real-time climate data integration.

‚Ä¢ **Recommendation**: Establish a climate adaptation dashboard to track trigger points and adaptation progress against warming scenarios.

‚Ä¢ **Opportunity**: Explore collaborative adaptation initiatives with neighboring farms to share resources and knowledge.""",

        "intro_ai_summary": f"""**AI Analysis of Introduction:**

‚Ä¢ **Objective Assessment**: The three core objectives (regulatory compliance, actionable pathways, capacity building) create a comprehensive framework, though success metrics could be more quantifiable.

‚Ä¢ **Integration Potential**: Existing farm management systems provide excellent platforms for climate adaptation integration, minimizing implementation disruption.

‚Ä¢ **Recommendation**: Develop climate literacy training modules tailored to different staff roles (operational, managerial, strategic).

‚Ä¢ **Data Enhancement**: Incorporate local traditional ecological knowledge alongside scientific projections for culturally-relevant adaptation.""",

        "client-desc_ai_summary": f"""**AI Analysis of Client Description:**

‚Ä¢ **Site Vulnerability**: {client_name}'s elevation (190m) offers flood protection but increases temperature exposure and potential water scarcity risks.

‚Ä¢ **Current Impacts**: Documented issues (surface flooding, livestock heat stress) align with regional climate trends and require prioritized intervention.

‚Ä¢ **Recommendation**: Implement microclimate monitoring stations across different farm zones to identify localized risk variations.

‚Ä¢ **Transport Resilience**: Develop climate-resilient alternative route mapping with real-time weather integration.""",

        "hazards_ai_summary": f"""**AI Analysis of Climate Hazards:**

‚Ä¢ **Compound Risk**: Heatwaves followed by intense rainfall create compounded soil and infrastructure stress requiring integrated response planning.

‚Ä¢ **Temporal Pattern**: Hazard frequency shows accelerating trends, with extreme event return periods decreasing approximately 30% from historical baselines.

‚Ä¢ **Recommendation**: Develop hazard-specific adaptation "playbooks" with clear trigger points and response protocols.

‚Ä¢ **Monitoring Gap**: Real-time hazard monitoring systems could enhance early warning capabilities.""",

        "impact_ai_summary": f"""**AI Analysis of Impact Assessment:**

‚Ä¢ **Cascading Effects**: Primary livestock impacts trigger secondary supply chain and financial stability risks requiring systemic planning.

‚Ä¢ **Threshold Behavior**: Non-linear impacts emerge beyond 2¬∞C warming, necessitating preparatory investments in transformational adaptation.

‚Ä¢ **Recommendation**: Conduct vulnerability assessments across interconnected systems (soil-water-crop-livestock) to identify feedback loops.

‚Ä¢ **Data Integration**: Combine quantitative climate projections with qualitative local experience for robust impact modeling.""",

        "adaptive-capacity_ai_summary": f"""**AI Analysis of Adaptive Capacity:**

‚Ä¢ **Strengths Assessment**: Existing operational management provides solid foundation, though climate-specific decision support requires enhancement.

‚Ä¢ **Development Pathway**: Phased capacity building (literacy ‚Üí specialized skills ‚Üí advanced analytics) aligns well with risk progression.

‚Ä¢ **Recommendation**: Implement climate scenario training exercises for leadership teams to build decision-making confidence.

‚Ä¢ **Knowledge Management**: Establish formal climate adaptation learning systems to capture and share lessons.""",

        "planning_ai_summary": f"""**AI Analysis of Adaptation Planning:**

‚Ä¢ **Action Prioritization**: Risk-based action sequencing demonstrates strategic coherence, though benefit-cost analysis could be strengthened.

‚Ä¢ **Implementation Timing**: Lead times for complex adaptations appear adequate, but contingency planning for accelerated climate change is needed.

‚Ä¢ **Recommendation**: Develop climate adaptation KPIs linked to existing farm performance metrics for seamless integration.

‚Ä¢ **Innovation Opportunity**: Create adaptation innovation fund for testing emerging resilience technologies.""",

        "conclusion_ai_summary": f"""**AI Analysis of Conclusions:**

‚Ä¢ **Plan Coherence**: The adaptation plan successfully balances scientific rigor with practical implementability across all farm operations.

‚Ä¢ **Forward Pathway**: Next steps are clearly articulated though resource allocation details require further specification.

‚Ä¢ **Recommendation**: Establish climate adaptation reporting framework for transparent stakeholder communication.

‚Ä¢ **Continuous Improvement**: Implement annual climate science updates to maintain plan relevance and effectiveness.""",

        "key_messages_callout": """‚Ä¢ Value: Proactive adaptation builds resilience, protects critical assets, and secures long-term sustainability against escalating climate impacts.

‚Ä¢ Urgency: Immediate action is paramount; delaying adaptation will drastically increase costs, risks, and the severity of future disruptions.

‚Ä¢ Strategic Actions: Implement integrated adaptation strategies aligned with farm operations and stakeholder requirements.

‚Ä¢ Implementation Actions: Develop detailed implementation plans with clear responsibilities, timelines, and resources.

‚Ä¢ Monitoring Actions: Establish robust monitoring, evaluation, and learning frameworks for continuous improvement.

‚Ä¢ Collaboration: Engage with neighboring farms and local authorities to share knowledge and resources.

‚Ä¢ Capacity Building: Invest in staff training and organizational development to build lasting adaptive capacity.""",

        "executive_summary_narrative": f"""This Climate Change Adaptation Plan for {client_name} addresses the growing risks from climate change that threaten the long-term viability of the {industry_1}. Based on the latest climate projections for {client_location}, the plan identifies key vulnerabilities including increasing heat stress, more frequent flooding events, and water scarcity issues.

The plan establishes a structured approach to building resilience through both physical adaptations and organisational capacity development. It aligns with regulatory requirements from the Environment Agency and international standards such as ISO 14090, ensuring compliance while enhancing operational sustainability.

By implementing the prioritized actions outlined in this plan, {client_name} can maintain productivity and animal welfare through approximately 3¬∞C of global warming. The plan emphasizes no-regrets actions that provide benefits under current conditions while preparing for future climate challenges, supported by a robust monitoring and evaluation framework for continuous improvement.""",

        "introduction_narrative": f"""{client_name} operates a dairy and beef farming enterprise in {client_location}, facing increasing climate-related challenges that threaten productivity, animal welfare, and business continuity. This Adaptation Plan provides a structured framework for addressing these challenges through scientifically-informed, practical adaptation measures.

The plan has been developed in response to regulatory requirements from the Environment Agency and aligns with international best practice standards including ISO 14090. It represents a proactive approach to climate risk management, moving beyond reactive responses toward strategic, forward-looking resilience building.

By embedding climate adaptation into core business processes and decision-making, {client_name} aims to protect its assets, maintain operational efficiency, and ensure the welfare of its livestock through the climate changes projected for the coming decades.""",

        "site_context_narrative": f"""{client_name} is situated in the Mendip Hills area of {client_location} at an elevation of 190 meters. The farm's location and topography create specific vulnerabilities to climate impacts, particularly surface water flooding during heavy rainfall events and heat stress during increasingly frequent hot periods.

Current climate impacts are already observable, including transport disruptions due to flooded access roads and reduced livestock productivity during heatwaves. These challenges are expected to intensify with further global warming, requiring systematic adaptation planning to maintain farm viability.

The farm's dependence on reliable road access, consistent water supplies, and optimal temperature conditions for livestock creates multiple exposure points to climate hazards. Understanding these site-specific vulnerabilities forms the foundation for targeted, effective adaptation measures.""",

        "hazard_narrative": f"""Climate projections for {client_location} indicate significant changes in key hazard patterns over the coming decades. Under a 2¬∞C warming scenario (approximately 2050), the number of hot days exceeding 25¬∞C is expected to increase substantially, with corresponding impacts on livestock welfare and farm operations.

Heavy rainfall events are projected to become more frequent and intense, increasing flood risks even if annual rainfall totals remain relatively stable. These events can lead to rapid surface water flooding, soil erosion, and infrastructure damage, with particularly severe implications for farm access and field operations.

Drought conditions are also expected to become more common, especially during summer months, potentially impacting pasture growth, water availability for livestock, and overall farm productivity. The interaction between these hazards‚Äîsuch as heatwaves followed by intense rainfall‚Äîcreates compound risks that require integrated adaptation approaches.""",

        "methodology_narrative": f"""The methodology employed for this risk and vulnerability assessment follows a systematic, multi-stage approach designed to capture both current risks and future climate scenarios. The assessment begins with a comprehensive exposure analysis, identifying all assets, operations, and stakeholders vulnerable to climate impacts at {client_name}.

This is followed by a sensitivity analysis evaluating how different farm systems respond to climate stressors, considering factors such as livestock tolerance to heat, infrastructure resilience to flooding, and operational dependencies on stable climate conditions. The final stage assesses adaptive capacity, examining the farm's current capabilities and identifying gaps that need to be addressed through targeted interventions.

The methodology integrates quantitative climate data from authoritative sources like the Met Office and Environment Agency with qualitative insights from stakeholder workshops and operational experience. This blended approach ensures the assessment is both scientifically rigorous and practically relevant to {client_name}'s specific context.""",

        "impact_narrative": f"""Climate change impacts on {client_name} will intensify progressively with each increment of global warming. At 1.0-1.5¬∞C warming (current to near-term), initial impacts include increased heat stress on livestock, more frequent mild flooding events, and emerging water scarcity during dry periods.

As warming reaches 1.5-2.0¬∞C, these impacts become chronic and more severe, with regular summer droughts affecting pasture availability and more intense heatwaves threatening animal welfare. Flood risks extend beyond surface water to include potential river flooding and infrastructure damage.

Beyond 2¬∞C warming, impacts become systemic, with compounding effects that challenge traditional farming practices. These include persistent water shortages, catastrophic flood events affecting large areas, and heat conditions that may require transformative changes to livestock management and potentially even land use.""",

        "adaptive_capacity_narrative": f"""{client_name} currently operates at Response Level 2 ("Stakeholder Responsive") in terms of adaptive capacity. This means the farm recognizes the need to understand and comply with climate-related requirements from key stakeholders like the Environment Agency, and has basic awareness of climate change across the organization.

Current strengths include established compliance processes, stakeholder engagement mechanisms, and growing internal awareness of climate issues. The farm has begun appointing individuals with specific responsibilities for climate adaptation and is developing plans to incorporate climate considerations into core procedures.

However, significant gaps remain in systematic climate-informed decision making, specialized adaptation expertise, and formal integration of climate adaptation into strategic planning. Building these capabilities will be essential for moving toward the target Response Level 4 ("Breakthrough Projects"), where the farm can innovate and develop new ways of working to address climate challenges effectively.""",

        "capacity_comparison_narrative": f"""Comparing current adaptive capacity (Response Level 2) with the required target level (Response Level 4) reveals both immediate gaps and longer-term development needs. Currently, {client_name} effectively responds to external stakeholder requirements but has limited capacity for proactive, innovative climate adaptation.

To bridge this gap, the farm needs to develop capabilities in several key areas: climate-informed strategic decision making, specialized technical expertise in adaptation measures, formal governance structures for adaptation oversight, and systematic integration of climate considerations into all operational planning.

The transition from stakeholder-responsive to breakthrough-oriented adaptation involves shifting from compliance-focused actions to innovation-driven approaches. This requires developing new skills, processes, and mindsets across the organization, supported by dedicated resources and leadership commitment. The capacity development plan outlines a phased approach to building these capabilities over the coming years.""",

        "physical_risk_narrative": f"""Physical risk management at {client_name} focuses on protecting critical assets and operations from climate hazards through a combination of structural and non-structural measures. Priority actions address the most immediate and severe risks, beginning with soil improvement to enhance water retention and reduce erosion during heavy rainfall.

Shelterbelt and paddock tree development provides natural cooling for livestock during heatwaves while also offering wind protection and habitat benefits. Pollution control measures, including riparian buffer zones and regular monitoring, protect water quality from nutrient runoff during flood events.

The physical adaptation strategy follows a phased approach aligned with projected warming levels. Early actions focus on "no-regrets" measures that provide benefits under current climate conditions while building resilience for future scenarios. As climate impacts intensify, more substantial interventions will be required, including potential infrastructure upgrades and landscape-scale modifications to maintain farm viability.""",

        "capacity_development_narrative": f"""Capacity development at {client_name} follows a structured, phased approach designed to build the skills, knowledge, and systems needed for effective climate adaptation. The initial phase focuses on leadership engagement and basic awareness building, ensuring senior management understands climate risks and supports adaptation efforts.

Subsequent phases develop specialized technical expertise, formal governance structures, and systematic integration of climate considerations into farm operations. This includes training programs for staff at all levels, development of climate-informed decision support tools, and establishment of dedicated adaptation roles and responsibilities.

The capacity development plan emphasizes continuous learning and improvement, with regular review cycles to assess progress and adjust approaches based on experience and new information. By building adaptive capacity systematically over time, {client_name} can ensure it has the capabilities needed to implement physical adaptation measures effectively and respond flexibly to evolving climate challenges.""",

        "monitoring_narrative": f"""The monitoring and evaluation framework for {client_name}'s adaptation plan establishes clear processes for tracking progress, assessing effectiveness, and enabling continuous improvement. The framework includes regular review cycles at six-month intervals initially, transitioning to annual reviews as the adaptation program matures.

Key monitoring elements include tracking implementation progress for all adaptation actions, assessing changes in climate risk exposure and vulnerability, and evaluating the effectiveness of implemented measures. The framework also includes specific indicators for adaptive capacity development, ensuring the farm builds the skills and systems needed for long-term resilience.

Data collection incorporates both quantitative metrics (such as temperature records, flood frequency, and implementation rates) and qualitative assessments (including stakeholder feedback and expert reviews). This comprehensive approach provides a robust evidence base for decision making, enabling {client_name} to adjust its adaptation strategy based on actual performance and changing conditions.""",

        "conclusion_narrative": f"""This Adaptation Plan provides {client_name} with a clear pathway to maintain a viable farming enterprise through approximately 3¬∞C of global warming. By implementing the prioritized actions and developing the necessary adaptive capacities, the farm can navigate the climate challenges of the coming decades while protecting productivity, animal welfare, and environmental compliance.

Immediate next steps include formal endorsement of the plan, development of detailed implementation schedules with assigned responsibilities and resources, and establishment of the monitoring and evaluation framework. These actions should commence within the next three months to maintain momentum and ensure timely adaptation.

The plan represents a living document that will evolve with new climate information, operational experience, and technological developments. Regular review cycles, aligned with the farm's existing management systems and the Environment Agency's permitting requirements, will ensure the plan remains relevant, effective, and proportionate to the evolving climate risks faced by {client_name}.""",

        "integration_management_narrative": f"""Integration of climate adaptation into {client_name}'s existing management systems is essential for ensuring long-term implementation and effectiveness. The adaptation plan will be embedded within the farm's Environmental Management System (EMS) and Operational Management System (OMS), creating synergies with existing processes and reducing implementation barriers.

Key integration points include environmental permit compliance processes, routine asset management and maintenance schedules, emergency preparedness and business continuity planning, health and safety training programs, and procurement policies for climate-resilient infrastructure and equipment.

The adaptation plan will function as a living annex to the OMS, updated at each formal review cycle or following significant weather events or regulatory changes. This integrated approach ensures climate adaptation becomes a routine part of farm operations rather than a separate, additional burden, maximizing the likelihood of successful and sustained implementation.""",

        "vision_narrative": f"""The vision for {client_name} is to maintain a thriving, climate-resilient farming enterprise that can adapt successfully to the changing climate conditions projected for {client_location} through the coming decades. This vision encompasses maintaining livestock productivity and welfare, protecting farm assets and infrastructure, ensuring business continuity, and contributing to sustainable agricultural practices in the region.

Guided by principles of precautionary action, integration, flexibility, proportionality, and continual learning, the farm aims to build resilience systematically over time. The planning horizon extends to approximately 3¬∞C of global warming, with recognition that beyond this point, more transformative adaptation options may need to be considered.

This vision represents a commitment to proactive climate risk management that protects both the farm's economic viability and its environmental responsibilities, ensuring {client_name} can continue to operate successfully through the climate changes of the 21st century and beyond."""
    }

    return fallback_narratives.get(narrative_key, f"[Content for {narrative_key} would be generated here]")


def get_fallback_narrative_with_context(narrative_key, json_data, prompt_context):
    """Get fallback narrative with prompt context awareness for JSON v4"""
    client_name = prompt_context.get("client_context", {}).get("name",
                                                               json_data.get("client_name",
                                                                             "Ministry of Rural Development"))
    client_location = prompt_context.get("client_context", {}).get("location",
                                                                   json_data.get("client_location", "Republic of Fiji"))
    sector = prompt_context.get("client_context", {}).get("primary_industry",
                                                          json_data.get("sector", "infrastructure"))

    # Parse JSON v4 data for better context
    #v4_data = parse_json_v4

def generate_content_with_gemini_with_context(prompt, narrative_key, prompt_context):
    """Generate content using Gemini with enhanced context"""
    if not GEMINI_API_KEY or not AVAILABLE_GEMINI_MODEL:
        return None

    try:
        # Add specific formatting instructions based on narrative type
        formatting_rules = """FORMATTING RULES:
1. Use '‚Ä¢' for bullet points, NOT '*' or '-'
2. Do NOT use markdown formatting like **bold** or *italic*
3. Use plain text only
4. Write complete sentences
5. Ensure all bullet points have proper content
6. Structure content logically
7. Use appropriate paragraph breaks
8. Be specific and avoid generic statements"""

        # Add narrative-specific formatting
        if "bullet" in narrative_key or "key_messages" in narrative_key:
            formatting_rules += "\n9. Each bullet point should be a complete sentence\n10. Limit to 5-7 bullet points maximum"

        if "executive_summary" in narrative_key:
            formatting_rules += "\n9. Structure as 3-4 paragraphs\n10. Include: context, risks, strategy, next steps"

        complete_prompt = f"""{prompt}

{formatting_rules}

IMPORTANT: Generate content that is accurate, relevant, and tailored to the specific client context provided above."""

        model_name = AVAILABLE_GEMINI_MODEL['name']
        api_version = AVAILABLE_GEMINI_MODEL['version']
        api_url = f"https://generativelanguage.googleapis.com/{api_version}/{model_name}:generateContent?key={GEMINI_API_KEY}"

        payload = {
            "contents": [{"parts": [{"text": complete_prompt}]}],
            "generationConfig": {
                "temperature": 0.3,  # Lower for more accurate, consistent content
                "maxOutputTokens": 2000,
                "topP": 0.8,
                "topK": 40,
                "stopSequences": ["###", "END", "Conclusion:"]
            }
        }

        response = requests.post(api_url, json=payload, timeout=120)

        if response.status_code == 200:
            result = response.json()
            if 'candidates' in result and result['candidates']:
                content = result['candidates'][0]['content']['parts'][0]['text']

                # Post-process content for consistency
                content = content.strip()

                # Remove any markdown formatting
                content = re.sub(r'\*\*(.*?)\*\*', r'\1', content)
                content = re.sub(r'\*(?!\s)(.*?)(?<!\s)\*', r'\1', content)

                # Replace markdown bullets with proper bullets
                content = re.sub(r'^\s*[\*\-]\s+', '‚Ä¢ ', content, flags=re.MULTILINE)

                # Fix incomplete bullet points
                content = fix_incomplete_bullets_with_context(content, narrative_key, prompt_context)

                # Ensure proper paragraph spacing
                content = re.sub(r'\n{3,}', '\n\n', content)

                return content

        return None

    except Exception as e:
        print(f"‚ö†Ô∏è Gemini API error for {narrative_key}: {e}")
        return None


def fix_incomplete_bullets_with_context(content, narrative_key, prompt_context):
    """Fix incomplete bullet points with context awareness"""
    client_name = prompt_context.get("client_context", {}).get("name", "the client")
    client_location = prompt_context.get("client_context", {}).get("location", "the location")
    industry = prompt_context.get("client_context", {}).get("primary_industry", "operations")

    lines = content.split('\n')
    cleaned_lines = []

    for line in lines:
        line = line.strip()
        if line.startswith('‚Ä¢'):
            # Check if bullet point is complete
            if len(line) < 40 and line.endswith(':'):
                # Incomplete bullet - expand based on context
                line = expand_bullet_with_context(line, narrative_key, client_name, client_location, industry)
            cleaned_lines.append(line)
        elif line:
            cleaned_lines.append(line)

    return '\n'.join(cleaned_lines)


def expand_bullet_with_context(bullet_line, narrative_key, client_name, client_location, industry):
    """Expand an incomplete bullet point using context"""
    if 'Value:' in bullet_line:
        return f"‚Ä¢ Value: Proactive adaptation builds resilience for {client_name}'s {industry} operations in {client_location}, protecting critical assets against escalating climate impacts."
    elif 'Urgency:' in bullet_line:
        return f"‚Ä¢ Urgency: Immediate action is required to prevent significantly higher costs and greater future disruption to {client_name}'s operations."
    elif 'Actions:' in bullet_line:
        return f"‚Ä¢ Actions: Implement prioritized adaptation measures tailored to {client_name}'s specific vulnerabilities in {client_location}."
    elif 'Recommendation:' in bullet_line:
        return f"‚Ä¢ Recommendation: Adopt a phased implementation approach starting with no-regrets actions for {client_name}'s {industry} operations."
    elif 'Opportunity:' in bullet_line:
        return f"‚Ä¢ Opportunity: Leverage {client_name}'s position in {client_location} to develop innovative adaptation solutions for the {industry} sector."
    elif 'Strengths:' in bullet_line:
        return f"‚Ä¢ Strengths: {client_name} has established operational systems that provide a solid foundation for implementing climate adaptation measures."
    elif 'Gaps:' in bullet_line:
        return f"‚Ä¢ Gaps: Additional capacity is needed in climate-informed decision making for {industry} operations at {client_name}."
    elif 'Strategic:' in bullet_line:
        return f"‚Ä¢ Strategic: Alignment of adaptation measures with {client_name}'s business objectives and long-term sustainability goals."
    elif 'Implementation:' in bullet_line:
        return f"‚Ä¢ Implementation: Focus on practical, cost-effective adaptation measures that can be integrated into {client_name}'s existing operations."
    else:
        return bullet_line


def integrate_bespoke_content_with_prompts(doc, json_data, form_prompts=None):
    """Main integration function with prompt support"""
    print("üîç Available JSON keys:", list(json_data.keys()))

    # Build prompt context FROM FORM DATA
    if form_prompts and any(prompt.strip() for key, prompt in form_prompts.items() if key not in ['include_agricultural_focus', 'include_regulatory_focus', 'include_practical_examples', 'include_local_context']):
        print("üìù Using form prompts for AI generation")
        prompt_context = build_prompt_context_from_form(form_prompts, json_data)
    else:
        print("üìù Using default prompts")
        prompt_context = build_default_prompt_context(json_data)

    print(f"ü§ñ Prompt context built: {len(prompt_context.get('focus_areas', []))} focus areas")

    # Generate AI narratives WITH PROMPT CONTEXT
    ai_narratives = generate_ai_narratives_with_prompts(json_data, prompt_context)
    json_data.update(ai_narratives)

    # ... [rest of your existing function] ...

    # Ensure all narrative placeholders have content
    ensure_narrative_content(json_data, prompt_context)

    # Build comprehensive content mapping
    content_mapping = build_content_mapping(json_data, prompt_context)

    # CRITICAL: Add specific fixes for common placeholders
    content_mapping.update({
        # Fix the specific placeholders you're seeing
        "[[client_name]]": json_data.get("client_name", "Client Name"),
        "[[intro _bespoke_text]]": json_data.get("intro-bespoke_text", ""),
        "[[intro-bespoke_text]]": json_data.get("intro-bespoke_text", ""),

        # Add any other placeholders you've seen
        "[[project_title]]": json_data.get("project_title", "Climate Adaptation Plan"),
        "[[client_location]]": json_data.get("client_location", ""),
        "[[report_date]]": json_data.get("report_date", datetime.now().strftime("%B %d, %Y")),
    })

    print("üîß Replacing placeholders with actual content...")

    # Replace all placeholders
    replace_placeholders(doc, content_mapping)

    # Remove leftover AI analysis sections
    remove_ai_analysis_sections(doc)

    # Handle industry placeholders
    handle_industry_placeholders(doc, json_data)

    # Clean up any remaining placeholders
    remove_specific_placeholders(doc)

    # Clean up bullet formatting
    clean_up_bullet_formatting(doc)

    # FINAL CHECK: Verify all placeholders are gone
    verify_no_placeholders_remain(doc)

    print("‚úÖ Content integration completed")
    return True


def verify_no_placeholders_remain(doc):
    """Verify that no placeholders remain in the document"""
    print("üîç Verifying no placeholders remain...")

    remaining_placeholders = []

    # Check all paragraphs
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text
        if "[[" in text and "]]" in text:
            # Extract placeholder
            start = text.find("[[")
            end = text.find("]]", start)
            if start != -1 and end != -1:
                placeholder = text[start:end + 2]
                remaining_placeholders.append((i, placeholder, text[:100]))

    # Check tables
    for table_idx, table in enumerate(doc.tables):
        for row_idx, row in enumerate(table.rows):
            for cell_idx, cell in enumerate(row.cells):
                for para_idx, paragraph in enumerate(cell.paragraphs):
                    text = paragraph.text
                    if "[[" in text and "]]" in text:
                        start = text.find("[[")
                        end = text.find("]]", start)
                        if start != -1 and end != -1:
                            placeholder = text[start:end + 2]
                            remaining_placeholders.append(
                                (f"Table{table_idx}-R{row_idx}-C{cell_idx}-P{para_idx}", placeholder, text[:100])
                            )

    if remaining_placeholders:
        print(f"‚ùå Found {len(remaining_placeholders)} remaining placeholders:")
        for location, placeholder, context in remaining_placeholders[:10]:  # Show first 10
            print(f"   üìç {location}: '{placeholder}' in '{context}...'")

        if len(remaining_placeholders) > 10:
            print(f"   ... and {len(remaining_placeholders) - 10} more")
    else:
        print("‚úÖ No remaining placeholders found!")

    return len(remaining_placeholders) == 0


def build_prompt_context_from_form(form_prompts, json_data):
    """Build prompt context from form data"""
    client_name = json_data.get("client_name", "East Higher Farm")
    client_location = json_data.get("client_location", "Somerset, England")
    industry_1 = json_data.get("Industry-1", "farm")
    industry_2 = json_data.get("Industry-2", "livestock and processing systems")

    # Build the general guidance from custom prompt
    custom_prompt = form_prompts.get("custom_prompt", "").strip()
    if not custom_prompt:
        custom_prompt = "Generate professional, farm-specific content for a climate adaptation plan. Focus on practical implementation and regulatory compliance."

    # Build specific prompts
    specific_prompts = {
        "executive_summary": form_prompts.get("exec_summary_prompt", "").strip() or
                           f"Focus on key climate risks for this {industry_1} in {client_location}, highlight regulatory requirements, and emphasize business continuity.",
        "introduction": form_prompts.get("intro_prompt", "").strip() or
                       f"Describe this {industry_1}'s climate adaptation objectives and regulatory context in {client_location}.",
        "site_context": form_prompts.get("site_context_prompt", "").strip() or
                       f"Describe the site location in {client_location}, current climate impacts, and specific vulnerabilities for this {industry_1}."
    }

    context = {
        "general_guidance": custom_prompt,
        "specific_prompts": specific_prompts,
        "focus_areas": [],
        "client_context": {
            "name": client_name,
            "location": client_location,
            "primary_industry": industry_1,
            "secondary_industry": industry_2,
            "project_title": json_data.get("project_title", "")
        },
        "instructions": "DO NOT add generic boilerplate like 'Context: This content is specific to...'. Write fluid, integrated content directly addressing the farm's situation."
    }

    # Add focus areas based on checkboxes
    if form_prompts.get("include_agricultural_focus"):
        context["focus_areas"].append(f"agricultural operations specific to {industry_1} and {industry_2}")
    if form_prompts.get("include_regulatory_focus"):
        context["focus_areas"].append("regulatory compliance (Environment Agency, ISO 14090)")
    if form_prompts.get("include_practical_examples"):
        context["focus_areas"].append("practical, implementable examples and case studies")
    if form_prompts.get("include_local_context"):
        context["focus_areas"].append(f"local context and specific conditions in {client_location}")

    # If no focus areas were selected, add defaults
    if not context["focus_areas"]:
        context["focus_areas"] = ["practical implementation", "regulatory compliance", "business continuity"]

    return context


def build_default_prompt_context(json_data):
    """Build default prompt context using JSON v4 data"""
    # Parse JSON v4 data first
    v4_data = parse_json_v4_data(json_data)

    client_name = v4_data.get("client_name", "Ministry of Rural Development")
    client_location = v4_data.get("client_location", "Republic of Fiji")
    sector = v4_data.get("sector", "infrastructure")
    key_risks = v4_data.get("key_climate_risks", ["sea-level rise", "tropical cyclones"])

    if isinstance(key_risks, str):
        key_risks = [key_risks]

    return {
        "general_guidance": "Generate professional, accurate content for a climate adaptation plan for infrastructure sector in Fiji.",
        "specific_prompts": {
            "executive_summary": f"Focus on {', '.join(key_risks[:3])} for {sector} in {client_location}, highlight National Adaptation Plan requirements, and emphasize infrastructure resilience and rural development.",
            "introduction": f"Describe {client_name}'s climate adaptation objectives and regulatory context for {sector} operations in {client_location}.",
            "site_context": f"Describe operational context in {client_location}, current climate impacts on infrastructure, and specific vulnerabilities for {sector}."
        },
        "focus_areas": ["infrastructure resilience", "regulatory compliance", "service continuity",
                        "rural development"],
        "client_context": {
            "name": client_name,
            "location": client_location,
            "primary_industry": sector,
            "secondary_industry": v4_data.get("industry_2", "rural development")
        },
        "instructions": "Write content specific to Fiji's infrastructure context, referencing National Adaptation Plan v2.0 and addressing rural community needs."
    }

def ensure_narrative_content(json_data, prompt_context):
    """Ensure all narrative placeholders have content"""
    all_narrative_placeholders = [
        'executive_summary_narrative', 'key_messages_callout', 'introduction_narrative',
        'site_context_narrative', 'hazard_narrative', 'methodology_narrative',
        'impact_narrative', 'adaptive_capacity_narrative', 'capacity_comparison_narrative',
        'physical_risk_narrative', 'capacity_development_narrative', 'monitoring_narrative',
        'conclusion_narrative', 'integration_management_narrative', 'vision_narrative'
    ]

    for placeholder in all_narrative_placeholders:
        if placeholder not in json_data or not json_data.get(placeholder) or json_data.get(placeholder).strip() == "":
            json_data[placeholder] = get_fallback_narrative_with_context(placeholder, json_data, prompt_context)
            print(f"üìù Added prompted content for {placeholder}")


def process_document_placeholders(doc, json_data, prompt_context):
    """Process all document placeholders with prompt context"""
    # Build content mapping
    content_mapping = build_content_mapping(json_data, prompt_context)

    # Replace placeholders in document
    replace_placeholders(doc, content_mapping)

    # Handle industry placeholders
    handle_industry_placeholders(doc, json_data)

    # Clean up formatting
    clean_up_bullet_formatting(doc)


def build_content_mapping(json_data, prompt_context):
    """Build comprehensive content mapping for document replacement"""
    # Start with basic placeholders
    content_mapping = {
        # Basic information placeholders
        "[[project_title]]": json_data.get("project_title", ""),
        "[[client_name]]": json_data.get("client_name", ""),
        "[[client_location]]": json_data.get("client_location", ""),
        "[[report_date]]": json_data.get("report_date", ""),

        # Industry placeholders
        "[[industry-1]]": json_data.get("Industry-1", ""),
        "[[Industry-1]]": json_data.get("Industry-1", ""),
        "[[industry-2]]": json_data.get("Industry-2", ""),
        "[[Industry-2]]": json_data.get("Industry-2", ""),

        # Bespoke text sections
        "[[exec-summ_bespoke_text]]": json_data.get("exec-summ_bespoke_text", ""),
        "[[intro-bespoke_text]]": json_data.get("intro-bespoke_text", ""),
        "[[client-desc_bespoke_text]]": json_data.get("client-desc_bespoke_text", ""),

        # LOF and LOT placeholders
        "[[lof]]": json_data.get("lof", ""),
        "[[lot]]": json_data.get("lot", ""),
    }

    # Add all AI-generated narratives
    narrative_keys = [
        'executive_summary_narrative', 'key_messages_callout', 'introduction_narrative',
        'site_context_narrative', 'hazard_narrative', 'methodology_narrative',
        'impact_narrative', 'adaptive_capacity_narrative', 'capacity_comparison_narrative',
        'physical_risk_narrative', 'capacity_development_narrative', 'monitoring_narrative',
        'conclusion_narrative', 'integration_management_narrative', 'vision_narrative'
    ]

    for key in narrative_keys:
        content_key = f"[[{key}]]"
        content_mapping[content_key] = json_data.get(key, "")

    return content_mapping


# Keep the original integrate_bespoke_content for backward compatibility
def integrate_bespoke_content(doc, json_data):
    """Original function - now calls the new version with default prompts"""
    print("üîç Using original integration with default prompts")
    return integrate_bespoke_content_with_prompts(doc, json_data, None)


# Update the handle_complex_sections function to fix wrong content:
def handle_complex_sections(doc, json_data):
    """Handle more complex sections that need paragraph-level replacement"""
    print("üîß Handling complex sections with direct text replacement and cleanup...")

    # First, clean up wrong content in Introduction section
    wrong_intro_content = "Solara Energy, a leading utility provider serving"

    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()

        # Remove the wrong content from Introduction
        if wrong_intro_content in text:
            # Find the correct intro content
            correct_intro = json_data.get("introduction_narrative", "")
            if correct_intro:
                # Replace the wrong content with correct content
                paragraph.text = correct_intro
                print(f"‚úÖ Fixed wrong content in Introduction at paragraph {i}")
            else:
                # Just remove the wrong content
                paragraph.text = paragraph.text.replace(wrong_intro_content, "")
                print(f"‚úÖ Removed wrong content from Introduction at paragraph {i}")

        # Clean up the incomplete JSON in site_context_narrative
        if "```json" in text or "site_description" in text or "existing_impacts" in text:
            # This is the incomplete JSON - replace it with proper narrative
            correct_site_narrative = json_data.get("site_context_narrative", "")
            if correct_site_narrative:
                paragraph.text = correct_site_narrative
                print(f"‚úÖ Fixed incomplete JSON in site context at paragraph {i}")
            else:
                paragraph.text = ""  # Clear it entirely

    # Also clean up empty or malformed paragraphs
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()

        # Remove empty paragraphs with just brackets or malformed content
        if text in ["[[", "]]", "[[[", "]]]", "{", "}"] or text.startswith("```"):
            paragraph.text = ""
            print(f"üóëÔ∏è Cleaned malformed content at paragraph {i}")


def clean_up_generated_report(doc, json_data):  # Add json_data parameter here
    """Clean up specific issues in the generated report"""
    print("üßπ Cleaning up generated report...")

    # Clean up bullet formatting first
    bullet_fixes = clean_up_bullet_formatting(doc)

    # PROTECT THE STATIC TEXT - This is CRITICAL
    protected_count = protect_static_executive_summary_text(doc)

    # Clean up Executive Summary specifically (remove wrong content)
    exec_cleaned_count = clean_executive_summary_content(doc, json_data)

    # Check Executive Summary structure
    ensure_executive_summary_structure(doc)

    # Remove any remaining AI analysis sections
    ai_fixes = remove_ai_analysis_sections(doc)

    # Clean up Executive Summary duplicates and wrong content
    exec_duplicate_fixes = clean_executive_summary_duplicates(doc, json_data)

    # FIX: Ensure all fixes are integers, not None
    bullet_fixes = bullet_fixes if bullet_fixes is not None else 0
    ai_fixes = ai_fixes if ai_fixes is not None else 0
    exec_duplicate_fixes = exec_duplicate_fixes if exec_duplicate_fixes is not None else 0
    exec_cleaned_count = exec_cleaned_count if exec_cleaned_count is not None else 0

    cleaned_count = bullet_fixes + protected_count + ai_fixes + exec_duplicate_fixes + exec_cleaned_count

    # Clean up specific problematic content patterns
    problematic_patterns = [
        "East Hill maritime development can sustain a viable cattle enterprise",
        "East Hill Farm can sustain a viable cattle enterprise",
        "maritime development can sustain a viable cattle",
        "can sustain a viable cattle enterprise",
        "Solara Energy, a leading utility provider serving",
        "```json",
        "Coastal Haven is a vibrant urban center",
        "The current hazard landscape is characterized",
        "The path forward is clearly delineated, focusing on a strategic and phased implementation",
        "Here is a hazard overview explaining current and future hazard trends"
    ]

    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()

        for pattern in problematic_patterns:
            if pattern in text:
                # Check context to decide what to do
                if pattern in ["East Hill maritime development can sustain a viable cattle enterprise",
                               "East Hill Farm can sustain a viable cattle enterprise",
                               "maritime development can sustain a viable cattle",
                               "can sustain a viable cattle enterprise"]:
                    # This is definitely wrong content - remove entire paragraph
                    paragraph.text = ""
                    cleaned_count += 1
                    print(f"üóëÔ∏è Removed wrong farm content at paragraph {i}")
                    break
                elif pattern in ["Solara Energy, a leading utility provider serving",
                                 "Coastal Haven is a vibrant urban center"]:
                    # This is definitely wrong content - remove entire paragraph
                    paragraph.text = ""
                    cleaned_count += 1
                    print(f"üóëÔ∏è Removed wrong company content at paragraph {i}")
                    break
                elif pattern == "```json":
                    # Remove JSON code blocks
                    if "site_description" in text or "existing_impacts" in text:
                        # This should be replaced with proper narrative
                        # Find client name from context
                        client_name = json_data.get("client_name", "Ministry of Rural Development")
                        proper_narrative = f"""{client_name} operates critical infrastructure assets across Fiji's island regions, including coastal protection systems, rural transport networks, and community facilities. The Ministry's infrastructure portfolio is increasingly exposed to climate hazards such as sea-level rise, intensified tropical cyclones, and more variable rainfall patterns.

Current climate impacts are already observable across Fiji's infrastructure systems, including recurrent flood damage to roads and bridges, cyclone destruction of coastal assets, and drought-related water scarcity affecting rural communities. These challenges are expected to intensify with further global warming, requiring systematic adaptation planning to maintain service continuity and protect development investments.

The Ministry's dependence on reliable infrastructure for rural service delivery, consistent resource availability for remote communities, and optimal operating conditions for critical facilities creates multiple exposure points to climate hazards. Understanding these site-specific vulnerabilities forms the foundation for targeted, effective adaptation measures at {client_name}."""

                        paragraph.text = proper_narrative
                        cleaned_count += 1
                        print(f"üîß Replaced JSON code with proper narrative at paragraph {i}")
                    break
                elif pattern == "Here is a hazard overview explaining current and future hazard trends":
                    # Remove this introductory sentence
                    if len(text) < 100:  # Short paragraph
                        paragraph.text = ""
                        cleaned_count += 1
                        print(f"üóëÔ∏è Removed generic hazard introduction at paragraph {i}")
                    break

    # Also clean up the introduction section specifically
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()

        # Fix the introduction section
        if text.startswith("Solara Energy") or "leading utility provider" in text:
            # This is definitely wrong - check if we're in Introduction section
            is_intro = False
            for j in range(max(0, i - 5), min(len(doc.paragraphs), i + 5)):
                if "Introduction" in doc.paragraphs[j].text and doc.paragraphs[j].text.strip() == "Introduction":
                    is_intro = True
                    break

            if is_intro:
                client_name = json_data.get("client_name", "Ministry of Rural Development")
                client_location = json_data.get("client_location", "Republic of Fiji")
                proper_intro = f"""{client_name} operates Fiji's critical rural infrastructure systems, facing increasing climate-related challenges that threaten service delivery, community resilience, and development progress. This Adaptation Plan provides a structured framework for addressing these challenges through scientifically-informed, practical adaptation measures.

The plan has been developed in response to regulatory requirements and aligns with international best practice standards including ISO 14090. It represents a proactive approach to climate risk management, moving beyond reactive responses toward strategic, forward-looking resilience building.

By embedding climate adaptation into core business processes and decision-making, {client_name} aims to protect its assets, maintain operational efficiency, and ensure the welfare of rural communities in {client_location} through the climate changes projected for the coming decades."""

                paragraph.text = proper_intro
                cleaned_count += 1
                print(f"üîß Fixed wrong content in Introduction at paragraph {i}")

    print(f"üßπ Cleaned {cleaned_count} problematic content sections")
    return cleaned_count


def clean_executive_summary(doc):
    """Clean up Executive Summary issues including lonely 'The'"""
    print("üßπ Cleaning Executive Summary...")

    cleaned_count = 0

    # Look for the specific pattern in Executive Summary
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()

        # Check if this is in or near Executive Summary section
        is_exec_summary = False
        for j in range(max(0, i - 5), min(len(doc.paragraphs), i + 5)):
            if "Executive Summary" in doc.paragraphs[j].text:
                is_exec_summary = True
                break

        if not is_exec_summary:
            continue

        # Clean up specific issues
        original_text = paragraph.text

        # Remove lonely "The" on its own line
        if text == "The":
            paragraph.text = ""
            cleaned_count += 1
            print(f"‚úÖ Removed lonely 'The' at paragraph {i}")
            continue

        # Fix "The\n" pattern
        if paragraph.text.startswith("The\n"):
            paragraph.text = paragraph.text[4:]  # Remove "The\n"
            cleaned_count += 1
            print(f"‚úÖ Fixed 'The\\n' pattern at paragraph {i}")
            continue

        # Fix "\nThe\n" pattern
        if "\nThe\n" in paragraph.text:
            paragraph.text = paragraph.text.replace("\nThe\n", "\n")
            cleaned_count += 1
            print(f"‚úÖ Fixed '\\nThe\\n' pattern at paragraph {i}")
            continue

        # Remove "The" at the beginning of a paragraph
        if text.startswith("The "):
            # Check if it's just "The " followed by nothing useful
            if len(text) < 10:
                paragraph.text = ""
                cleaned_count += 1
                print(f"‚úÖ Removed incomplete 'The' at paragraph {i}")

    # Also clean up empty paragraphs in Executive Summary
    for i, paragraph in enumerate(doc.paragraphs):
        if i > 0 and i < len(doc.paragraphs) - 1:
            # Check if this is an empty paragraph in Executive Summary
            if paragraph.text.strip() == "":
                prev_text = doc.paragraphs[i - 1].text.strip()
                next_text = doc.paragraphs[i + 1].text.strip()

                # Check if surrounding paragraphs mention Executive Summary
                if "Executive Summary" in prev_text or "Executive Summary" in next_text:
                    # Merge with next paragraph if it has content
                    if next_text:
                        doc.paragraphs[i + 1].text = paragraph.text + doc.paragraphs[i + 1].text
                        paragraph.text = ""
                        cleaned_count += 1

    print(f"‚úÖ Cleaned {cleaned_count} issues in Executive Summary")
    return cleaned_count


def clean_executive_summary_duplicates(doc, json_data=None):  # Add optional json_data parameter
    """Clean up duplicate static text and wrong content in Executive Summary"""
    print("üßπ Cleaning Executive Summary duplicates and wrong content...")

    cleaned_count = 0
    in_exec_summary = False
    exec_summary_start = None

    # First, find the Executive Summary section
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()

        if "Executive Summary" in text and not in_exec_summary:
            in_exec_summary = True
            exec_summary_start = i
            print(f"‚úÖ Found Executive Summary at paragraph {i}")
            break

    if not exec_summary_start:
        print("‚ö†Ô∏è Could not find Executive Summary section")
        return 0

    # Look for duplicate static text and wrong content within Executive Summary
    static_text_patterns = [
        "Regulatory alignment: Integrates adaptation",
        "Actionable pathway: Translates risk insights",
        "Continuous improvement: Establishes monitoring"
    ]

    wrong_content_patterns = [
        "East Hill maritime development can sustain a viable cattle enterprise",
        "East Hill Farm can sustain a viable cattle enterprise",
        "maritime development can sustain a viable cattle",
        "can sustain a viable cattle enterprise"
    ]

    duplicate_found = False
    lines_seen = []

    for i in range(exec_summary_start, min(exec_summary_start + 30, len(doc.paragraphs))):
        paragraph = doc.paragraphs[i]
        text = paragraph.text.strip()

        # Remove wrong farm content
        for wrong_pattern in wrong_content_patterns:
            if wrong_pattern in text:
                if json_data:
                    # Replace with correct client name
                    client_name = json_data.get("client_name", "Ministry of Rural Development")
                    client_location = json_data.get("client_location", "Republic of Fiji")
                    correct_text = f"{client_name} can maintain resilient operations in {client_location} through climate adaptation by implementing prioritized actions and developing required capabilities."
                    paragraph.text = correct_text
                else:
                    paragraph.text = ""
                cleaned_count += 1
                print(f"üóëÔ∏è Removed wrong farm content: '{wrong_pattern[:50]}...'")
                break

        # Check for duplicate static text
        if any(pattern in text for pattern in static_text_patterns):
            # Check if we've seen this line before
            for seen_line in lines_seen:
                similarity = len(set(text.split()) & set(seen_line.split())) / max(len(text.split()),
                                                                                   len(seen_line.split()))
                if similarity > 0.8:  # 80% similar
                    # This is a duplicate
                    paragraph.text = ""
                    duplicate_found = True
                    cleaned_count += 1
                    print(f"üóëÔ∏è Removed duplicate static text: '{text[:50]}...'")
                    break

            if text and not any(wrong_pattern in text for wrong_pattern in wrong_content_patterns):
                lines_seen.append(text)

    # Also clean up the "Key messages" section to ensure proper formatting
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()

        if "Key messages" in text and "value, urgency, actions" in text:
            # Make sure it's properly formatted
            if ":" in text and not text.endswith(":"):
                # Fix the formatting
                parts = text.split(":")
                if len(parts) >= 2:
                    paragraph.text = f"{parts[0].strip()}:"
                    # Add the rest as a new paragraph if needed
                    rest_text = ":".join(parts[1:]).strip()
                    if rest_text:
                        new_para = doc.paragraphs[i].insert_paragraph_before(rest_text)
                        new_para.style = "Normal"

    print(f"‚úÖ Cleaned {cleaned_count} issues in Executive Summary")
    return cleaned_count


def protect_static_executive_summary_text(doc):
    """Remove any AI-generated content that duplicates the static '1.1 Why this plan...' text"""
    print("üõ°Ô∏è Protecting static Executive Summary text...")

    static_text_phrases = [
        "Regulatory alignment: Integrates adaptation",
        "Actionable pathway: Translates risk insights",
        "Continuous improvement: Establishes monitoring",
        "1.1 Why this plan and what it delivers"
    ]

    removed_count = 0
    ai_content_indicators = ["AI Analysis", "AI-generated", "‚Ä¢ Regulatory alignment", "‚Ä¢ Actionable pathway",
                             "‚Ä¢ Continuous improvement"]

    # First pass: Remove any AI analysis sections
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()

        # Remove AI analysis headings
        if any(indicator in text for indicator in ai_content_indicators):
            # Check if this is in Executive Summary section
            is_in_exec_summary = False
            # Look backwards to see if we're in Executive Summary
            for j in range(max(0, i - 10), i):
                if "Executive Summary" in doc.paragraphs[j].text:
                    is_in_exec_summary = True
                    break

            if is_in_exec_summary:
                paragraph.clear()
                removed_count += 1
                print(f"üóëÔ∏è Removed AI analysis heading at paragraph {i}")

    # Second pass: Find and protect the static text section
    static_section_found = False
    static_section_index = -1

    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()

        # Find the static text section
        if "1.1 Why this plan and what it delivers" in text:
            static_section_found = True
            static_section_index = i
            print(f"‚úÖ Found static text section at paragraph {i}")

            # Check next few paragraphs for the bullet points
            for j in range(i, min(i + 10, len(doc.paragraphs))):
                next_text = doc.paragraphs[j].text.strip()
                # If this paragraph looks like it might be AI-duplicated content after the static section
                if j > i + 3 and any(phrase in next_text for phrase in static_text_phrases[1:]):
                    # Clear AI-duplicated content
                    doc.paragraphs[j].clear()
                    removed_count += 1
                    print(f"üóëÔ∏è Cleared AI-duplicated static text at paragraph {j}")

    # Third pass: Clean up any orphaned content
    if static_section_found and static_section_index > 0:
        # Check paragraphs immediately before the static text for AI duplicates
        for i in range(max(0, static_section_index - 3), static_section_index):
            text = doc.paragraphs[i].text.strip()
            if any(phrase in text for phrase in static_text_phrases):
                # This is likely AI content trying to duplicate static text
                doc.paragraphs[i].clear()
                removed_count += 1
                print(f"üóëÔ∏è Cleared pre-static AI duplicate at paragraph {i}")

    print(f"üõ°Ô∏è Protected static text: removed {removed_count} AI duplicates")
    return removed_count


def ensure_executive_summary_structure(doc):
    """Ensure Executive Summary has proper structure with AI content in right place"""
    print("üîß Checking Executive Summary structure...")

    # Find the Executive Summary heading
    exec_heading_index = -1
    static_text_index = -1

    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()

        if "Executive Summary" in text and exec_heading_index == -1:
            exec_heading_index = i
            print(f"‚úÖ Found 'Executive Summary' heading at paragraph {i}")

        if "1.1 Why this plan and what it delivers" in text and static_text_index == -1:
            static_text_index = i
            print(f"‚úÖ Found static text section at paragraph {i}")
            break  # Only find the first occurrence

    if exec_heading_index == -1:
        print("‚ö†Ô∏è Could not find Executive Summary heading")
        return False

    # Check structure
    if static_text_index == -1:
        print("‚ö†Ô∏è Could not find static text section - template might be missing it")
    elif static_text_index <= exec_heading_index + 2:
        print("‚ö†Ô∏è Static text appears too close to heading - may be missing AI content")
        return False

    print("‚úÖ Executive Summary structure looks good")
    return True


def clean_executive_summary_content(doc, json_data):
    """Simple cleanup for Executive Summary - remove wrong content and ensure proper structure"""
    print("üßπ Cleaning Executive Summary content...")

    wrong_content_patterns = [
        "East Hill maritime development can sustain a viable cattle enterprise",
        "East Hill Farm can sustain a viable cattle enterprise",
        "maritime development can sustain a viable cattle",
        "can sustain a viable cattle enterprise",
        "Solara Energy, a leading utility provider serving"
    ]

    cleaned_count = 0

    # First, fix wrong content
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text

        for wrong_pattern in wrong_content_patterns:
            if wrong_pattern in text:
                # Replace with correct content based on client
                client_name = json_data.get("client_name", "Ministry of Rural Development")
                client_location = json_data.get("client_location", "Republic of Fiji")

                if "maritime development" in wrong_pattern or "cattle enterprise" in wrong_pattern:
                    correct_text = f"{client_name} can maintain resilient operations in {client_location} through comprehensive climate adaptation by implementing prioritized actions and developing required capabilities."
                    paragraph.text = correct_text
                    cleaned_count += 1
                    print(f"‚úÖ Fixed wrong farm content in Executive Summary at paragraph {i}")
                break

    # Second, ensure proper bullet formatting
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()

        # Fix bullet formatting in Executive Summary
        if "Executive Summary" in paragraph.text:
            # Check next 20 paragraphs for bullet issues
            for j in range(i, min(i + 20, len(doc.paragraphs))):
                bullet_text = doc.paragraphs[j].text

                # Replace markdown bullets with proper bullets
                if bullet_text.startswith("* "):
                    doc.paragraphs[j].text = bullet_text.replace("* ", "‚Ä¢ ", 1)
                elif bullet_text.startswith("- "):
                    doc.paragraphs[j].text = bullet_text.replace("- ", "‚Ä¢ ", 1)

                # Ensure proper formatting for key messages
                bullet_text = doc.paragraphs[j].text
                if "‚Ä¢" in bullet_text and ":" not in bullet_text:
                    # Check if this is a key message that needs colon
                    lower_text = bullet_text.lower()
                    if any(keyword in lower_text for keyword in
                           ["value", "urgency", "action", "strategic", "implementation"]):
                        parts = bullet_text.split("‚Ä¢ ", 1)
                        if len(parts) > 1:
                            content = parts[1]
                            words = content.split()
                            if len(words) > 1:
                                first_word = words[0].rstrip(":")
                                rest = " ".join(words[1:])
                                doc.paragraphs[j].text = f"‚Ä¢ {first_word}: {rest}"

    print(f"‚úÖ Cleaned {cleaned_count} items from Executive Summary")
    return cleaned_count

def quick_fix_executive_summary(doc):
    """Quick fix for the Executive Summary issues"""
    print("üöÄ Applying quick fix to Executive Summary...")

    cleaned_count = 0

    # Find and fix the wrong farm content
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text

        # Remove the wrong farm content and replace it
        if "East Hill maritime development can sustain a viable cattle enterprise" in text:
            # Replace with correct Ministry content
            correct_text = """The Ministry of Rural Development can maintain resilient infrastructure operations through approximately 3¬∞C global warming by implementing prioritized adaptation actions and developing required capabilities. Beyond that, transformational options should be developed in parallel. The plan embeds the disciplines‚Äîgovernance, triggers, monitoring and integration‚Äîneeded to make adaptation routine, auditable and proportionate. Immediate next step: Endorse this executive summary and instruct preparation of the detailed Implementation Plan with budget, triggers and responsibilities, followed by the first six-monthly review cycle."""

            paragraph.text = correct_text
            cleaned_count += 1
            print("‚úÖ Fixed wrong farm content in Executive Summary")

        # Fix duplicate static text
        elif "‚Ä¢ Regulatory alignment:" in text:
            # Count how many times this appears in nearby paragraphs
            count = 0
            for j in range(max(0, i - 3), min(len(doc.paragraphs), i + 3)):
                if "‚Ä¢ Regulatory alignment:" in doc.paragraphs[j].text:
                    count += 1

            if count > 1:
                # Check if this is a duplicate (look for identical or very similar text nearby)
                for j in range(max(0, i - 2), min(len(doc.paragraphs), i + 2)):
                    if j != i and doc.paragraphs[j].text.strip() == text:
                        # This is a duplicate, remove it
                        paragraph.text = ""
                        cleaned_count += 1
                        print("‚úÖ Removed duplicate static text")
                        break

    # Also fix any remaining "East Hill" references
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text
        if "East Hill" in text and "Farm" not in text and "maritime" not in text:
            # Replace with Ministry
            paragraph.text = text.replace("East Hill", "Ministry of Rural Development")
            cleaned_count += 1
            print("‚úÖ Fixed 'East Hill' reference")

    print(f"‚úÖ Quick fix applied: {cleaned_count} changes made")
    return cleaned_count

def verify_table_formatting(doc):
    """Verify that table formatting in Word matches expected formatting"""
    print("üìä Verifying table formatting consistency...")

    table_fixes = 0

    for table_idx, table in enumerate(doc.tables):
        try:
            # Check table properties
            tbl = table._tbl
            tblPr = tbl.tblPr

            # Ensure table has borders
            has_borders = False
            for elem in tblPr:
                if 'tblBorders' in elem.tag:
                    has_borders = True
                    break

            if not has_borders:
                print(f"‚ö†Ô∏è Table {table_idx} has no borders, applying basic formatting")
                # Apply basic table borders
                tblBorders = parse_xml(
                    r'<w:tblBorders xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main">'
                    r'<w:top w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                    r'<w:left w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                    r'<w:bottom w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                    r'<w:right w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                    r'<w:insideH w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                    r'<w:insideV w:val="single" w:sz="2" w:space="0" w:color="000000"/>'
                    r'</w:tblBorders>')
                tblPr.append(tblBorders)
                table_fixes += 1

            # Ensure consistent font in all cells
            for row_idx, row in enumerate(table.rows):
                for cell_idx, cell in enumerate(row.cells):
                    for paragraph in cell.paragraphs:
                        for run in paragraph.runs:
                            if run.font.name != "Calibri" and run.text.strip():
                                run.font.name = "Calibri"
                                if row_idx == 0:  # Header row
                                    run.bold = True
                                    run.font.size = Pt(11)
                                else:
                                    run.font.size = Pt(10)

            # Ensure proper column widths for specific tables
            if len(table.columns) >= 2:
                # Set reasonable default widths
                total_width = Inches(6.0)
                if len(table.columns) == 2:
                    table.columns[0].width = total_width * 0.4
                    table.columns[1].width = total_width * 0.6
                elif len(table.columns) == 3:
                    table.columns[0].width = total_width * 0.3
                    table.columns[1].width = total_width * 0.4
                    table.columns[2].width = total_width * 0.3
                elif len(table.columns) == 4:
                    table.columns[0].width = total_width * 0.25
                    table.columns[1].width = total_width * 0.35
                    table.columns[2].width = total_width * 0.2
                    table.columns[3].width = total_width * 0.2

        except Exception as e:
            print(f"‚ö†Ô∏è Error verifying table {table_idx}: {e}")

    print(f"‚úÖ Applied {table_fixes} table formatting fixes")
    return table_fixes

def remove_all_old_appendix_content(doc):
    """Remove ALL old Appendix content including any placeholder text"""
    print("üóëÔ∏è Removing ALL old Appendix content...")

    # More comprehensive list of patterns to remove
    patterns_to_remove = [
        "This is a placeholder for an automatically numbered appendix.",
        "This appendix will contain a list of cited documents",
        "with each entry added automatically",
        "Appendix A: Supporting Documents",
        "Appendix"
    ]

    # First pass: remove paragraphs containing these patterns
    paragraphs_to_remove = []

    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()
        if any(pattern in text for pattern in patterns_to_remove):
            paragraphs_to_remove.append(i)
            print(f"üóëÔ∏è Marked for removal: '{text}'")

    # Remove in reverse order
    for i in sorted(paragraphs_to_remove, reverse=True):
        if i < len(doc.paragraphs):
            p = doc.paragraphs[i]._element
            p.getparent().remove(p)

    # Second pass: look for the specific problematic block
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()
        if "UK Met Office (2025). Met Office Data Report, 2025" in text:
            # Found the problematic block - remove this paragraph and surrounding ones
            start_index = max(0, i - 3)  # Remove a few paragraphs before
            end_index = min(len(doc.paragraphs), i + 2)  # And a few after

            for j in range(start_index, end_index):
                if j < len(doc.paragraphs):
                    p_text = doc.paragraphs[j].text.strip()
                    if any(pattern in p_text for pattern in patterns_to_remove + ["UK Met Office", "Project Team"]):
                        try:
                            p = doc.paragraphs[j]._element
                            p.getparent().remove(p)
                        except:
                            pass

    print(f"‚úÖ Old appendix content removal completed")


def create_proper_appendix_section(doc, json_data):
    """Create proper Appendix section with the new layout"""
    print("üìã Creating proper Appendix section...")

    # First, remove ALL old Appendix content multiple times to be sure
    remove_all_old_appendix_content(doc)

    # Also check tables for appendix content
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                for paragraph in cell.paragraphs:
                    text = paragraph.text.strip()
                    patterns = [
                        "This is a placeholder for an automatically numbered appendix.",
                        "This appendix will contain a list of cited documents",
                        "Appendix A: Supporting Documents"
                    ]
                    if any(pattern in text for pattern in patterns):
                        paragraph.text = ""

    # Find the best place to insert the new appendix
    insert_index = len(doc.paragraphs) - 1

    # Look for existing appendix content to replace
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip().lower()
        if "appendix" in text and "supporting documents" in text:
            insert_index = i
            break
        elif "appendix" in text:
            insert_index = i
            break

    # Clear out any remaining old appendix content at insertion point
    if insert_index < len(doc.paragraphs):
        current_text = doc.paragraphs[insert_index].text.strip()
        if any(pattern in current_text for pattern in [
            "This is a placeholder",
            "automatically numbered appendix",
            "This appendix will contain"
        ]):
            p = doc.paragraphs[insert_index]._element
            p.getparent().remove(p)

    # Add the new clean appendix section
    appendix_heading = doc.add_heading("Appendix A: Supporting Documents", level=1)

    # Description paragraph
    description = doc.add_paragraph(
        "This appendix contains all supporting documents, references, and additional materials referenced throughout the climate adaptation plan.")

    # References heading
    references_heading = doc.add_heading("References", level=2)

    # Add references from JSON
    if "references" in json_data and json_data["references"]:
        for ref in json_data["references"]:
            ref_para = doc.add_paragraph()
            ref_para.add_run(f"{ref.get('author', '')} ({ref.get('year', '')}). {ref.get('title', '')}")
    else:
        no_ref_para = doc.add_paragraph("No references provided.")

    # Additional Supporting Materials heading
    supporting_heading = doc.add_heading("Additional Supporting Materials", level=2)

    # Supporting materials bullet list
    supporting_docs = [
        "Climate Risk Assessment Data Sheets",
        "Stakeholder Engagement Records",
        "Site Survey Documentation",
        "Climate Projection Models",
        "Adaptation Action Cost-Benefit Analysis",
        "Monitoring and Evaluation Framework"
    ]

    for doc_item in supporting_docs:
        doc_para = doc.add_paragraph()
        doc_para.add_run("‚Ä¢ " + doc_item)

    # Contact Information heading
    contact_heading = doc.add_heading("Contact Information", level=2)

    # Contact information
    contact_para = doc.add_paragraph()
    contact_para.add_run("For further information about this Climate Adaptation Plan, please contact:\n\n")
    contact_para.add_run(f"{json_data.get('client_name', 'East Hill Farm')}\n")
    contact_para.add_run(f"{json_data.get('client_location', 'Somerset, England')}\n")
    contact_para.add_run("Email: info@easthillfarm.com\n")
    contact_para.add_run("Phone: +44 (0)1234 567890")


def clean_duplicate_appendix_content(doc):
    """Final cleanup to remove any duplicate appendix content"""
    print("üßπ Final cleanup of duplicate appendix content...")

    # Look for the problematic pattern that keeps appearing
    found_proper_appendix = False
    paragraphs_to_remove = []

    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()

        # Track when we find the proper appendix
        if "Appendix A: Supporting Documents" in text and "This appendix contains all supporting documents" in \
           doc.paragraphs[i + 1].text if i + 1 < len(doc.paragraphs) else "":
            found_proper_appendix = True
            continue

        # If we find appendix-like content AFTER the proper appendix, remove it
        if found_proper_appendix and any(pattern in text for pattern in [
            "This is a placeholder for an automatically numbered appendix",
            "This appendix will contain a list of cited documents",
            "UK Met Office (2025). Met Office Data Report, 2025",
            "Project Team (2025). Mural Project Board Documentation"
        ]):
            paragraphs_to_remove.append(i)

    # Remove the duplicates
    for i in sorted(paragraphs_to_remove, reverse=True):
        if i < len(doc.paragraphs):
            p = doc.paragraphs[i]._element
            p.getparent().remove(p)

    print(f"‚úÖ Removed {len(paragraphs_to_remove)} duplicate appendix paragraphs")


def add_conclusions_after_appendix(doc):
    """Add Conclusions and Recommendations section after Appendix"""
    print("üìù Adding Conclusions and Recommendations after Appendix...")

    # Add page break before Conclusions
    doc.add_page_break()

    # Conclusions and Recommendations heading
    conclusions_heading = doc.add_heading("Conclusions and Recommendations", level=1)

    # Introduction paragraph
    intro_para = doc.add_paragraph(
        "This assessment highlights the importance of proactive climate adaptation planning. Key recommendations include:")

    # Recommendations bullet list
    recommendations = [
        "Develop comprehensive climate resilience strategy",
        "Invest in climate-adaptive infrastructure",
        "Enhance early warning systems for extreme weather",
        "Promote community awareness and preparedness programs",
        "Maintain ongoing monitoring and evaluation of climate risks"
    ]

    for item in recommendations:
        rec_para = doc.add_paragraph()
        rec_para.add_run("‚Ä¢ " + item)


def add_bullet_list(doc, items):
    """Safely add bullet list without style errors"""
    for item in items:
        p = doc.add_paragraph()
        p.add_run("‚Ä¢ " + str(item))


def create_excel_from_json(data, path):
    wb = Workbook()
    ws = wb.active
    ws.title = "Table 1"
    if isinstance(data, list) and len(data) > 0 and isinstance(data[0], dict):
        headers = list(data[0].keys())
        ws.append(headers)
        for row in data:
            ws.append([row.get(h, "") for h in headers])
    else:
        ws.append(["value"])
        ws.append([json.dumps(data)])
    wb.save(path)


# ---------------- GEMINI UTILITIES ----------------
def discover_available_models():
    if not GEMINI_API_KEY:
        return None, "API key not configured"

    try:
        url = f"https://generativelanguage.googleapis.com/v1beta/models?key={GEMINI_API_KEY}"
        response = requests.get(url, timeout=30)
        if response.status_code == 200:
            models_data = response.json()
            models = models_data.get('models', [])

            available_models = []
            for model in models:
                model_name = model['name']
                supported_methods = model.get('supportedGenerationMethods', [])
                if 'generateContent' in supported_methods:
                    short_name = model_name.split('/')[-1]
                    available_models.append({
                        'name': model_name,
                        'short_name': short_name,
                        'version': 'v1beta'
                    })

            if available_models:
                return available_models, None

        return None, "No models found"

    except Exception as e:
        return None, f"Error: {str(e)}"


def get_best_available_model():
    available_models, error = discover_available_models()
    if not available_models:
        return None, error

    # Use the first available model
    return available_models[0], None


def initialize_gemini():
    global AVAILABLE_GEMINI_MODEL

    if not GEMINI_API_KEY:
        return False

    model, error = get_best_available_model()
    if model:
        AVAILABLE_GEMINI_MODEL = model
        return True
    else:
        return False


def send_to_gemini(filepaths):
    if not GEMINI_API_KEY or not AVAILABLE_GEMINI_MODEL:
        return {"status": "error", "message": "Gemini API not configured."}

    model_name = AVAILABLE_GEMINI_MODEL['name']
    api_version = AVAILABLE_GEMINI_MODEL['version']
    api_url = f"https://generativelanguage.googleapis.com/{api_version}/{model_name}:generateContent?key={GEMINI_API_KEY}"

    file_list = "\n".join([f"- {os.path.basename(p)}" for p in filepaths])

    prompt = f"""
    Analyze these files for a climate risk assessment report: 
    {file_list}

    Provide a brief analysis focusing on:
    1. Main climate risks and vulnerabilities to eastern country /firm
    2. Key data points and trends 
    3. Recommendations for resilience planning
    4. Priority actions for adaptation

    Keep the response concise and actionable for a technical report.
    """

    payload = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {
            "temperature": 0.3,
            "maxOutputTokens": 1024,
        }
    }

    try:
        resp = requests.post(api_url, json=payload, timeout=120)

        if resp.status_code == 200:
            result = resp.json()
            if 'candidates' in result and result['candidates']:
                text_response = result['candidates'][0]['content']['parts'][0]['text']
                return {"status": "success", "analysis": text_response}
            return {"status": "error", "message": "No response from API"}
        else:
            return {"status": "error", "message": f"API Error {resp.status_code}"}

    except Exception as e:
        return {"status": "error", "message": f"Request Failed: {str(e)}"}


def add_ai_summary_sections(doc, json_data):
    """Add AI summary sections at the END of each specified section"""
    print("ü§ñ Adding AI summary sections to document...")

    # Define AI summary sections with their titles and JSON field names
    ai_sections = [
        {
            "title": "AI Analysis",
            "placeholder": "exec-summ_ai_summary",
            "json_field": "exec-summ_ai_summary",
            "section_keyword": "Executive Summary"
        },
        {
            "title": "AI Analysis",
            "placeholder": "intro_ai_summary",
            "json_field": "intro_ai_summary",
            "section_keyword": "Introduction"
        },
        {
            "title": "AI Analysis",
            "placeholder": "client-desc_ai_summary",
            "json_field": "client-desc_ai_summary",
            "section_keyword": "East Hill Farm in a Changing Climate"
        },
        {
            "title": "AI Analysis",
            "placeholder": "hazards_ai_summary",
            "json_field": "hazards_ai_summary",
            "section_keyword": "Climate Change Hazards"
        },
        {
            "title": "AI Analysis",
            "placeholder": "impact_ai_summary",
            "json_field": "impact_ai_summary",
            "section_keyword": "Impact Assessment"
        },
        {
            "title": "AI Analysis",
            "placeholder": "adaptive-capacity_ai_summary",
            "json_field": "adaptive-capacity_ai_summary",
            "section_keyword": "Adaptive capacity"
        },
        {
            "title": "AI Analysis",
            "placeholder": "planning_ai_summary",
            "json_field": "planning_ai_summary",
            "section_keyword": "Adaptation Planning"
        },
        {
            "title": "AI Analysis",
            "placeholder": "conclusion_ai_summary",
            "json_field": "conclusion_ai_summary",
            "section_keyword": "Conclusion"
        }
    ]

    sections_added = 0

    for section in ai_sections:
        section_title = section["title"]
        placeholder = f"[[{section['placeholder']}]]"
        json_field = section["json_field"]
        section_keyword = section["section_keyword"]

        # Get the AI summary content from JSON
        ai_content = json_data.get(json_field, "")

        # Skip if no content
        if not ai_content or ai_content.strip() == "":
            print(f"‚ö†Ô∏è No AI content for {json_field}, skipping section")
            continue

        print(f"üìù Adding AI summary for section: {section_keyword}")

        # Find where to insert at the END of the specified section
        insertion_index = find_end_of_section(doc, section_keyword)

        if insertion_index is not None and insertion_index < len(doc.paragraphs):
            try:
                # Add spacing before the AI section
                spacing_para = doc.paragraphs[insertion_index].insert_paragraph_before()
                spacing_para.paragraph_format.space_before = Pt(12)

                # Add a horizontal line or separator
                separator_para = doc.paragraphs[insertion_index].insert_paragraph_before("‚îÄ" * 50)
                separator_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
                separator_para.runs[0].font.color.rgb = RGBColor(192, 192, 192)  # Light gray

                # Add the AI section heading (smaller than regular headings)
                heading_para = doc.paragraphs[insertion_index].insert_paragraph_before(section_title)
                if heading_para.runs:
                    heading_para.runs[0].bold = True
                    heading_para.runs[0].font.size = Pt(11)
                    heading_para.runs[0].font.color.rgb = RGBColor(0, 102, 204)  # Blue color

                # Add the AI content
                content_para = doc.paragraphs[insertion_index].insert_paragraph_before(ai_content)
                content_para.style = "Normal"

                # Format the AI content (italic, smaller font)
                if content_para.runs:
                    for run in content_para.runs:
                        run.italic = True
                        run.font.size = Pt(10)
                        run.font.color.rgb = RGBColor(64, 64, 64)  # Dark gray

                sections_added += 1
                print(f"‚úÖ Added AI analysis at end of '{section_keyword}' section")

            except Exception as e:
                print(f"‚ö†Ô∏è Error adding AI section for {section_keyword}: {e}")
                import traceback
                traceback.print_exc()
        else:
            # Fallback: add at the end of the document
            try:
                print(f"‚ö†Ô∏è Section '{section_keyword}' not found, adding at end")
                doc.add_paragraph().add_run(f"AI Analysis for {section_keyword}:").bold = True
                doc.add_paragraph(ai_content)
                sections_added += 1
                print(f"‚úÖ Added AI section at end: {section_keyword}")
            except Exception as e:
                print(f"‚ö†Ô∏è Error adding AI section at end for {section_keyword}: {e}")

    print(f"üìä Total AI summary sections added: {sections_added}")
    return sections_added > 0


def remove_ai_analysis_sections(doc):
    """Remove leftover AI analysis sections from the document"""
    print("üóëÔ∏è Removing AI analysis sections...")

    try:
        sections_to_remove = [
            "AI-Powered Analysis",
            "Based on the provided files, here's an analysis",
            "eastern country/firm",
            "Main Climate Risks and Vulnerabilities to Eastern",
            "AI Analysis of",
            "**AI Analysis of**"
        ]

        removed_count = 0

        for i, paragraph in enumerate(doc.paragraphs):
            text = paragraph.text.strip()

            # Check if this paragraph contains AI analysis text
            for section_text in sections_to_remove:
                if section_text in text:
                    # Clear the paragraph
                    paragraph.clear()
                    removed_count += 1
                    print(f"üóëÔ∏è Removed AI analysis section at paragraph {i}: '{text[:50]}...'")
                    break

            # Also check for paragraphs that start with numbers like "12 AI-Powered Analysis"
            if text and text[0].isdigit() and any(x in text for x in ["AI", "Analysis", "eastern"]):
                paragraph.clear()
                removed_count += 1
                print(f"üóëÔ∏è Removed numbered AI analysis at paragraph {i}")

        print(f"‚úÖ Removed {removed_count} AI analysis sections")
        return removed_count  # Always returns an integer

    except Exception as e:
        print(f"‚ö†Ô∏è Error removing AI analysis sections: {e}")
        return 0  # Return 0 instead of None


def find_end_of_section(doc, section_keyword):
    """Find the END of a specific section (right before next heading)"""
    print(f"üîç Looking for end of section: {section_keyword}")

    found_section = False
    current_heading_level = None

    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()

        # Check if this is our target section
        if section_keyword in text and not found_section:
            # Check if it's a heading (has heading style or looks like a heading)
            is_heading = (
                    paragraph.style.name.startswith('Heading') or
                    (len(text) < 100 and text.isupper()) or
                    text == section_keyword
            )

            if is_heading:
                found_section = True
                print(f"‚úÖ Found '{section_keyword}' heading at paragraph {i}")

                # Try to determine heading level
                if paragraph.style.name.startswith('Heading'):
                    try:
                        current_heading_level = int(paragraph.style.name.replace('Heading ', ''))
                    except:
                        current_heading_level = 1
                else:
                    current_heading_level = 1

                continue

        # If we've found our section, look for the end
        if found_section:
            # Check if we've reached another heading (end of current section)
            is_next_heading = False

            # Check by style
            if paragraph.style.name.startswith('Heading'):
                try:
                    next_heading_level = int(paragraph.style.name.replace('Heading ', ''))
                    # If next heading is same or higher level, we've reached end
                    if next_heading_level <= current_heading_level:
                        is_next_heading = True
                except:
                    is_next_heading = True

            # Check by content patterns
            elif (len(text) < 100 and
                  any(keyword in text for keyword in [
                      "Table", "Figure", "Appendix", "References",
                      "Executive Summary", "Introduction", "Conclusion"
                  ])):
                is_next_heading = True

            # Check for obvious next sections
            elif (section_keyword == "Executive Summary" and "Introduction" in text):
                is_next_heading = True
            elif (section_keyword == "Introduction" and "East Hill Farm" in text):
                is_next_heading = True
            elif (section_keyword == "Climate Change Hazards" and "Planning Process" in text):
                is_next_heading = True

            # If we found the next heading, insert BEFORE it
            if is_next_heading and text:  # Make sure it's not an empty paragraph
                print(f"üìå Found next heading '{text}' at paragraph {i}, inserting at {i}")
                return i

            # If we're at the end of the document
            if i == len(doc.paragraphs) - 1:
                print(f"üìå Reached end of document, inserting at {i + 1}")
                return i + 1

    if not found_section:
        print(f"‚ö†Ô∏è Section '{section_keyword}' not found in document")
        # Try a broader search
        return find_section_by_broad_search(doc, section_keyword)

    print(f"‚ö†Ô∏è Could not find end of section '{section_keyword}'")
    return None


def find_section_by_broad_search(doc, section_keyword):
    """Broad search for section when exact match fails"""
    print(f"üîç Broad search for section containing: {section_keyword}")

    # Split keyword for partial matching
    keywords = section_keyword.split()

    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()

        # Check for partial matches
        matches_all_keywords = all(any(kw in text for kw in keywords) for keyword in keywords[:2]) if len(
            keywords) > 1 else keywords[0] in text

        if matches_all_keywords:
            print(f"‚úÖ Found partial match for '{section_keyword}' at paragraph {i}")
            # Look ahead for next heading
            for j in range(i + 1, len(doc.paragraphs)):
                next_text = doc.paragraphs[j].text.strip()
                if (doc.paragraphs[j].style.name.startswith('Heading') and
                        len(next_text) > 0 and
                        section_keyword not in next_text):
                    print(f"üìå Found next heading at paragraph {j}, inserting at {j}")
                    return j

            # If no next heading found, insert near this paragraph
            return min(i + 3, len(doc.paragraphs) - 1)

    print(f"‚ùå Could not find section '{section_keyword}' even with broad search")
    return None


def generate_ai_summaries_if_missing(json_data):
    """Generate AI summaries for all AI summary fields"""
    print("ü§ñ Generating AI summaries for all sections...")

    # Map each AI summary field to its context/prompt
    ai_field_contexts = {
        "exec-summ_ai_summary": {
            "section": "Executive Summary",
            "prompt_part": "Provide an AI analysis of the executive summary focusing on: 1) Key climate risks identified, 2) Adaptation priorities, 3) Strategic recommendations for farm resilience"
        },
        "intro_ai_summary": {
            "section": "Introduction",
            "prompt_part": "Analyze the introduction section for: 1) Plan objectives alignment, 2) Regulatory compliance needs, 3) Capacity building requirements"
        },
        "client-desc_ai_summary": {
            "section": "Client Description",
            "prompt_part": "Analyze the client description for: 1) Site-specific vulnerabilities, 2) Existing climate impacts, 3) Transport and infrastructure challenges"
        },
        "hazards_ai_summary": {
            "section": "Climate Change Hazards",
            "prompt_part": "Analyze climate hazards for: 1) Severity assessment, 2) Hazard interdependencies, 3) Temporal progression risks"
        },
        "impact_ai_summary": {
            "section": "Impact Assessment",
            "prompt_part": "Analyze impact assessment for: 1) Cascading effects, 2) Warming scenario impacts, 3) Systemic vulnerabilities"
        },
        "adaptive-capacity_ai_summary": {
            "section": "Adaptive Capacity",
            "prompt_part": "Analyze adaptive capacity for: 1) Strengths and gaps, 2) Development priorities, 3) Resilience building needs"
        },
        "planning_ai_summary": {
            "section": "Adaptation Planning",
            "prompt_part": "Analyze adaptation planning for: 1) Action prioritization, 2) Implementation pathways, 3) Integration strategies"
        },
        "conclusion_ai_summary": {
            "section": "Conclusion",
            "prompt_part": "Analyze conclusions for: 1) Key findings synthesis, 2) Forward-looking recommendations, 3) Resilience building pathway"
        }
    }

    generated_count = 0

    for field, context in ai_field_contexts.items():
        current_content = json_data.get(field, "")

        # Check if field is empty or contains placeholder text
        should_generate = (
                not current_content or
                current_content.strip() == "" or
                "AI-generated analysis" in current_content or
                "would appear here" in current_content or
                "AI analysis for" in current_content or
                len(current_content.strip()) < 100  # Very short content
        )

        if should_generate:
            if GEMINI_API_KEY and AVAILABLE_GEMINI_MODEL:
                print(f"üîß Generating AI content for: {field} ({context['section']})")
                generated_content = generate_specific_ai_content(field, context, json_data)
                if generated_content and len(generated_content.strip()) > 50:
                    json_data[field] = generated_content
                    generated_count += 1
                    print(f"‚úÖ Generated {field} ({len(generated_content)} chars)")
                else:
                    # Fallback to realistic placeholder
                    placeholder_content = generate_realistic_placeholder(field, context, json_data)
                    json_data[field] = placeholder_content
                    print(f"‚ö†Ô∏è Gemini failed, using placeholder for {field}")
            else:
                # Generate realistic placeholder content
                placeholder_content = generate_realistic_placeholder(field, context, json_data)
                json_data[field] = placeholder_content
                generated_count += 1
                print(f"üìù Added realistic placeholder for {field}")
        else:
            print(f"‚úì AI content already exists for {field} ({len(current_content)} chars)")

    print(f"üìä Generated/updated {generated_count} AI summaries")
    return json_data


def generate_specific_ai_content(field, context, json_data):
    """Generate specific AI content for a section"""
    section_name = context["section"]
    prompt_part = context["prompt_part"]

    # Get the actual content from the JSON for this section
    section_content = ""
    if section_name == "Executive Summary":
        section_content = json_data.get("exec-summ_bespoke_text", "")
    elif section_name == "Introduction":
        section_content = json_data.get("intro-bespoke_text", "")
    elif section_name == "Client Description":
        section_content = json_data.get("client-desc_bespoke_text", "")

    # Get context data
    client_name = json_data.get("client_name", "East Hill Farm")
    client_location = json_data.get("client_location", "Somerset, England")
    industry_1 = json_data.get("Industry-1", "farm")
    industry_2 = json_data.get("Industry-2", "livestock and processing systems")

    # Build the prompt
    prompt = f"""
    Analyze this {section_name} section from a climate adaptation plan for {client_name} in {client_location}:

    {section_content}

    {prompt_part}

    Provide a concise, professional analysis (150-250 words) with:
    1. 2-3 key insights from the content
    2. 1-2 specific recommendations
    3. Any identified gaps or opportunities

    Format with bullet points for clarity.
    """

    try:
        # Make direct Gemini API call
        model_name = AVAILABLE_GEMINI_MODEL['name']
        api_version = AVAILABLE_GEMINI_MODEL['version']
        api_url = f"https://generativelanguage.googleapis.com/{api_version}/{model_name}:generateContent?key={GEMINI_API_KEY}"

        payload = {
            "contents": [{"parts": [{"text": prompt}]}],
            "generationConfig": {
                "temperature": 0.3,
                "maxOutputTokens": 800,
                "topP": 0.8,
                "topK": 40
            }
        }

        response = requests.post(api_url, json=payload, timeout=30)

        if response.status_code == 200:
            result = response.json()
            if 'candidates' in result and result['candidates']:
                content = result['candidates'][0]['content']['parts'][0]['text']
                return content.strip()

        # If API call failed, return None to trigger fallback
        return None

    except Exception as e:
        print(f"‚ö†Ô∏è Error generating AI content for {field}: {e}")
        return None


def generate_realistic_placeholder(field, context, json_data):
    """Generate realistic placeholder content"""
    section_name = context["section"]
    client_name = json_data.get("client_name", "East Hill Farm")

    # Pre-written realistic analyses for each section
    placeholder_templates = {
        "exec-summ_ai_summary": f"""**AI Analysis of Executive Summary:**

‚Ä¢ **Key Finding**: The executive summary effectively positions {client_name}'s adaptation plan within a 3¬∞C warming threshold framework, balancing immediate actions with long-term transformational needs.

‚Ä¢ **Strategic Alignment**: Governance structures and monitoring frameworks are well-defined, though quarterly review cycles could be enhanced with real-time climate data integration.

‚Ä¢ **Recommendation**: Establish a climate adaptation dashboard to track trigger points and adaptation progress against warming scenarios.

‚Ä¢ **Opportunity**: Explore collaborative adaptation initiatives with neighboring farms to share resources and knowledge.""",

        "intro_ai_summary": f"""**AI Analysis of Introduction:**

‚Ä¢ **Objective Assessment**: The three core objectives (regulatory compliance, actionable pathways, capacity building) create a comprehensive framework, though success metrics could be more quantifiable.

‚Ä¢ **Integration Potential**: Existing farm management systems provide excellent platforms for climate adaptation integration, minimizing implementation disruption.

‚Ä¢ **Recommendation**: Develop climate literacy training modules tailored to different staff roles (operational, managerial, strategic).

‚Ä¢ **Data Enhancement**: Incorporate local traditional ecological knowledge alongside scientific projections for culturally-relevant adaptation.""",

        "client-desc_ai_summary": f"""**AI Analysis of Client Description:**

‚Ä¢ **Site Vulnerability**: {client_name}'s elevation (190m) offers flood protection but increases temperature exposure and potential water scarcity risks.

‚Ä¢ **Current Impacts**: Documented issues (surface flooding, livestock heat stress) align with regional climate trends and require prioritized intervention.

‚Ä¢ **Recommendation**: Implement microclimate monitoring stations across different farm zones to identify localized risk variations.

‚Ä¢ **Transport Resilience**: Develop climate-resilient alternative route mapping with real-time weather integration.""",

        "hazards_ai_summary": f"""**AI Analysis of Climate Hazards:**

‚Ä¢ **Compound Risk**: Heatwaves followed by intense rainfall create compounded soil and infrastructure stress requiring integrated response planning.

‚Ä¢ **Temporal Pattern**: Hazard frequency shows accelerating trends, with extreme event return periods decreasing approximately 30% from historical baselines.

‚Ä¢ **Recommendation**: Develop hazard-specific adaptation "playbooks" with clear trigger points and response protocols.

‚Ä¢ **Monitoring Gap**: Real-time hazard monitoring systems could enhance early warning capabilities.""",

        "impact_ai_summary": f"""**AI Analysis of Impact Assessment:**

‚Ä¢ **Cascading Effects**: Primary livestock impacts trigger secondary supply chain and financial stability risks requiring systemic planning.

‚Ä¢ **Threshold Behavior**: Non-linear impacts emerge beyond 2¬∞C warming, necessitating preparatory investments in transformational adaptation.

‚Ä¢ **Recommendation**: Conduct vulnerability assessments across interconnected systems (soil-water-crop-livestock) to identify feedback loops.

‚Ä¢ **Data Integration**: Combine quantitative climate projections with qualitative local experience for robust impact modeling.""",

        "adaptive-capacity_ai_summary": f"""**AI Analysis of Adaptive Capacity:**

‚Ä¢ **Strengths Assessment**: Existing operational management provides solid foundation, though climate-specific decision support requires enhancement.

‚Ä¢ **Development Pathway**: Phased capacity building (literacy ‚Üí specialized skills ‚Üí advanced analytics) aligns well with risk progression.

‚Ä¢ **Recommendation**: Implement climate scenario training exercises for leadership teams to build decision-making confidence.

‚Ä¢ **Knowledge Management**: Establish formal climate adaptation learning systems to capture and share lessons.""",

        "planning_ai_summary": f"""**AI Analysis of Adaptation Planning:**

‚Ä¢ **Action Prioritization**: Risk-based action sequencing demonstrates strategic coherence, though benefit-cost analysis could be strengthened.

‚Ä¢ **Implementation Timing**: Lead times for complex adaptations appear adequate, but contingency planning for accelerated climate change is needed.

‚Ä¢ **Recommendation**: Develop climate adaptation KPIs linked to existing farm performance metrics for seamless integration.

‚Ä¢ **Innovation Opportunity**: Create adaptation innovation fund for testing emerging resilience technologies.""",

        "conclusion_ai_summary": f"""**AI Analysis of Conclusions:**

‚Ä¢ **Plan Coherence**: The adaptation plan successfully balances scientific rigor with practical implementability across all farm operations.

‚Ä¢ **Forward Pathway**: Next steps are clearly articulated though resource allocation details require further specification.

‚Ä¢ **Recommendation**: Establish climate adaptation reporting framework for transparent stakeholder communication.

‚Ä¢ **Continuous Improvement**: Implement annual climate science updates to maintain plan relevance and effectiveness."""
    }

    return placeholder_templates.get(field, f"""**AI Analysis of {section_name}:**

This analysis identifies key patterns, interdependencies, and strategic opportunities within the {section_name.lower()} content.

‚Ä¢ **Primary Insight**: [Key finding from the section]
‚Ä¢ **Strategic Implication**: [How this affects adaptation planning]
‚Ä¢ **Recommendation**: [Specific action for enhanced resilience]
‚Ä¢ **Monitoring Focus**: [Area requiring ongoing attention]""")


def add_ai_summary_sections(doc, json_data):
    """Add AI summary sections at the END of each specified section"""
    print("ü§ñ Adding AI summary sections to document...")

    # Define AI summary sections with their specific headings to search for
    ai_sections = [
        {
            "title": "AI Analysis",
            "json_field": "exec-summ_ai_summary",
            "heading_text": "Executive Summary",  # Exact heading text to find
            "section_type": "main_heading"
        },
        {
            "title": "AI Analysis",
            "json_field": "intro_ai_summary",
            "heading_text": "Introduction",
            "section_type": "main_heading"
        },
        {
            "title": "AI Analysis",
            "json_field": "client-desc_ai_summary",
            "heading_text": "East Hill Farm in a Changing Climate",
            "section_type": "main_heading"
        },
        {
            "title": "AI Analysis",
            "json_field": "hazards_ai_summary",
            "heading_text": "Climate Change Hazards",
            "section_type": "main_heading"
        },
        {
            "title": "AI Analysis",
            "json_field": "impact_ai_summary",
            "heading_text": "Impact Assessment",
            "section_type": "main_heading"
        },
        {
            "title": "AI Analysis",
            "json_field": "adaptive-capacity_ai_summary",
            "heading_text": "Adaptive capacity",
            "section_type": "main_heading"
        },
        {
            "title": "AI Analysis",
            "json_field": "planning_ai_summary",
            "heading_text": "Adaptation Planning",
            "section_type": "main_heading"
        },
        {
            "title": "AI Analysis",
            "json_field": "conclusion_ai_summary",
            "heading_text": "Conclusion",
            "section_type": "main_heading"
        }
    ]

    sections_added = 0

    for section in ai_sections:
        section_title = section["title"]
        json_field = section["json_field"]
        heading_text = section["heading_text"]

        # Get the AI summary content from JSON
        ai_content = json_data.get(json_field, "")

        # Skip if no content
        if not ai_content or ai_content.strip() == "":
            print(f"‚ö†Ô∏è No AI content for {json_field}, skipping section")
            continue

        print(f"üìù Looking for heading: '{heading_text}' to add AI analysis")

        # Find the exact heading in the document
        heading_index = -1

        for i, paragraph in enumerate(doc.paragraphs):
            text = paragraph.text.strip()

            # Exact match for the heading
            if heading_text.lower() in text.lower() and len(text) < 150:
                # Additional check to ensure it's a heading, not regular text
                is_likely_heading = (
                        paragraph.style.name.startswith('Heading') or
                        text.isupper() or
                        text == heading_text or
                        (len(text.split()) <= 8 and text[0].isupper())
                )

                if is_likely_heading:
                    heading_index = i
                    print(f"‚úÖ Found heading '{heading_text}' at paragraph {i}")
                    break

        if heading_index == -1:
            print(f"‚ö†Ô∏è Could not find heading '{heading_text}' in document")
            continue

        # Find the END of this section (right before next heading of same or higher level)
        insertion_index = find_end_of_section_from_heading(doc, heading_index)

        if insertion_index and insertion_index > heading_index:
            try:
                print(f"üìå Inserting AI analysis at paragraph {insertion_index} (end of '{heading_text}' section)")

                # Add separator line before AI section
                separator = doc.paragraphs[insertion_index].insert_paragraph_before("‚îÄ" * 70)
                separator.alignment = WD_ALIGN_PARAGRAPH.CENTER
                if separator.runs:
                    separator.runs[0].font.color.rgb = RGBColor(180, 180, 180)
                    separator.runs[0].font.size = Pt(9)

                # Add AI section heading
                ai_heading = doc.paragraphs[insertion_index].insert_paragraph_before(section_title)
                ai_heading.alignment = WD_ALIGN_PARAGRAPH.LEFT
                if ai_heading.runs:
                    ai_heading.runs[0].bold = True
                    ai_heading.runs[0].font.size = Pt(11)
                    ai_heading.runs[0].font.color.rgb = RGBColor(0, 51, 102)
                    ai_heading.runs[0].font.name = "Calibri"

                # Add spacing after heading
                ai_heading.paragraph_format.space_after = Pt(6)

                # Add the AI content
                # Split content into paragraphs if it has newlines
                content_lines = ai_content.strip().split('\n')

                for line_num, line in enumerate(content_lines):
                    if line.strip():
                        content_para = doc.paragraphs[insertion_index].insert_paragraph_before(line.strip())
                        content_para.style = "Normal"
                        content_para.alignment = WD_ALIGN_PARAGRAPH.LEFT

                        # Format the content
                        if content_para.runs:
                            for run in content_para.runs:
                                run.font.size = Pt(10)
                                run.font.name = "Calibri"
                                # Make bullet points stand out
                                if line.strip().startswith(('‚Ä¢', '-', '*', '1.', '2.', '3.', '4.', '5.')):
                                    run.bold = True
                                    run.font.color.rgb = RGBColor(0, 0, 0)

                        # Add spacing between paragraphs
                        if line_num < len(content_lines) - 1:
                            content_para.paragraph_format.space_after = Pt(3)

                # Add final spacing after AI section
                final_spacing = doc.paragraphs[insertion_index].insert_paragraph_before()
                final_spacing.paragraph_format.space_after = Pt(12)

                sections_added += 1
                print(f"‚úÖ Successfully added AI analysis at end of '{heading_text}' section")

            except Exception as e:
                print(f"‚ö†Ô∏è Error adding AI section for '{heading_text}': {e}")
                import traceback
                traceback.print_exc()
        else:
            print(f"‚ö†Ô∏è Could not find end of section for '{heading_text}'")

    print(f"üìä Total AI summary sections added: {sections_added}")
    return sections_added > 0


def find_end_of_section_from_heading(doc, heading_index):
    """Find where a section ends starting from a heading"""
    if heading_index >= len(doc.paragraphs) - 1:
        return len(doc.paragraphs) - 1

    # Get the heading level if possible
    heading_level = 1
    heading_paragraph = doc.paragraphs[heading_index]
    if heading_paragraph.style.name.startswith('Heading'):
        try:
            heading_level = int(heading_paragraph.style.name.replace('Heading ', ''))
        except:
            heading_level = 1

    # Start searching from after the heading
    for i in range(heading_index + 1, len(doc.paragraphs)):
        current_para = doc.paragraphs[i]
        current_text = current_para.text.strip()

        # Skip empty paragraphs
        if not current_text:
            continue

        # Check if we've reached another heading
        if current_para.style.name.startswith('Heading'):
            try:
                current_level = int(current_para.style.name.replace('Heading ', ''))
                # If this is a heading of same or higher level, we've reached end of section
                if current_level <= heading_level:
                    return i
            except:
                # If can't determine level, check if it looks like a new section
                if len(current_text.split()) <= 8 and current_text[0].isupper():
                    return i

        # Check for obvious section boundaries
        section_boundaries = [
            "Table", "Figure", "Appendix", "References", "Bibliography",
            "Executive Summary", "Introduction", "Conclusion", "Recommendations",
            "Acknowledgements", "Glossary", "Abbreviations"
        ]

        for boundary in section_boundaries:
            if boundary in current_text and len(current_text) < 100:
                return i

        # Check for numbered sections (e.g., "1.", "2.", "3.")
        if re.match(r'^\d+\.\s+[A-Z]', current_text) and len(current_text.split()) <= 10:
            return i

    # If we reach the end of document
    return len(doc.paragraphs)


# Also update the find_end_of_section function to be more robust
def find_end_of_section(doc, section_keyword):
    """Find the END of a specific section"""
    print(f"üîç Finding end of section: {section_keyword}")

    # First find the heading
    heading_index = -1
    for i, paragraph in enumerate(doc.paragraphs):
        text = paragraph.text.strip()
        if section_keyword.lower() in text.lower():
            # Check if it's likely a heading
            if (paragraph.style.name.startswith('Heading') or
                    text.isupper() or
                    text == section_keyword or
                    len(text.split()) <= 8):
                heading_index = i
                break

    if heading_index == -1:
        print(f"‚ö†Ô∏è Could not find '{section_keyword}' heading")
        return None

    return find_end_of_section_from_heading(doc, heading_index)


def find_insertion_point_after_section(doc, start_index):
    """Find where to insert content after a section ends"""
    for i in range(start_index + 1, len(doc.paragraphs)):
        paragraph = doc.paragraphs[i]
        text = paragraph.text.strip()

        # Check if this is another heading (end of current section)
        if paragraph.style.name.startswith('Heading') and text:
            return i

        # Check for obvious section endings
        if len(text) < 100 and any(keyword in text for keyword in [
            "Table", "Figure", "Appendix", "References", "Executive Summary",
            "Introduction", "Conclusion", "Adaptation", "Monitoring"
        ]):
            return i

    # If no next heading found, insert near the end
    return min(start_index + 10, len(doc.paragraphs) - 1)



# ---------------- ROUTES ----------------
@app.route("/")
def index():
    return render_template("upload.html")


# Progress tracking for background tasks
processing_tasks = {}

def update_progress(task_id, percent, message, status="processing"):
    """Update the progress of a background task"""
    if task_id in processing_tasks:
        processing_tasks[task_id]["percent"] = percent
        processing_tasks[task_id]["message"] = message
        processing_tasks[task_id]["status"] = status
        print(f"üîÑ Task {task_id}: {percent}% - {message}")

def generate_report_thread(task_id, config):
    """Background worker to generate the report"""
    try:
        update_progress(task_id, 5, "Initializing report generation...")
        
        # Extract config
        template_path = config.get('template_path')
        json_data = config.get('json_data', {})
        image_paths = config.get('image_paths', [])
        excel_paths = config.get('excel_paths', [])
        client_logo_path = config.get('client_logo_path')
        climate_logo_path = config.get('climate_logo_path')
        form_prompts = config.get('form_prompts', {})
        prompt_images = config.get('prompt_images', {})
        custom_sections = config.get('custom_sections', [])
        saved_files = config.get('saved_files', [])
        extract_mural = config.get('extract_mural', False)
        
        # Mural Extraction
        mural_data = None
        if extract_mural:
            update_progress(task_id, 10, "Extracting Mural data...")
            try:
                # Dynamically import and run the extraction script
                import importlib.util
                import sys
                
                print("üöÄ Attempting to run get_mural_data_to_excel.py...")
                spec = importlib.util.spec_from_file_location("mural_extractor", "get_mural_data_to_excel.py")
                if spec and spec.loader:
                    mural_module = importlib.util.module_from_spec(spec)
                    sys.modules["mural_extractor"] = mural_module
                    spec.loader.exec_module(mural_module)
                    
                    if hasattr(mural_module, 'main'):
                        print("‚ö° Running Mural extraction main()...")
                        mural_data = mural_module.main()
                        print("‚úÖ Mural extraction completion signal received")
                    else:
                        print("‚ö†Ô∏è Mural script has no main() function")
                else:
                     print("‚ö†Ô∏è Could not load get_mural_data_to_excel.py")
                     
            except Exception as e:
                print(f"‚ö†Ô∏è Mural extraction failed: {e}")
                # Fallback to existing file handled below
                pass

        # Update JSON with form data
        update_progress(task_id, 20, "Analyzing data with AI...")
        # (Rest of AI analysis skip...)
        # Fallback: Try to load existing Mural data if not extracted in this run
        if not mural_data and os.path.exists("mural_content_for_report.json"):
            print(" Using existing mural_content_for_report.json")
            try:
                with open("mural_content_for_report.json", 'r', encoding='utf-8') as f:
                    mural_data = json.load(f)
            except Exception as e:
                print(f"Failed to load existing Mural data: {e}")
        
        # JSON parsing ensure V4 structure
        update_progress(task_id, 15, "Processing data structure...")
        v4_parsed_data = parse_json_v4_data(json_data)
        json_data.update(v4_parsed_data)

        # Gemini Analysis
        if saved_files and AVAILABLE_GEMINI_MODEL:
            update_progress(task_id, 20, "Analyzing files with AI...")
            try:
                send_to_gemini(saved_files)
            except Exception as e:
                print(f"Gemini error: {e}")

        # Create report - Template
        update_progress(task_id, 25, "Loading template...")
        try:
            doc = Document(template_path)
            fix_executive_summary_headings(doc)
        except Exception as e:
            doc = Document()
            doc.add_heading("Climate Risk Assessment Report", 0)
            update_progress(task_id, 25, "Using default template (load failed)")

        # Steps 0-1
        update_progress(task_id, 30, "Structuring document...")
        update_template_for_v4_structure(doc, json_data)
        fix_executive_summary_headings(doc)
        update_toc_section_titles(doc, json_data)
        ensure_placeholders_in_doc(doc)
        update_template_for_v4_structure(doc, json_data)

        # Step 2: Logos
        update_progress(task_id, 35, "Inserting logos...")
        replace_logo_placeholders(doc, client_logo_path, climate_logo_path)

        # Step 3: Excel
        if excel_paths:
            update_progress(task_id, 40, "Processing Excel tables...")
            for i, excel_path in enumerate(excel_paths):
                process_table_1_special(doc, excel_path)
                process_table_3_special(doc, excel_path)
                process_table_4_special(doc, excel_path)
                process_table_5_special(doc, excel_path)
                process_table_7_special(doc, excel_path)
                process_table_A2_special(doc, excel_path)
                insert_excel_table_data(doc, excel_path)

        # Step 4: Placeholders
        remove_specific_placeholders(doc)
        
        # Step 4b: Specific Figure Replacements (User Request)
        replace_figure_2_placeholder(doc)
        replace_figure_1_placeholder(doc)

        # Step 5: Images
        if image_paths:
            update_progress(task_id, 50, "Placing images...")
            figure_mapping = map_images_to_figures(image_paths)
            
            # Remove Figure 1 and Figure 2 from generic mapping
            # Figure 2 is handled by specific function above
            # Figure 1 is requested to be removed
            if figure_mapping:
                if 2 in figure_mapping:
                   del figure_mapping[2]
                if 1 in figure_mapping:
                   del figure_mapping[1]
                
                insert_images_by_figure_number_flexible(doc, figure_mapping)

        # Step 6-8: Formatting & AI Content
        update_progress(task_id, 60, "Generating AI narrative...")
        fix_adaptation_plan_section(doc)
        integrate_bespoke_content_with_prompts(doc, json_data, form_prompts)
        clean_executive_summary(doc)
        clean_executive_summary_duplicates(doc)
        quick_fix_executive_summary(doc)

        # Step 9-14: Polish
        update_progress(task_id, 70, "Finalizing formatting...")
        verify_table_formatting(doc)
        create_proper_toc_sections(doc, json_data)
        remove_ai_analysis_sections(doc)
        clean_up_generated_report(doc, json_data)
        move_executive_summary_to_page_four(doc)
        fix_title_page_placeholders(doc, json_data)

        # Step 15: Apply User Headings (Dynamic)
        heading_replacements = config.get('heading_replacements', {})
        if heading_replacements:
            update_progress(task_id, 72, "Applying custom headings...")
            for para in doc.paragraphs:
                if para.style.name.startswith('Heading'):
                    text = para.text.strip()
                    # Check exact match or containing match if strict enough? 
                    # Exact match is safer to avoid partial replacements in sentences
                    if text in heading_replacements:
                        print(f"üîÑ Replacing heading: '{text}' -> '{heading_replacements[text]}'")
                        para.text = heading_replacements[text]


        # Step 15: Mural
        update_progress(task_id, 75, "Inserting Mural workshop data...")
        if mural_data:
            json_data['mural_data'] = mural_data
            insert_mural_content_into_document(doc)
        else:
            insert_minimal_fallback_at_placeholders(doc)

        # Step 15.5: Prompt Images
        if prompt_images:
            update_progress(task_id, 80, "Inserting section images...")
            toc_end_index = find_end_of_toc_section(doc)
            if toc_end_index:
                section_headings = get_section_headings(json_data)
                for section_key, image_data in prompt_images.items():
                    possible_headings = section_headings.get(section_key, [])
                    for heading_text in possible_headings:
                        section_index = find_section_in_content(doc, heading_text, toc_end_index)
                        if section_index is not None:
                            try:
                                insert_image_at_section_end(doc, section_index, image_data, json_data)
                                break
                            except: pass
            else:
                 insert_prompt_images_at_sections_skip_toc(doc, prompt_images, json_data)

        # Step 16: Custom sections
        if custom_sections:
            update_progress(task_id, 85, "Adding custom sections...")
            insert_custom_sections(doc, custom_sections, json_data)

        # Step 16b: Insert Hardcoded "11 Conclusion and Next Steps" (User Request)
        # We process this BEFORE the dynamic custom sections so they appear as Section 12+
        update_progress(task_id, 86, "Adding Conclusion section...")
        
        # Find where to insert (before Appendices/References)
        concl_insertion_index = len(doc.paragraphs) - 1
        found_concl_target = False
        target_sections = ["appendix", "appendices", "references", "bibliography"]
        
        for i, p in enumerate(doc.paragraphs):
            text = p.text.strip().lower()
            is_target = any(target in text for target in target_sections)
            if is_target:
                if (p.style.name.startswith("Heading") or 
                    (p.runs and p.runs[0].bold and len(text) < 50) or 
                    text in target_sections):
                    concl_insertion_index = max(0, i)
                    found_concl_target = True
                    break
        
        # Check if "Conclusion" already exists to avoid duplication
        conclusion_exists = False
        for p in doc.paragraphs:
            if "11 conclusion and next steps" in p.text.lower():
                conclusion_exists = True
                break
                
        if not conclusion_exists:
            print("‚ú® Inserting specific Conclusion and Next Steps section")
            conclusion_content = [
                ("Conclusion and Next Steps", "Heading 1"),
                ("Ministry of Rural Development has significant current and developing vulnerabilities to climate change.  Measures have been identified to retain a viable maritime development operations enterprise to 3oC global warming.  Beyond that level of global warming, the viability of a cattle enterprise compared to other options will need to be considered.  ", "Normal"),
                ("To efficiently retain its viability requires a shift from reactive crisis management to anticipatory, integrated planning. This Plan provides the basis for that shift. By identifying priority risks and outlining proportionate responses, it enables informed decisions that reduce climate-related disruptions while supporting compliance and long-term business continuity.", "Normal"),
                ("This adaptation plan provides a critical framework for the Ministry of Rural Development to proactively address the impacts of climate change on rural infrastructure. It highlights the urgent need to embed adaptation considerations directly into all infrastructure planning processes, assign clear accountability for implementation across all levels, and establish robust monitoring and evaluation mechanisms to track progress and ensure effectiveness. By adopting these recommendations, the Ministry will strengthen the resilience of vital rural assets and safeguard the well-being of communities.", "Normal"),
                ("", "Normal"),
                ("The path forward requires immediate and decisive action to embed climate adaptation into the Ministry's core operations. The immediate next steps and priorities include:", "Normal"),
                ("‚Ä¢ Endorsing this adaptation plan to formally adopt its recommendations", "List Bullet"),
                ("‚Ä¢ Developing a comprehensive implementation schedule detailing specific actions, responsibilities, and timelines", "List Bullet"),
                ("‚Ä¢ Preparing for the execution of the first set of adaptation actions in the medium-term, ensuring a swift transition from strategy to tangible impact", "List Bullet"),
                ("", "Normal"),
                ("For long-term success and sustainability, the Ministry of Rural Development must fully integrate adaptation into its core operations and strategic partnerships. This comprehensive integration will ensure that adaptation becomes an intrinsic part of the Ministry's mandate, leading to enduring benefits for rural communities across the nation. Key long-term considerations include:", "Normal"),
                ("‚Ä¢ Aligning all adaptation efforts with the broader National Adaptation Plan cycles", "List Bullet"),
                ("‚Ä¢ Integrating adaptation measures within existing ministry management systems", "List Bullet"),
                ("‚Ä¢ Coordinating continuously with all rural development partners to leverage resources and share knowledge", "List Bullet"),
                ("Next steps include:", "Normal"),
                ("‚Ä¢ Embedding adaptation into site-level investment plans, and capital projects.", "List Bullet"),
                ("‚Ä¢ Assigning internal accountability for implementation and review.", "List Bullet"),
                ("‚Ä¢ Establishing monitoring and evaluation processes linked to performance metrics.", "List Bullet"),
                ("‚Ä¢ Coordinating with supply chain partners, insurers, and local authorities to align risk-controls and adaptation actions.", "List Bullet"),
                ("This Plan is a living document, designed to evolve alongside climate science, operational needs, and regulatory expectations.", "Normal"),
                ("An initial implementation review will be conducted within 12 months, supported by annual updates to reflect new data, changing baselines, and stakeholder feedback. This review cycle can be in line with the EA Permitting cycle, so enabling demonstration that the plan is embedded within the company‚Äôs management systems. Future updates will explicitly document optimal resource requirements for a proportionate adaptation response, and progress in making those resources available. It will also highlight the assumptions behind those judgements.", "Normal")
            ]
            
            target_para = doc.paragraphs[concl_insertion_index]
            for text, style in conclusion_content:
                # Using target_para object instead of index to maintain sequence
                new_p = target_para.insert_paragraph_before(text)
                try: new_p.style = style
                except: new_p.style = "Normal"
                
                if style == "Heading 1" and new_p.runs:
                    new_p.runs[0].bold = True
                    new_p.runs[0].font.size = Pt(16)
                    new_p.runs[0].font.color.rgb = RGBColor(0, 51, 102)
            
            target_para.insert_paragraph_before()

        # Step 16c: Process DYNAMIC Custom Sections (New Feature)
        dynamic_custom_headings = config.get('dynamic_custom_headings', [])
        if dynamic_custom_headings:
            update_progress(task_id, 88, "Generating additional custom sections...")
            
            # Recalculate target para for dynamic sections
            target_para = doc.paragraphs[len(doc.paragraphs)-1]
            found_target = False
            for i, p in enumerate(doc.paragraphs):
                text = p.text.strip().lower()
                is_target = any(target in text for target in target_sections)
                if is_target:
                    if (p.style.name.startswith("Heading") or (p.runs and p.runs[0].bold and len(text) < 50) or text in target_sections):
                        target_para = p
                        found_target = True
                        break
            
            if found_target:
                target_para.insert_paragraph_before().add_run().add_break(WD_BREAK.PAGE)
            
            dynamic_custom_prompts = config.get('dynamic_custom_prompts', [])
            dynamic_custom_images = config.get('dynamic_custom_images', {})
            
            for idx, heading in enumerate(dynamic_custom_headings):
                prompt = dynamic_custom_prompts[idx] if idx < len(dynamic_custom_prompts) else ""
                if heading:
                    # HEADING
                    p = target_para.insert_paragraph_before(heading)
                    p.style = "Heading 1"
                    
                    # CONTENT
                    try:
                        # Correct function name: generate_content_with_gemini_with_retry
                        print(f"ü§ñ Generating AI content for dynamic section: {heading}")
                        content = generate_content_with_gemini_with_retry(f"Write a section about '{heading}'. Instructions: {prompt}")
                        if content:
                            for line in content.split('\n'):
                                if line.strip():
                                    content_p = target_para.insert_paragraph_before(line.strip())
                                    content_p.style = "Normal"
                    except Exception as e:
                         print(f"‚ùå Error generating content for {heading}: {e}")
                         target_para.insert_paragraph_before(f"[Error generating content for {heading}: {str(e)}]")
     
                    # IMAGE
                    img_path = dynamic_custom_images.get(str(idx+1))
                    if img_path and os.path.exists(img_path):
                        img_para = target_para.insert_paragraph_before()
                        img_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
                        try:
                            img_para.add_run().add_picture(img_path, width=Inches(5.0))
                        except Exception as e:
                            print(f"‚ùå Error adding custom image: {e}")
                            
                    # SPACING
                    target_para.insert_paragraph_before()

        # Step 17-19: Cleanup
        update_progress(task_id, 90, "Cleaning up document...")
        remove_unwanted_ai_analysis(doc)
        remove_figure_placeholders(doc)
        remove_figure_placeholders_only_after_processing(doc)
        clean_up_toc_formatting(doc)
        debug_document_structure(doc)

        # Save
        update_progress(task_id, 95, "Saving and uploading...")
        out_name = f"Climate_Report_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}.docx"
        out_path = os.path.join(OUTPUT_FOLDER, out_name)
        doc.save(out_path)

        # Dropbox
        if dbx:
             dropbox_path = f"/Apps/FlaskReport/{out_name}"
             upload_to_dropbox(out_path, dropbox_path)

        # Complete
        processing_tasks[task_id]["result_file"] = out_name
        update_progress(task_id, 100, "Done!", status="completed")
        
    except Exception as e:
        print(f"‚ùå Error in background worker: {e}")
        traceback.print_exc()
        update_progress(task_id, 0, f"Error: {str(e)}", status="error")

@app.route("/process", methods=["POST"])
def process():
    task_id = str(uuid.uuid4())
    processing_tasks[task_id] = {
        "percent": 0,
        "message": "Starting upload...",
        "status": "processing"
    }

    try:
        saved_files = []
        
        # Template
        template_path = TEMPLATE_DEFAULT
        if "docx_file" in request.files and request.files["docx_file"].filename:
             t_file = request.files["docx_file"]
             if allowed_file(t_file.filename):
                 template_path = save_uploaded_file(t_file, UPLOAD_FOLDER)
                 saved_files.append(template_path)
        
        # JSON
        json_path = None
        json_data = get_default_json_data()
        
        if "json_file" in request.files and request.files["json_file"].filename:
             j_file = request.files["json_file"]
             if allowed_file(j_file.filename):
                 json_path = save_uploaded_file(j_file, UPLOAD_FOLDER)
                 saved_files.append(json_path)
                 loaded = load_json_file(json_path)
                 json_data.update(loaded)

        # Images
        image_paths = []
        if "image_files" in request.files:
            for f in request.files.getlist("image_files"):
                if f and allowed_file(f.filename):
                    p = save_uploaded_file(f, UPLOAD_FOLDER)
                    image_paths.append(p)
                    saved_files.append(p)

        # Excel
        excel_paths = []
        if "excel_files" in request.files:
            for f in request.files.getlist("excel_files"):
                if f and allowed_file(f.filename):
                    p = save_uploaded_file(f, UPLOAD_FOLDER)
                    excel_paths.append(p)
                    saved_files.append(p)

        # Logos
        client_logo_path = None
        if "client_logo_file" in request.files and request.files["client_logo_file"].filename:
            f = request.files["client_logo_file"]
            if allowed_file(f.filename):
                client_logo_path = save_uploaded_file(f, UPLOAD_FOLDER)
                saved_files.append(client_logo_path)
                
        climate_logo_path = None
        if "climate_logo_file" in request.files and request.files["climate_logo_file"].filename:
            f = request.files["climate_logo_file"]
            if allowed_file(f.filename):
                climate_logo_path = save_uploaded_file(f, UPLOAD_FOLDER)
                saved_files.append(climate_logo_path)

        # Prompt Images
        prompt_images = process_prompt_images(request)

        # Custom Sections
        custom_sections = process_custom_sections(request.form, request.files)
        
        # Dynamic Custom Sections (New Feature)
        # Debugging form data keys
        print("====== FORM DATA KEYS ======")
        for key in request.form.keys():
            print(f"  {key}")
        print("============================")
        
        dynamic_custom_headings = request.form.getlist('custom_headings[]')
        if not dynamic_custom_headings:
            # Try without brackets just in case
            dynamic_custom_headings = request.form.getlist('custom_headings')
            
        dynamic_custom_prompts = request.form.getlist('custom_prompts[]')
        if not dynamic_custom_prompts:
            dynamic_custom_prompts = request.form.getlist('custom_prompts')
            
        print(f"üì• Received {len(dynamic_custom_headings)} dynamic custom headings: {dynamic_custom_headings}")
        
        # Process dynamic section images
        # They are named custom_images_1, custom_images_2 etc based on our JS
        dynamic_custom_images = {}
        # We need to find how many we have created or iterate through request.files keys
        for key in request.files:
            if key.startswith('custom_images_'):
                # Extract the index/ID
                idx = key.replace('custom_images_', '')
                f = request.files[key]
                if f and allowed_file(f.filename):
                    p = save_uploaded_file(f, UPLOAD_FOLDER)
                    dynamic_custom_images[idx] = p
                    saved_files.append(p)
        
        # Form Data inputs
        form_prompts = {
            "exec_summary_prompt": request.form.get("exec_summary_prompt", ""),
            "intro_prompt": request.form.get("intro_prompt", ""),
            "site_context_prompt": request.form.get("site_context_prompt", ""),
            "custom_prompt": request.form.get("custom_prompt", ""),
            'include_agricultural_focus': request.form.get('include_agricultural_focus'),
            'include_regulatory_focus': request.form.get('include_regulatory_focus'),
            'include_practical_examples': request.form.get('include_practical_examples'),
            'include_local_context': request.form.get('include_local_context')
        }

        # Heading Replacements
        heading_replacements = {}
        if REPORT_SETTINGS and "ui_defaults" in REPORT_SETTINGS:
            for p in REPORT_SETTINGS["ui_defaults"].get("section_prompts", []):
                # ID is index 0, Default Heading is index 5
                if len(p) > 5:
                    p_id = p[0]
                    default_heading = p[5]
                    user_heading = request.form.get(f"heading_{p_id}")
                    
                    if user_heading and user_heading.strip() and user_heading.strip() != default_heading:
                        heading_replacements[default_heading] = user_heading.strip()
        
        # Mural
        extract_mural = request.form.get("extract_mural") == "true" or request.form.get("extract_mural") == "on"

        # Config
        config = {
            'template_path': template_path,
            'json_data': json_data,
            'image_paths': image_paths,
            'excel_paths': excel_paths,
            'client_logo_path': client_logo_path,
            'climate_logo_path': climate_logo_path,
            'form_prompts': form_prompts,
            'prompt_images': prompt_images,
            'extract_mural': extract_mural,
            'custom_sections': custom_sections,
            'dynamic_custom_headings': dynamic_custom_headings,
            'dynamic_custom_prompts': dynamic_custom_prompts,
            'dynamic_custom_images': dynamic_custom_images,
            'saved_files': saved_files,
            'heading_replacements': heading_replacements
        }
        
        Thread(target=generate_report_thread, args=(task_id, config)).start()
        
        return jsonify({'task_id': task_id})

    except Exception as e:
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


# ===== MURAL ROUTES =====

@app.route("/extract-mural")
def extract_mural_only():
    """Extract Mural data separately without generating a report"""
    print("\n" + "=" * 60)
    print("üöÄ EXTRACTING MURAL DATA (STANDALONE)")
    print("=" * 60)

    try:
        # Import and run the Mural extraction script
        import subprocess
        import sys
        import json
        import time

        print("üîß Running Mural extraction script...")

        # Run the script - capture output but don't wait indefinitely
        process = subprocess.Popen(
            [sys.executable, "get_mural_data_to_excel.py"],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            encoding='utf-8'
        )

        # Wait with timeout
        try:
            stdout, stderr = process.communicate(timeout=180)  # 3 minute timeout

            if process.returncode == 0:
                print("‚úÖ Mural extraction completed successfully!")

                # Check if JSON file was created
                if os.path.exists("mural_content_for_report.json"):
                    with open("mural_content_for_report.json", 'r', encoding='utf-8') as f:
                        data = json.load(f)

                    summary = f"""
                    üìä Mural Data Extracted Successfully:

                    ‚Ä¢ Table 1 - Risks from climate change:
                      - Column 1 (Yellow): {len(data['table1']['columns'][0]['content'])} items
                      - Column 2 (Dark Red): {len(data['table1']['columns'][1]['content'])} items
                      - Column 3 (Orange): {len(data['table1']['columns'][2]['content'])} items

                    ‚Ä¢ Table 2 - RAPA (Green): {len(data['table2']['content'])} items

                    ‚úÖ Data saved to: mural_content_for_report.json
                    """

                    flash("‚úÖ Mural data extracted successfully!")

                    # Return a simple success page (you can create a template for this)
                    return f"""
                    <!DOCTYPE html>
                    <html>
                    <head>
                        <title>‚úÖ Mural Extraction Successful</title>
                        <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
                        <style>
                            body {{ padding: 20px; background-color: #f8f9fa; }}
                            .container {{ max-width: 800px; margin: 0 auto; }}
                        </style>
                    </head>
                    <body>
                        <div class="container">
                            <div class="alert alert-success">
                                <h4>‚úÖ Mural Data Extracted Successfully!</h4>
                                <pre style="white-space: pre-wrap;">{summary}</pre>
                            </div>
                            <div class="d-flex justify-content-between">
                                <a href="/" class="btn btn-primary">‚Üê Back to Report Generator</a>
                                <a href="/" class="btn btn-outline-success">Generate Report with Mural Data</a>
                            </div>
                        </div>
                    </body>
                    </html>
                    """
                else:
                    flash("‚ö†Ô∏è Mural extraction ran but no JSON file was created")
                    return """
                    <!DOCTYPE html>
                    <html>
                    <head>
                        <title>‚ö†Ô∏è Mural Extraction Issue</title>
                        <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
                    </head>
                    <body>
                        <div class="container mt-5">
                            <div class="alert alert-warning">
                                <h4>‚ö†Ô∏è Mural Extraction Issue</h4>
                                <p>Script ran but no JSON output file was created.</p>
                            </div>
                            <a href="/" class="btn btn-primary">‚Üê Back to Report Generator</a>
                        </div>
                    </body>
                    </html>
                    """
            else:
                error_msg = f"Mural extraction failed with code {process.returncode}"
                if stderr:
                    error_msg += f"\nError: {stderr[:500]}"

                flash("‚ùå Mural extraction failed")
                return f"""
                <!DOCTYPE html>
                <html>
                <head>
                    <title>‚ùå Mural Extraction Failed</title>
                    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
                </head>
                <body>
                    <div class="container mt-5">
                        <div class="alert alert-danger">
                            <h4>‚ùå Mural Extraction Failed</h4>
                            <pre style="white-space: pre-wrap;">{error_msg}</pre>
                        </div>
                        <a href="/" class="btn btn-primary">‚Üê Back to Report Generator</a>
                    </div>
                </body>
                </html>
                """

        except subprocess.TimeoutExpired:
            process.kill()
            flash("‚è∞ Mural extraction timed out (took too long)")
            return """
            <!DOCTYPE html>
            <html>
            <head>
                <title>‚è∞ Mural Extraction Timeout</title>
                <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
            </head>
            <body>
                <div class="container mt-5">
                    <div class="alert alert-warning">
                        <h4>‚è∞ Mural Extraction Timeout</h4>
                        <p>Extraction timed out after 3 minutes. Please try again.</p>
                    </div>
                    <a href="/" class="btn btn-primary">‚Üê Back to Report Generator</a>
                </div>
            </body>
            </html>
            """

    except Exception as e:
        error_msg = f"Error running Mural extraction: {str(e)}"
        print(f"‚ùå {error_msg}")
        import traceback
        traceback.print_exc()

        flash("‚ùå Error extracting Mural data")
        return f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>‚ùå Mural Extraction Error</title>
            <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
        </head>
        <body>
            <div class="container mt-5">
                <div class="alert alert-danger">
                    <h4>‚ùå Mural Extraction Error</h4>
                    <p>{error_msg}</p>
                </div>
                <a href="/" class="btn btn-primary">‚Üê Back to Report Generator</a>
            </div>
        </body>
        </html>
        """


@app.route("/check-mural-data")
def check_mural_data():
    """Check if Mural data is already extracted"""
    try:
        if os.path.exists("mural_content_for_report.json"):
            with open("mural_content_for_report.json", 'r', encoding='utf-8') as f:
                data = json.load(f)

            # Count items
            table1_items = sum(len(col['content']) for col in data['table1']['columns'])
            
            # Table 2 items (handle both old and new structure)
            if 'content' in data['table2']:
                table2_items = len(data['table2']['content'])
            else:
                # New structure with adaptation_actions and assumptions
                actions = len(data['table2'].get('adaptation_actions', {}).get('content', []))
                assumptions = len(data['table2'].get('assumptions', {}).get('content', []))
                table2_items = actions + assumptions

            return {
                'exists': True,
                'table1_items': table1_items,
                'table2_items': table2_items,
                'timestamp': datetime.fromtimestamp(os.path.getmtime("mural_content_for_report.json")).strftime(
                    "%Y-%m-%d %H:%M:%S")
            }
        else:
            return {'exists': False}
    except Exception as e:
        return {'exists': False, 'error': str(e)}

@app.route("/download/<filename>")
def download_file(filename):
    path = os.path.join(OUTPUT_FOLDER, filename)
    if not os.path.exists(path):
        flash("‚ùå File not found.")
        return redirect(url_for("index"))
    return send_file(path, as_attachment=True, download_name=filename)


@app.route("/clean")
def clean_uploads():
    """Clean uploaded files"""
    import shutil
    if os.path.exists(UPLOAD_FOLDER):
        shutil.rmtree(UPLOAD_FOLDER)
        os.makedirs(UPLOAD_FOLDER)
    flash("‚úÖ Uploaded files cleaned")
    return redirect(url_for("index"))


@app.route("/download_report")
def download_report():
    """Download the most recently generated report"""
    try:
        # Get all files in output folder
        files = [os.path.join(OUTPUT_FOLDER, f) for f in os.listdir(OUTPUT_FOLDER) 
                if f.endswith('.docx') and os.path.isfile(os.path.join(OUTPUT_FOLDER, f))]
        
        if not files:
            flash("‚ö†Ô∏è No report found to download")
            return redirect(url_for("index"))
            
        # Sort by modification time (newest first)
        latest_file = max(files, key=os.path.getmtime)
        filename = os.path.basename(latest_file)
        
        print(f"‚¨áÔ∏è Downloading: {filename}")
        return send_file(latest_file, as_attachment=True, download_name=filename)
        
    except Exception as e:
        print(f"‚ùå Error downloading report: {e}")
        flash(f"‚ö†Ô∏è Error downloading report: {str(e)}")
        return redirect(url_for("index"))


def replace_figure_2_placeholder(doc):
    """Specific replacement for Figure 2 placeholder requested by user"""
    print("üñºÔ∏è Checking for Figure 2 placeholder...")
    
    placeholder_text = "[[Figure-2_Climate-Records-Nov-2025_Met-Fiji]]"
    image_filename = "Figure-2_Climate-Records-Nov-2025_Met-Fiji.png"
    caption_text = 'Figure 2: Change in "tropical nights" (over 20¬∫C) for Republic of Fiji (Source Met Office Local Authority Climate Service 2025)'
    
    # Check if image exists
    image_path = os.path.join(UPLOAD_FOLDER, image_filename)
    if not os.path.exists(image_path):
        print(f"‚ö†Ô∏è Figure 2 image not found: {image_path}")
        return False
        
    found = False
    for i, paragraph in enumerate(doc.paragraphs):
        if placeholder_text in paragraph.text:
            print(f"‚úÖ Found Figure 2 placeholder at paragraph {i}")
            
            # Clear paragraph content
            paragraph.text = ""
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            
            # Insert image
            run = paragraph.add_run()
            try:
                run.add_picture(image_path, width=Inches(6.0))
                print(f"‚úÖ Inserted Figure 2 image")
            except Exception as e:
                print(f"‚ùå Error inserting Figure 2 image: {e}")
                
            # Add caption
            # Check if the NEXT paragraph is already the caption
            next_para_is_caption = False
            if i + 1 < len(doc.paragraphs):
                next_para = doc.paragraphs[i+1]
                if "Figure 2" in next_para.text:
                    print(f"‚úÖ Found existing Figure 2 caption, updating it")
                    caption_para = next_para
                    caption_para.text = caption_text
                    next_para_is_caption = True
            
            if not next_para_is_caption:
                if i + 1 < len(doc.paragraphs):
                    caption_para = doc.paragraphs[i+1].insert_paragraph_before(caption_text)
                else:
                    caption_para = doc.add_paragraph(caption_text)
                print(f"‚úÖ inserted new Figure 2 caption")
                
            caption_para.style = "Caption"
            caption_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
            if caption_para.runs:
                caption_para.runs[0].italic = True
                caption_para.runs[0].font.size = Pt(9)
                
            found = True
            break
            
    if not found:
        print("‚ö†Ô∏è Figure 2 placeholder not found in document")
        
    return found


def replace_figure_1_placeholder(doc):
    """Specific replacement for Figure 1 placeholder requested by user"""
    print("üñºÔ∏è Checking for Figure 1 placeholder...")
    
    # User requested [[Figure-1]]
    placeholder_text = "[[Figure-1]]"
    caption_text = 'Figure 1: Change in "hot summer days" (over 30¬∫C) for Republic of Fiji (Source Met Office Local Authority Climate Service 2025)'
    
    # Try multiple possible filenames for Figure 1
    possible_filenames = [
        "Figure-1_Change-in-Hot-Summer-Days_3.png",
        "Figure-1_Change-in-Hot-Summer-Days.png",
        "Figure-1.png"
    ]
    
    image_path = None
    for filename in possible_filenames:
        path = os.path.join(UPLOAD_FOLDER, filename)
        if os.path.exists(path):
            image_path = path
            print(f"‚úÖ Found Figure 1 image: {filename}")
            break
            
    if not image_path:
        print(f"‚ö†Ô∏è Figure 1 image not found (checked: {possible_filenames})")
        return False
        
    found = False
    for i, paragraph in enumerate(doc.paragraphs):
        if placeholder_text in paragraph.text:
            print(f"‚úÖ Found Figure 1 placeholder at paragraph {i}")
            
            # Clear paragraph content
            paragraph.text = ""
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            
            # Insert image
            run = paragraph.add_run()
            try:
                run.add_picture(image_path, width=Inches(6.0))
                print(f"‚úÖ Inserted Figure 1 image")
            except Exception as e:
                print(f"‚ùå Error inserting Figure 1 image: {e}")
                
            # Add caption
            # Check if the NEXT paragraph is already the caption
            next_para_is_caption = False
            if i + 1 < len(doc.paragraphs):
                next_para = doc.paragraphs[i+1]
                if "Figure 1" in next_para.text:
                    print(f"‚úÖ Found existing Figure 1 caption, updating it")
                    caption_para = next_para
                    caption_para.text = caption_text
                    next_para_is_caption = True
            
            if not next_para_is_caption:
                if i + 1 < len(doc.paragraphs):
                    caption_para = doc.paragraphs[i+1].insert_paragraph_before(caption_text)
                else:
                    caption_para = doc.add_paragraph(caption_text)
                print(f"‚úÖ inserted new Figure 1 caption")
                
            caption_para.style = "Caption"
            caption_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
            if caption_para.runs:
                caption_para.runs[0].italic = True
                caption_para.runs[0].font.size = Pt(9)
                
            found = True
            break
            
    if not found:
        print("‚ö†Ô∏è Figure 1 placeholder not found in document")
        
    return found


if __name__ == "__main__":
    print("üöÄ Starting Flask Gemini Report Generator...")
    print(f"üîë Gemini API: {'‚úÖ CONFIGURED' if GEMINI_API_KEY else '‚ùå NOT CONFIGURED'}")

    # Initialize Gemini
    if initialize_gemini():
        print(f"ü§ñ Gemini AI: ‚úÖ ENABLED - Using {AVAILABLE_GEMINI_MODEL['short_name']}")
    else:
        print("ü§ñ Gemini AI: ‚ö†Ô∏è DISABLED (Reports will still work)")

    # Dropbox status
    if dbx:
        print("‚òÅÔ∏è Dropbox: ‚úÖ ENABLED with permanent access")
    else:
        print("‚òÅÔ∏è Dropbox: ‚ö†Ô∏è DISABLED (Set refresh token for uploads)")

    print("üìÅ Folders ready:", [UPLOAD_FOLDER, OUTPUT_FOLDER])
    print("üåê Server starting at http://127.0.0.1:5000")

    app.run(host="0.0.0.0", port=5000, debug=True)